{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_coin_detection0203.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPQKzYN94tau1WzlVfuOMdl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9cy0C2xB1CM8"},"source":["掛載Google雲端硬盤\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"ggq5qliD4f7P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612318676969,"user_tz":-480,"elapsed":24759,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"5ad88659-93e1-4d4e-b50c-91b9c6793bc0"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","model_dir = '/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203'\r\n","import os\r\n","os.makedirs(model_dir, exist_ok=True)\r\n","!ls -ltra '{model_dir}'/.."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","total 4\n","drwx------ 2 root root 4096 Feb  2 14:16 Training0203\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fW_3ap4V0_to"},"source":["安裝一些必須的套件："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhLI35kvzWGI","executionInfo":{"status":"ok","timestamp":1612318787094,"user_tz":-480,"elapsed":107017,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"63c7325f-2a8d-4ff1-f934-8cf30ff2dd23"},"source":["!pip uninstall tensorflow\r\n","!pip install tensorflow-gpu==1.14.0\r\n","!pip install tf_slim\r\n","!pip list # 列出已安裝的套件清單檢查tensorflow是否為1.14版"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-2.4.1.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.4.1\n","Collecting tensorflow-gpu==1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n","\u001b[K     |████████████████████████████████| 377.0MB 46kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 48.2MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 50.4MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (53.0.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n","Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n","Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 19.4MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n","Package                       Version        \n","----------------------------- ---------------\n","absl-py                       0.10.0         \n","alabaster                     0.7.12         \n","albumentations                0.1.12         \n","altair                        4.1.0          \n","appdirs                       1.4.4          \n","argon2-cffi                   20.1.0         \n","asgiref                       3.3.1          \n","astor                         0.8.1          \n","astropy                       4.1            \n","astunparse                    1.6.3          \n","async-generator               1.10           \n","atari-py                      0.2.6          \n","atomicwrites                  1.4.0          \n","attrs                         20.3.0         \n","audioread                     2.1.9          \n","autograd                      1.3            \n","Babel                         2.9.0          \n","backcall                      0.2.0          \n","beautifulsoup4                4.6.3          \n","bleach                        3.2.3          \n","blis                          0.4.1          \n","bokeh                         2.1.1          \n","Bottleneck                    1.3.2          \n","branca                        0.4.2          \n","bs4                           0.0.1          \n","CacheControl                  0.12.6         \n","cachetools                    4.2.1          \n","catalogue                     1.0.0          \n","certifi                       2020.12.5      \n","cffi                          1.14.4         \n","chainer                       7.4.0          \n","chardet                       3.0.4          \n","click                         7.1.2          \n","cloudpickle                   1.3.0          \n","cmake                         3.12.0         \n","cmdstanpy                     0.9.5          \n","colorlover                    0.3.0          \n","community                     1.0.0b1        \n","contextlib2                   0.5.5          \n","convertdate                   2.2.0          \n","coverage                      3.7.1          \n","coveralls                     0.5            \n","crcmod                        1.7            \n","cufflinks                     0.17.3         \n","cupy-cuda101                  7.4.0          \n","cvxopt                        1.2.5          \n","cvxpy                         1.0.31         \n","cycler                        0.10.0         \n","cymem                         2.0.5          \n","Cython                        0.29.21        \n","daft                          0.0.4          \n","dask                          2.12.0         \n","dataclasses                   0.8            \n","datascience                   0.10.6         \n","debugpy                       1.0.0          \n","decorator                     4.4.2          \n","defusedxml                    0.6.0          \n","descartes                     1.1.0          \n","dill                          0.3.3          \n","distributed                   1.25.3         \n","Django                        3.1.5          \n","dlib                          19.18.0        \n","dm-tree                       0.1.5          \n","docopt                        0.6.2          \n","docutils                      0.16           \n","dopamine-rl                   1.0.5          \n","earthengine-api               0.1.238        \n","easydict                      1.9            \n","ecos                          2.0.7.post1    \n","editdistance                  0.5.3          \n","en-core-web-sm                2.2.5          \n","entrypoints                   0.3            \n","ephem                         3.7.7.1        \n","et-xmlfile                    1.0.1          \n","fa2                           0.3.5          \n","fancyimpute                   0.4.3          \n","fastai                        1.0.61         \n","fastdtw                       0.3.4          \n","fastprogress                  1.0.0          \n","fastrlock                     0.5            \n","fbprophet                     0.7.1          \n","feather-format                0.4.1          \n","filelock                      3.0.12         \n","firebase-admin                4.4.0          \n","fix-yahoo-finance             0.0.22         \n","Flask                         1.1.2          \n","flatbuffers                   1.12           \n","folium                        0.8.3          \n","future                        0.16.0         \n","gast                          0.3.3          \n","GDAL                          2.2.2          \n","gdown                         3.6.4          \n","gensim                        3.6.0          \n","geographiclib                 1.50           \n","geopy                         1.17.0         \n","gin-config                    0.4.0          \n","glob2                         0.7            \n","google                        2.0.3          \n","google-api-core               1.16.0         \n","google-api-python-client      1.7.12         \n","google-auth                   1.24.0         \n","google-auth-httplib2          0.0.4          \n","google-auth-oauthlib          0.4.2          \n","google-cloud-bigquery         1.21.0         \n","google-cloud-bigquery-storage 1.1.0          \n","google-cloud-core             1.0.3          \n","google-cloud-datastore        1.8.0          \n","google-cloud-firestore        1.7.0          \n","google-cloud-language         1.2.0          \n","google-cloud-storage          1.18.1         \n","google-cloud-translate        1.5.0          \n","google-colab                  1.0.0          \n","google-pasta                  0.2.0          \n","google-resumable-media        0.4.1          \n","googleapis-common-protos      1.52.0         \n","googledrivedownloader         0.4            \n","graphviz                      0.10.1         \n","grpcio                        1.32.0         \n","gspread                       3.0.1          \n","gspread-dataframe             3.0.8          \n","gym                           0.17.3         \n","h5py                          2.10.0         \n","HeapDict                      1.0.1          \n","holidays                      0.10.4         \n","holoviews                     1.13.5         \n","html5lib                      1.0.1          \n","httpimport                    0.5.18         \n","httplib2                      0.17.4         \n","httplib2shim                  0.0.3          \n","humanize                      0.5.1          \n","hyperopt                      0.1.2          \n","ideep4py                      2.0.0.post3    \n","idna                          2.10           \n","image                         1.5.33         \n","imageio                       2.4.1          \n","imagesize                     1.2.0          \n","imbalanced-learn              0.4.3          \n","imblearn                      0.0            \n","imgaug                        0.2.9          \n","importlib-metadata            3.4.0          \n","importlib-resources           5.1.0          \n","imutils                       0.5.4          \n","inflect                       2.1.0          \n","iniconfig                     1.1.1          \n","intel-openmp                  2021.1.2       \n","intervaltree                  2.1.0          \n","ipykernel                     4.10.1         \n","ipython                       5.5.0          \n","ipython-genutils              0.2.0          \n","ipython-sql                   0.3.9          \n","ipywidgets                    7.6.3          \n","itsdangerous                  1.1.0          \n","jax                           0.2.8          \n","jaxlib                        0.1.59+cuda101 \n","jdcal                         1.4.1          \n","jedi                          0.18.0         \n","jieba                         0.42.1         \n","Jinja2                        2.11.2         \n","joblib                        1.0.0          \n","jpeg4py                       0.1.4          \n","jsonschema                    2.6.0          \n","jupyter                       1.0.0          \n","jupyter-client                5.3.5          \n","jupyter-console               5.2.0          \n","jupyter-core                  4.7.0          \n","jupyterlab-pygments           0.1.2          \n","jupyterlab-widgets            1.0.0          \n","kaggle                        1.5.10         \n","kapre                         0.1.3.1        \n","Keras                         2.4.3          \n","Keras-Applications            1.0.8          \n","Keras-Preprocessing           1.1.2          \n","keras-vis                     0.4.1          \n","kiwisolver                    1.3.1          \n","knnimpute                     0.1.0          \n","korean-lunar-calendar         0.2.1          \n","librosa                       0.8.0          \n","lightgbm                      2.2.3          \n","llvmlite                      0.34.0         \n","lmdb                          0.99           \n","lucid                         0.3.8          \n","LunarCalendar                 0.0.9          \n","lxml                          4.2.6          \n","Markdown                      3.3.3          \n","MarkupSafe                    1.1.1          \n","matplotlib                    3.2.2          \n","matplotlib-venn               0.11.6         \n","missingno                     0.4.2          \n","mistune                       0.8.4          \n","mizani                        0.6.0          \n","mkl                           2019.0         \n","mlxtend                       0.14.0         \n","more-itertools                8.6.0          \n","moviepy                       0.2.3.5        \n","mpmath                        1.1.0          \n","msgpack                       1.0.2          \n","multiprocess                  0.70.11.1      \n","multitasking                  0.0.9          \n","murmurhash                    1.0.5          \n","music21                       5.5.0          \n","natsort                       5.5.0          \n","nbclient                      0.5.1          \n","nbconvert                     5.6.1          \n","nbformat                      5.1.2          \n","nest-asyncio                  1.5.1          \n","networkx                      2.5            \n","nibabel                       3.0.2          \n","nltk                          3.2.5          \n","notebook                      5.3.1          \n","np-utils                      0.5.12.1       \n","numba                         0.51.2         \n","numexpr                       2.7.2          \n","numpy                         1.19.5         \n","nvidia-ml-py3                 7.352.0        \n","oauth2client                  4.1.3          \n","oauthlib                      3.1.0          \n","okgrade                       0.4.3          \n","opencv-contrib-python         4.1.2.30       \n","opencv-python                 4.1.2.30       \n","openpyxl                      2.5.9          \n","opt-einsum                    3.3.0          \n","osqp                          0.6.2.post0    \n","packaging                     20.8           \n","palettable                    3.3.0          \n","pandas                        1.1.5          \n","pandas-datareader             0.9.0          \n","pandas-gbq                    0.13.3         \n","pandas-profiling              1.4.1          \n","pandocfilters                 1.4.3          \n","panel                         0.9.7          \n","param                         1.10.1         \n","parso                         0.8.1          \n","pathlib                       1.0.1          \n","patsy                         0.5.1          \n","pexpect                       4.8.0          \n","pickleshare                   0.7.5          \n","Pillow                        7.0.0          \n","pip                           19.3.1         \n","pip-tools                     4.5.1          \n","plac                          1.1.3          \n","plotly                        4.4.1          \n","plotnine                      0.6.0          \n","pluggy                        0.7.1          \n","pooch                         1.3.0          \n","portpicker                    1.3.1          \n","prefetch-generator            1.0.1          \n","preshed                       3.0.5          \n","prettytable                   2.0.0          \n","progressbar2                  3.38.0         \n","prometheus-client             0.9.0          \n","promise                       2.3            \n","prompt-toolkit                1.0.18         \n","protobuf                      3.12.4         \n","psutil                        5.4.8          \n","psycopg2                      2.7.6.1        \n","ptyprocess                    0.7.0          \n","py                            1.10.0         \n","pyarrow                       0.14.1         \n","pyasn1                        0.4.8          \n","pyasn1-modules                0.2.8          \n","pycocotools                   2.0.2          \n","pycparser                     2.20           \n","pyct                          0.4.8          \n","pydata-google-auth            1.1.0          \n","pydot                         1.3.0          \n","pydot-ng                      2.0.0          \n","pydotplus                     2.0.2          \n","PyDrive                       1.3.1          \n","pyemd                         0.5.1          \n","pyglet                        1.5.0          \n","Pygments                      2.6.1          \n","pygobject                     3.26.1         \n","pymc3                         3.7            \n","PyMeeus                       0.3.7          \n","pymongo                       3.11.2         \n","pymystem3                     0.2.0          \n","pynndescent                   0.5.1          \n","PyOpenGL                      3.1.5          \n","pyparsing                     2.4.7          \n","pyrsistent                    0.17.3         \n","pysndfile                     1.3.8          \n","PySocks                       1.7.1          \n","pystan                        2.19.1.1       \n","pytest                        3.6.4          \n","python-apt                    1.6.5+ubuntu0.5\n","python-chess                  0.23.11        \n","python-dateutil               2.8.1          \n","python-louvain                0.15           \n","python-slugify                4.0.1          \n","python-utils                  2.5.5          \n","pytz                          2018.9         \n","pyviz-comms                   2.0.1          \n","PyWavelets                    1.1.1          \n","PyYAML                        3.13           \n","pyzmq                         22.0.2         \n","qdldl                         0.1.5.post0    \n","qtconsole                     5.0.2          \n","QtPy                          1.9.0          \n","regex                         2019.12.20     \n","requests                      2.23.0         \n","requests-oauthlib             1.3.0          \n","resampy                       0.2.2          \n","retrying                      1.3.3          \n","rpy2                          3.2.7          \n","rsa                           4.7            \n","scikit-image                  0.16.2         \n","scikit-learn                  0.22.2.post1   \n","scipy                         1.4.1          \n","screen-resolution-extra       0.0.0          \n","scs                           2.1.2          \n","seaborn                       0.11.1         \n","Send2Trash                    1.5.0          \n","setuptools                    53.0.0         \n","setuptools-git                1.2            \n","Shapely                       1.7.1          \n","simplegeneric                 0.8.1          \n","six                           1.15.0         \n","sklearn                       0.0            \n","sklearn-pandas                1.8.0          \n","smart-open                    4.1.2          \n","snowballstemmer               2.1.0          \n","sortedcontainers              2.3.0          \n","SoundFile                     0.10.3.post1   \n","spacy                         2.2.4          \n","Sphinx                        1.8.5          \n","sphinxcontrib-serializinghtml 1.1.4          \n","sphinxcontrib-websupport      1.2.4          \n","SQLAlchemy                    1.3.22         \n","sqlparse                      0.4.1          \n","srsly                         1.0.5          \n","statsmodels                   0.10.2         \n","sympy                         1.1.1          \n","tables                        3.4.4          \n","tabulate                      0.8.7          \n","tblib                         1.7.0          \n","tensorboard                   1.14.0         \n","tensorboard-plugin-wit        1.8.0          \n","tensorboardcolab              0.0.22         \n","tensorflow-addons             0.8.3          \n","tensorflow-datasets           4.0.1          \n","tensorflow-estimator          1.14.0         \n","tensorflow-gcs-config         2.4.0          \n","tensorflow-gpu                1.14.0         \n","tensorflow-hub                0.11.0         \n","tensorflow-metadata           0.27.0         \n","tensorflow-privacy            0.2.2          \n","tensorflow-probability        0.12.1         \n","termcolor                     1.1.0          \n","terminado                     0.9.2          \n","testpath                      0.4.4          \n","text-unidecode                1.3            \n","textblob                      0.15.3         \n","textgenrnn                    1.4.1          \n","tf-slim                       1.1.0          \n","Theano                        1.0.5          \n","thinc                         7.4.0          \n","tifffile                      2020.9.3       \n","toml                          0.10.2         \n","toolz                         0.11.1         \n","torch                         1.7.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.8.1+cu101    \n","tornado                       5.1.1          \n","tqdm                          4.41.1         \n","traitlets                     4.3.3          \n","tweepy                        3.6.0          \n","typeguard                     2.7.1          \n","typing-extensions             3.7.4.3        \n","tzlocal                       1.5.1          \n","umap-learn                    0.5.0          \n","uritemplate                   3.0.1          \n","urllib3                       1.24.3         \n","vega-datasets                 0.9.0          \n","wasabi                        0.8.1          \n","wcwidth                       0.2.5          \n","webencodings                  0.5.1          \n","Werkzeug                      1.0.1          \n","wheel                         0.36.2         \n","widgetsnbextension            3.5.1          \n","wordcloud                     1.5.0          \n","wrapt                         1.12.1         \n","xarray                        0.15.1         \n","xgboost                       0.90           \n","xkit                          0.0.0          \n","xlrd                          1.1.0          \n","xlwt                          1.3.0          \n","yellowbrick                   0.9.1          \n","zict                          2.0.0          \n","zipp                          3.4.0          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5c3Dj67hz7GX"},"source":["repo_url = 'https://github.com/yifangzz/myprojet' #換成自己的網址\r\n","\r\n","num_steps = 1000\r\n","num_eval_steps = 50\r\n","MODELS_CONFIG = {\r\n","    'ssd_mobilenet_v1_quantized': {\r\n","        'model_name': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18',\r\n","        'pipeline_file': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync.config',\r\n","        'batch_size': 12\r\n","    },    \r\n","    'ssd_mobilenet_v2': {\r\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\r\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\r\n","        'batch_size': 12\r\n","    },\r\n","    'ssd_mobilenet_v2_quantized': {\r\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\r\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\r\n","        'batch_size': 12\r\n","    },\r\n","    'faster_rcnn_inception_v2': {\r\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\r\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\r\n","        'batch_size': 12\r\n","    },\r\n","    'rfcn_resnet101': {\r\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\r\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\r\n","        'batch_size': 12\r\n","    }\r\n","}\r\n","\r\n","selected_model = 'ssd_mobilenet_v2_quantized'\r\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\r\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\r\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wW4j5uEu03Sa"},"source":["3 建立培訓環境\r\n","3.1 Clone您的github網頁"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQBnsxBl0j-i","executionInfo":{"status":"ok","timestamp":1612318813589,"user_tz":-480,"elapsed":1064,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"0e757981-5402-4d0e-979b-c9188c4304b1"},"source":["import os\r\n","\r\n","%cd /content\r\n","\r\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\r\n","\r\n","!git clone {repo_url}\r\n","%cd {repo_dir_path}\r\n","\r\n","print('Pull it so that we have the latest code/data')\r\n","!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'myprojet' already exists and is not an empty directory.\n","/content/myprojet\n","Pull it so that we have the latest code/data\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LtUAnI7l01Mv"},"source":["3.2安裝所需的套件包"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBhf4G2M0svB","executionInfo":{"status":"ok","timestamp":1612318857104,"user_tz":-480,"elapsed":37522,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"b5ce9b47-8b23-490e-d3a8-ad6144b70cdf"},"source":["%cd /content\r\n","!git clone --quiet https://github.com/tensorflow/models.git\r\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\r\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\r\n","!pip install -q pycocotools\r\n","!pip install lvis\r\n","\r\n","%cd /content/models/research\r\n","!protoc object_detection/protos/*.proto --python_out=.\r\n","\r\n","import os\r\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\r\n","\r\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 146456 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.19.5)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n","Installing collected packages: lvis\n","Successfully installed lvis-0.5.3\n","/content/models/research\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lj-Cvott1TAK"},"source":["3.3準備tfrecord文件："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cg6-fF41Gf_","executionInfo":{"status":"ok","timestamp":1612318862164,"user_tz":-480,"elapsed":6138,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"972b9650-3f79-4f31-c5b3-325bbc7c3a66"},"source":["%cd {repo_dir_path}/models/object_detection\r\n","\r\n","# Convert train folder annotation xml files to a single csv file,\r\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\r\n","!python code/xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\r\n","\r\n","# Convert test folder annotation xml files to a single csv.\r\n","!python code/xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\r\n","\r\n","# Generate `train.record`\r\n","!python code/generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\r\n","\r\n","# Generate `test.record`\r\n","!python code/generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/myprojet/models/object_detection\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0203 02:20:59.406891 140717406054272 deprecation_wrapper.py:119] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0203 02:20:59.436688 140717406054272 deprecation_wrapper.py:119] From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/myprojet/models/object_detection/data/annotations/train.record\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0203 02:21:01.482485 140337668884352 deprecation_wrapper.py:119] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0203 02:21:01.496196 140337668884352 deprecation_wrapper.py:119] From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/myprojet/models/object_detection/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OauOCC6A29-U"},"source":["test_record_fname = repo_dir_path + '/models/object_detection/data/annotations/test.record'\r\n","train_record_fname = repo_dir_path + '/models/object_detection/data/annotations/train.record'\r\n","label_map_pbtxt_fname = repo_dir_path + '/models/object_detection/data/annotations/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlqKbUKg3AL1","executionInfo":{"status":"ok","timestamp":1612318872048,"user_tz":-480,"elapsed":769,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"aff1ee1f-fcc4-412f-dc7f-2b6b9cb25a5f"},"source":["!cat data/annotations/test_labels.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["filename,width,height,class,xmin,ymin,xmax,ymax\n","044.jpg,540,960,1 dallar,175,222,260,303\n","044.jpg,540,960,1 dallar,243,334,328,415\n","044.jpg,540,960,5 dallar,168,437,260,524\n","044.jpg,540,960,5 dallar,323,401,415,488\n","044.jpg,540,960,5 dallar,136,323,228,410\n","044.jpg,540,960,10 dallar,205,534,324,646\n","044.jpg,540,960,10 dallar,291,230,398,337\n","045.jpg,540,960,1 dallar,129,248,212,327\n","045.jpg,540,960,1 dallar,222,339,305,418\n","045.jpg,540,960,5 dallar,116,352,205,445\n","045.jpg,540,960,5 dallar,319,384,408,477\n","045.jpg,540,960,5 dallar,175,454,264,547\n","045.jpg,540,960,10 dallar,243,227,351,331\n","045.jpg,540,960,10 dallar,237,543,345,647\n","013.jpg,540,960,5 dallar,143,350,238,446\n","013.jpg,540,960,5 dallar,288,308,383,404\n","013.jpg,540,960,5 dallar,340,416,435,512\n","013.jpg,540,960,10 dallar,157,506,291,624\n","013.jpg,540,960,10 dallar,222,181,356,299\n","013.jpg,540,960,1 dallar,235,419,323,506\n","013.jpg,540,960,1 dallar,316,530,404,617\n","084.jpg,540,960,10 dallar,185,283,293,386\n","084.jpg,540,960,10 dallar,270,578,380,695\n","084.jpg,540,960,5 dallar,170,455,261,546\n","084.jpg,540,960,5 dallar,290,357,381,448\n","084.jpg,540,960,5 dallar,372,433,463,524\n","084.jpg,540,960,1 dallar,281,476,363,562\n","084.jpg,540,960,1 dallar,402,547,484,633\n","011.jpg,540,960,10 dallar,234,184,370,308\n","011.jpg,540,960,10 dallar,130,503,266,627\n","011.jpg,540,960,5 dallar,136,331,237,438\n","011.jpg,540,960,5 dallar,293,306,394,413\n","011.jpg,540,960,5 dallar,329,421,430,528\n","011.jpg,540,960,1 dallar,224,412,317,504\n","011.jpg,540,960,1 dallar,296,535,389,627\n","083.jpg,540,960,10 dallar,182,326,284,436\n","083.jpg,540,960,10 dallar,257,634,375,747\n","083.jpg,540,960,5 dallar,159,504,256,599\n","083.jpg,540,960,5 dallar,284,401,381,496\n","083.jpg,540,960,5 dallar,364,481,461,576\n","083.jpg,540,960,1 dallar,274,530,361,615\n","083.jpg,540,960,1 dallar,395,600,482,685\n","042.jpg,540,960,10 dallar,184,534,303,646\n","042.jpg,540,960,10 dallar,326,251,436,354\n","042.jpg,540,960,5 dallar,159,312,249,397\n","042.jpg,540,960,5 dallar,170,429,260,514\n","042.jpg,540,960,5 dallar,332,424,422,509\n","042.jpg,540,960,1 dallar,218,221,305,300\n","042.jpg,540,960,1 dallar,265,343,352,422\n","085.jpg,540,960,10 dallar,206,226,310,325\n","085.jpg,540,960,10 dallar,274,516,384,628\n","085.jpg,540,960,5 dallar,181,396,271,480\n","085.jpg,540,960,5 dallar,299,309,389,393\n","085.jpg,540,960,5 dallar,382,388,472,472\n","085.jpg,540,960,1 dallar,289,422,371,504\n","085.jpg,540,960,1 dallar,409,492,491,574\n","082.jpg,540,960,10 dallar,146,357,251,457\n","082.jpg,540,960,10 dallar,232,666,353,782\n","082.jpg,540,960,5 dallar,129,537,220,637\n","082.jpg,540,960,5 dallar,252,428,343,528\n","082.jpg,540,960,5 dallar,338,504,429,604\n","082.jpg,540,960,1 dallar,241,560,334,647\n","082.jpg,540,960,1 dallar,369,617,468,709\n","062.jpg,540,960,10 dallar,28,339,145,448\n","062.jpg,540,960,10 dallar,317,225,434,334\n","062.jpg,540,960,5 dallar,162,225,255,328\n","062.jpg,540,960,5 dallar,280,329,377,417\n","062.jpg,540,960,5 dallar,210,420,303,523\n","062.jpg,540,960,1 dallar,160,342,246,417\n","062.jpg,540,960,1 dallar,111,467,197,542\n","015.jpg,540,960,10 dallar,162,204,286,320\n","015.jpg,540,960,10 dallar,205,529,329,645\n","015.jpg,540,960,5 dallar,136,379,228,485\n","015.jpg,540,960,5 dallar,266,292,358,398\n","015.jpg,540,960,5 dallar,347,385,439,491\n","015.jpg,540,960,1 dallar,359,507,450,603\n","015.jpg,540,960,1 dallar,244,419,335,515\n","063.jpg,540,960,1 dallar,146,458,228,547\n","063.jpg,540,960,1 dallar,181,331,263,420\n","063.jpg,540,960,10 dallar,59,340,173,456\n","063.jpg,540,960,10 dallar,330,199,444,315\n","063.jpg,540,960,5 dallar,179,222,268,324\n","063.jpg,540,960,5 dallar,303,311,392,413\n","063.jpg,540,960,5 dallar,244,410,334,499\n","043.jpg,540,960,1 dallar,224,220,300,298\n","043.jpg,540,960,1 dallar,268,339,347,421\n","043.jpg,540,960,5 dallar,158,307,252,398\n","043.jpg,540,960,5 dallar,332,420,426,511\n","043.jpg,540,960,5 dallar,170,424,264,515\n","043.jpg,540,960,10 dallar,186,531,299,647\n","043.jpg,540,960,10 dallar,331,247,439,352\n","064.jpg,540,960,1 dallar,154,475,240,550\n","064.jpg,540,960,1 dallar,178,348,264,423\n","064.jpg,540,960,10 dallar,49,354,177,475\n","064.jpg,540,960,10 dallar,317,180,445,301\n","064.jpg,540,960,5 dallar,168,223,260,321\n","064.jpg,540,960,5 dallar,256,408,348,506\n","064.jpg,540,960,5 dallar,301,310,393,408\n","041.jpg,540,960,10 dallar,193,537,310,652\n","041.jpg,540,960,10 dallar,332,255,440,354\n","041.jpg,540,960,5 dallar,161,314,257,400\n","041.jpg,540,960,5 dallar,174,432,270,518\n","041.jpg,540,960,5 dallar,335,426,431,512\n","041.jpg,540,960,1 dallar,225,221,302,303\n","041.jpg,540,960,1 dallar,273,346,350,428\n","012.jpg,540,960,1 dallar,231,423,312,501\n","012.jpg,540,960,1 dallar,295,540,392,630\n","012.jpg,540,960,10 dallar,147,500,267,623\n","012.jpg,540,960,10 dallar,238,189,358,312\n","012.jpg,540,960,5 dallar,134,340,238,435\n","012.jpg,540,960,5 dallar,297,313,401,408\n","012.jpg,540,960,5 dallar,333,426,437,521\n","061.jpg,540,960,10 dallar,19,331,134,436\n","061.jpg,540,960,10 dallar,321,243,436,348\n","061.jpg,540,960,5 dallar,156,234,261,320\n","061.jpg,540,960,5 dallar,262,343,367,429\n","061.jpg,540,960,5 dallar,184,433,289,519\n","061.jpg,540,960,1 dallar,82,458,180,547\n","061.jpg,540,960,1 dallar,143,335,241,424\n","065.jpg,540,960,10 dallar,59,377,173,488\n","065.jpg,540,960,10 dallar,304,192,418,303\n","065.jpg,540,960,5 dallar,156,247,245,335\n","065.jpg,540,960,5 dallar,296,306,385,394\n","065.jpg,540,960,5 dallar,259,418,348,506\n","065.jpg,540,960,1 dallar,181,350,265,425\n","065.jpg,540,960,1 dallar,165,478,250,561\n","081.jpg,540,960,1 dallar,199,569,291,665\n","081.jpg,540,960,1 dallar,327,636,419,732\n","081.jpg,540,960,10 dallar,108,358,216,471\n","081.jpg,540,960,10 dallar,185,678,297,803\n","081.jpg,540,960,5 dallar,78,541,187,647\n","081.jpg,540,960,5 dallar,201,435,310,541\n","081.jpg,540,960,5 dallar,295,516,404,622\n","014.jpg,540,960,10 dallar,206,196,323,305\n","014.jpg,540,960,10 dallar,186,518,303,627\n","014.jpg,540,960,5 dallar,138,363,238,453\n","014.jpg,540,960,5 dallar,283,301,383,391\n","014.jpg,540,960,5 dallar,339,405,439,495\n","014.jpg,540,960,1 dallar,245,416,325,511\n","014.jpg,540,960,1 dallar,335,516,429,612\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qukcbxtr1e_W"},"source":["3.4下載基本模型"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"id":"ZCjJUu1c1dkv","executionInfo":{"status":"ok","timestamp":1612318882956,"user_tz":-480,"elapsed":3320,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"a2c58905-473d-4faa-9c39-4a26b6ac261e"},"source":["%cd /content/models/research\r\n","\r\n","import os\r\n","import shutil\r\n","import glob\r\n","import urllib.request\r\n","import tarfile\r\n","MODEL_FILE = MODEL + '.tar.gz'\r\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\r\n","DEST_DIR = '/content/models/research/pretrained_model'\r\n","\r\n","if not (os.path.exists(MODEL_FILE)):\r\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\r\n","\r\n","tar = tarfile.open(MODEL_FILE)\r\n","tar.extractall()\r\n","tar.close()\r\n","\r\n","os.remove(MODEL_FILE)\r\n","if (os.path.exists(DEST_DIR)):\r\n","    shutil.rmtree(DEST_DIR)\r\n","os.rename(MODEL, DEST_DIR)\r\n","\r\n","!echo {DEST_DIR}\r\n","!ls -alh {DEST_DIR}\r\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\r\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research\n","/content/models/research/pretrained_model\n","total 204M\n","drwx------  2 303230 5000 4.0K Jan  4  2019 .\n","drwxr-xr-x 24 root   root 4.0K Feb  3 02:21 ..\n","-rw-------  1 303230 5000  93M Jan  4  2019 model.ckpt.data-00000-of-00001\n","-rw-------  1 303230 5000  68K Jan  4  2019 model.ckpt.index\n","-rw-------  1 303230 5000  20M Jan  4  2019 model.ckpt.meta\n","-rw-------  1 303230 5000 4.3K Jan  4  2019 pipeline.config\n","-rw-------  1 303230 5000  24M Jan  4  2019 tflite_graph.pb\n","-rw-------  1 303230 5000  68M Jan  4  2019 tflite_graph.pbtxt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"5mkNMTGS1iz4"},"source":["\r\n","4轉移學習訓練\r\n","\r\n","4.1配置訓練Pipeline，設定訓練模型之config檔（類別數目與名稱、\r\n","訓練資料來源）\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIQ12Z8q1kzL","executionInfo":{"status":"ok","timestamp":1612275679201,"user_tz":-480,"elapsed":1929,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"115bb59c-3b80-44c7-a774-2d50bc46fceb"},"source":["import os\r\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\r\n","\r\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\r\n","def get_num_classes(pbtxt_fname):\r\n","    from object_detection.utils import label_map_util\r\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\r\n","    categories = label_map_util.convert_label_map_to_categories(\r\n","        label_map, max_num_classes=90, use_display_name=True)\r\n","    category_index = label_map_util.create_category_index(categories)\r\n","    return len(category_index.keys())\r\n","\r\n","import re\r\n","num_classes = get_num_classes(label_map_pbtxt_fname)\r\n","with open(pipeline_fname) as f:\r\n","    s = f.read()\r\n","with open(pipeline_fname, 'w') as f:\r\n","    \r\n","    # fine_tune_checkpoint: downloaded pre-trained model checkpoint path\r\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\r\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\r\n","    \r\n","    # tfrecord files train and test, we created earlier with our training/test sets\r\n","    s = re.sub(\r\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\r\n","    s = re.sub(\r\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\r\n","\r\n","    # label_map_path: ID to label file\r\n","    s = re.sub(\r\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\r\n","\r\n","    # Set training batch_size.\r\n","    s = re.sub('batch_size: [0-9]+',\r\n","               'batch_size: {}'.format(batch_size), s)\r\n","\r\n","    # Set training steps, num_steps (Number of epochs to train)\r\n","    s = re.sub('num_steps: [0-9]+',\r\n","               'num_steps: {}'.format(num_steps), s)\r\n","    \r\n","    # Set number of classes num_classes.\r\n","    s = re.sub('num_classes: [0-9]+',\r\n","               'num_classes: {}'.format(num_classes), s)\r\n","    f.write(s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"252oa5T037If","executionInfo":{"status":"ok","timestamp":1612275688155,"user_tz":-480,"elapsed":736,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"23912ab8-8c8c-4f83-f985-055ab3c6a49e"},"source":["!cat {label_map_pbtxt_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["item {\n","    id: 1\n","    name: '1 dallar'\n","}\n","\n","item {\n","    id: 2\n","    name: '10 dallar'\n","}\n","\n","item {\n","    id: 3\n","    name: '5 dallar'\n","}"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5wcHIUZx5V2I"},"source":["4.2設定訓練輸出"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtFbGfpp39Ov","executionInfo":{"status":"ok","timestamp":1612275736215,"user_tz":-480,"elapsed":737,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"e96eaa29-fbbf-4c9b-cf4a-a86ad77209cc"},"source":["%%writefile /content/models/research/object_detection/model_main.py\r\n","from __future__ import absolute_import\r\n","from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","from absl import flags\r\n","\r\n","import tensorflow as tf\r\n","\r\n","from object_detection import model_hparams\r\n","from object_detection import model_lib\r\n","#tf.logging.set_verbosity(tf.logging.INFO)\r\n","#config = tf.estimator.RunConfig(log_step_count_steps=1)\r\n","\r\n","flags.DEFINE_string(\r\n","    'model_dir', None, 'Path to output model directory '\r\n","    'where event and checkpoint files will be written.')\r\n","flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\r\n","                    'file.')\r\n","flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\r\n","flags.DEFINE_boolean('eval_training_data', False,\r\n","                     'If training data should be evaluated for this job. Note '\r\n","                     'that one call only use this in eval-only mode, and '\r\n","                     '`checkpoint_dir` must be supplied.')\r\n","flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\r\n","                     'every n eval input examples, where n is provided.')\r\n","flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\r\n","                     'one of every n train input examples for evaluation, '\r\n","                     'where n is provided. This is only used if '\r\n","                     '`eval_training_data` is True.')\r\n","flags.DEFINE_string(\r\n","    'hparams_overrides', None, 'Hyperparameter overrides, '\r\n","    'represented as a string containing comma-separated '\r\n","    'hparam_name=value pairs.')\r\n","flags.DEFINE_string(\r\n","    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\r\n","    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\r\n","    'writing resulting metrics to `model_dir`.')\r\n","flags.DEFINE_boolean(\r\n","    'run_once', False, 'If running in eval-only mode, whether to run just '\r\n","    'one round of eval vs running continuously (default).'\r\n",")\r\n","FLAGS = flags.FLAGS\r\n","\r\n","def main(unused_argv):\r\n","  flags.mark_flag_as_required('model_dir')\r\n","  flags.mark_flag_as_required('pipeline_config_path')\r\n","  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,log_step_count_steps=1)\r\n","\r\n","  train_and_eval_dict = model_lib.create_estimator_and_inputs(\r\n","      run_config=config,\r\n","      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\r\n","      pipeline_config_path=FLAGS.pipeline_config_path,\r\n","      train_steps=FLAGS.num_train_steps,\r\n","      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\r\n","      sample_1_of_n_eval_on_train_examples=(\r\n","          FLAGS.sample_1_of_n_eval_on_train_examples))\r\n","  estimator = train_and_eval_dict['estimator']\r\n","  train_input_fn = train_and_eval_dict['train_input_fn']\r\n","  eval_input_fns = train_and_eval_dict['eval_input_fns']\r\n","  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\r\n","  predict_input_fn = train_and_eval_dict['predict_input_fn']\r\n","  train_steps = train_and_eval_dict['train_steps']\r\n","\r\n","  if FLAGS.checkpoint_dir:\r\n","    if FLAGS.eval_training_data:\r\n","      name = 'training_data'\r\n","      input_fn = eval_on_train_input_fn\r\n","    else:\r\n","      name = 'validation_data'\r\n","      # The first eval input will be evaluated.\r\n","      input_fn = eval_input_fns[0]\r\n","    if FLAGS.run_once:\r\n","      estimator.evaluate(input_fn,steps=None,checkpoint_path=tf.train.latest_checkpoint(FLAGS.checkpoint_dir))\r\n","    else:\r\n","      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,train_steps, name)\r\n","  else:\r\n","    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\r\n","        train_input_fn,\r\n","        eval_input_fns,\r\n","        eval_on_train_input_fn,\r\n","        predict_input_fn,\r\n","        train_steps,\r\n","        eval_on_train_data=False)\r\n","\r\n","    # Currently only a single Eval Spec is allowed.\r\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n","\r\n","if __name__ == '__main__':\r\n","  tf.app.run()\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/models/research/object_detection/model_main.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y5wkEFui69hh"},"source":["開始訓練模型\r\n","大約需要15分鐘"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLPP8NKY5bFm","executionInfo":{"status":"ok","timestamp":1612276642820,"user_tz":-480,"elapsed":903722,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"8cc03d4e-3943-4128-e000-1bb045ddd91a"},"source":["num_steps = 1000\r\n","num_eval_steps = 50\r\n","print(\"Colab train started\")\r\n","!python /content/models/research/object_detection/model_main.py \\\r\n","    --pipeline_config_path={pipeline_fname} \\\r\n","    --model_dir='{model_dir}' \\\r\n","    --alsologtostderr \\\r\n","    --num_train_steps={num_steps} \\\r\n","    --num_eval_steps={num_eval_steps}\r\n","print(\"Colab train finished\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n","I0202 14:24:44.037448 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3458\n","INFO:tensorflow:loss = 5.406488, step = 35 (0.743 sec)\n","I0202 14:24:44.037744 140715376195456 basic_session_run_hooks.py:260] loss = 5.406488, step = 35 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.34603\n","I0202 14:24:44.780367 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34603\n","INFO:tensorflow:loss = 5.683706, step = 36 (0.743 sec)\n","I0202 14:24:44.780693 140715376195456 basic_session_run_hooks.py:260] loss = 5.683706, step = 36 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.35607\n","I0202 14:24:45.517811 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35607\n","INFO:tensorflow:loss = 6.1049705, step = 37 (0.737 sec)\n","I0202 14:24:45.518159 140715376195456 basic_session_run_hooks.py:260] loss = 6.1049705, step = 37 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.32451\n","I0202 14:24:46.272801 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32451\n","INFO:tensorflow:loss = 5.474995, step = 38 (0.755 sec)\n","I0202 14:24:46.273117 140715376195456 basic_session_run_hooks.py:260] loss = 5.474995, step = 38 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.37711\n","I0202 14:24:46.998957 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37711\n","INFO:tensorflow:loss = 5.639455, step = 39 (0.726 sec)\n","I0202 14:24:46.999475 140715376195456 basic_session_run_hooks.py:260] loss = 5.639455, step = 39 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.36566\n","I0202 14:24:47.731190 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36566\n","INFO:tensorflow:loss = 5.6210337, step = 40 (0.732 sec)\n","I0202 14:24:47.731514 140715376195456 basic_session_run_hooks.py:260] loss = 5.6210337, step = 40 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39337\n","I0202 14:24:48.448886 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39337\n","INFO:tensorflow:loss = 5.4438787, step = 41 (0.718 sec)\n","I0202 14:24:48.449201 140715376195456 basic_session_run_hooks.py:260] loss = 5.4438787, step = 41 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.3923\n","I0202 14:24:49.167113 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3923\n","INFO:tensorflow:loss = 5.1537623, step = 42 (0.718 sec)\n","I0202 14:24:49.167413 140715376195456 basic_session_run_hooks.py:260] loss = 5.1537623, step = 42 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.33994\n","I0202 14:24:49.913440 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33994\n","INFO:tensorflow:loss = 5.1782603, step = 43 (0.746 sec)\n","I0202 14:24:49.913746 140715376195456 basic_session_run_hooks.py:260] loss = 5.1782603, step = 43 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.3986\n","I0202 14:24:50.628449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3986\n","INFO:tensorflow:loss = 5.439781, step = 44 (0.715 sec)\n","I0202 14:24:50.628785 140715376195456 basic_session_run_hooks.py:260] loss = 5.439781, step = 44 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.34667\n","I0202 14:24:51.371002 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34667\n","INFO:tensorflow:loss = 5.390989, step = 45 (0.743 sec)\n","I0202 14:24:51.371325 140715376195456 basic_session_run_hooks.py:260] loss = 5.390989, step = 45 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.38611\n","I0202 14:24:52.092451 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38611\n","INFO:tensorflow:loss = 5.504806, step = 46 (0.722 sec)\n","I0202 14:24:52.092936 140715376195456 basic_session_run_hooks.py:260] loss = 5.504806, step = 46 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.42953\n","I0202 14:24:52.791988 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42953\n","INFO:tensorflow:loss = 5.4156237, step = 47 (0.699 sec)\n","I0202 14:24:52.792315 140715376195456 basic_session_run_hooks.py:260] loss = 5.4156237, step = 47 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 1.38257\n","I0202 14:24:53.515250 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38257\n","INFO:tensorflow:loss = 5.1266356, step = 48 (0.723 sec)\n","I0202 14:24:53.515768 140715376195456 basic_session_run_hooks.py:260] loss = 5.1266356, step = 48 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37477\n","I0202 14:24:54.242654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37477\n","INFO:tensorflow:loss = 5.0853944, step = 49 (0.727 sec)\n","I0202 14:24:54.242941 140715376195456 basic_session_run_hooks.py:260] loss = 5.0853944, step = 49 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.38765\n","I0202 14:24:54.963305 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38765\n","INFO:tensorflow:loss = 4.948928, step = 50 (0.721 sec)\n","I0202 14:24:54.963636 140715376195456 basic_session_run_hooks.py:260] loss = 4.948928, step = 50 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37769\n","I0202 14:24:55.689154 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37769\n","INFO:tensorflow:loss = 5.228763, step = 51 (0.726 sec)\n","I0202 14:24:55.689651 140715376195456 basic_session_run_hooks.py:260] loss = 5.228763, step = 51 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.35262\n","I0202 14:24:56.428487 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35262\n","INFO:tensorflow:loss = 4.920458, step = 52 (0.739 sec)\n","I0202 14:24:56.428997 140715376195456 basic_session_run_hooks.py:260] loss = 4.920458, step = 52 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.43502\n","I0202 14:24:57.125317 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43502\n","INFO:tensorflow:loss = 4.8268366, step = 53 (0.697 sec)\n","I0202 14:24:57.125824 140715376195456 basic_session_run_hooks.py:260] loss = 4.8268366, step = 53 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 1.36544\n","I0202 14:24:57.857696 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36544\n","INFO:tensorflow:loss = 4.8753533, step = 54 (0.732 sec)\n","I0202 14:24:57.858207 140715376195456 basic_session_run_hooks.py:260] loss = 4.8753533, step = 54 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.3692\n","I0202 14:24:58.588050 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3692\n","INFO:tensorflow:loss = 4.832838, step = 55 (0.730 sec)\n","I0202 14:24:58.588358 140715376195456 basic_session_run_hooks.py:260] loss = 4.832838, step = 55 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.36084\n","I0202 14:24:59.322869 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36084\n","INFO:tensorflow:loss = 4.558879, step = 56 (0.735 sec)\n","I0202 14:24:59.323162 140715376195456 basic_session_run_hooks.py:260] loss = 4.558879, step = 56 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.38102\n","I0202 14:25:00.046971 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38102\n","INFO:tensorflow:loss = 4.579205, step = 57 (0.724 sec)\n","I0202 14:25:00.047282 140715376195456 basic_session_run_hooks.py:260] loss = 4.579205, step = 57 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.38832\n","I0202 14:25:00.767292 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38832\n","INFO:tensorflow:loss = 4.171464, step = 58 (0.721 sec)\n","I0202 14:25:00.767878 140715376195456 basic_session_run_hooks.py:260] loss = 4.171464, step = 58 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.27344\n","I0202 14:25:01.552572 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.27344\n","INFO:tensorflow:loss = 5.053601, step = 59 (0.785 sec)\n","I0202 14:25:01.553048 140715376195456 basic_session_run_hooks.py:260] loss = 5.053601, step = 59 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 1.39788\n","I0202 14:25:02.267903 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39788\n","INFO:tensorflow:loss = 4.65903, step = 60 (0.715 sec)\n","I0202 14:25:02.268200 140715376195456 basic_session_run_hooks.py:260] loss = 4.65903, step = 60 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.37412\n","I0202 14:25:02.995666 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37412\n","INFO:tensorflow:loss = 4.529235, step = 61 (0.728 sec)\n","I0202 14:25:02.996242 140715376195456 basic_session_run_hooks.py:260] loss = 4.529235, step = 61 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.40191\n","I0202 14:25:03.708956 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40191\n","INFO:tensorflow:loss = 5.3346686, step = 62 (0.713 sec)\n","I0202 14:25:03.709261 140715376195456 basic_session_run_hooks.py:260] loss = 5.3346686, step = 62 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.39012\n","I0202 14:25:04.428308 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39012\n","INFO:tensorflow:loss = 5.0826845, step = 63 (0.720 sec)\n","I0202 14:25:04.428810 140715376195456 basic_session_run_hooks.py:260] loss = 5.0826845, step = 63 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.3942\n","I0202 14:25:05.145618 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3942\n","INFO:tensorflow:loss = 4.4119124, step = 64 (0.717 sec)\n","I0202 14:25:05.145953 140715376195456 basic_session_run_hooks.py:260] loss = 4.4119124, step = 64 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.32855\n","I0202 14:25:05.898271 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32855\n","INFO:tensorflow:loss = 4.3172975, step = 65 (0.753 sec)\n","I0202 14:25:05.898600 140715376195456 basic_session_run_hooks.py:260] loss = 4.3172975, step = 65 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.31315\n","I0202 14:25:06.659802 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31315\n","INFO:tensorflow:loss = 4.853601, step = 66 (0.762 sec)\n","I0202 14:25:06.660107 140715376195456 basic_session_run_hooks.py:260] loss = 4.853601, step = 66 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 1.3168\n","I0202 14:25:07.419257 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3168\n","INFO:tensorflow:loss = 4.437555, step = 67 (0.759 sec)\n","I0202 14:25:07.419603 140715376195456 basic_session_run_hooks.py:260] loss = 4.437555, step = 67 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 1.36598\n","I0202 14:25:08.151283 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36598\n","INFO:tensorflow:loss = 4.0509977, step = 68 (0.732 sec)\n","I0202 14:25:08.151612 140715376195456 basic_session_run_hooks.py:260] loss = 4.0509977, step = 68 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.36377\n","I0202 14:25:08.884622 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36377\n","INFO:tensorflow:loss = 4.4002404, step = 69 (0.733 sec)\n","I0202 14:25:08.884941 140715376195456 basic_session_run_hooks.py:260] loss = 4.4002404, step = 69 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.33664\n","I0202 14:25:09.632726 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33664\n","INFO:tensorflow:loss = 4.0954833, step = 70 (0.748 sec)\n","I0202 14:25:09.633018 140715376195456 basic_session_run_hooks.py:260] loss = 4.0954833, step = 70 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.33073\n","I0202 14:25:10.384156 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33073\n","INFO:tensorflow:loss = 4.567801, step = 71 (0.751 sec)\n","I0202 14:25:10.384478 140715376195456 basic_session_run_hooks.py:260] loss = 4.567801, step = 71 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.37601\n","I0202 14:25:11.110894 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37601\n","INFO:tensorflow:loss = 4.423017, step = 72 (0.727 sec)\n","I0202 14:25:11.111397 140715376195456 basic_session_run_hooks.py:260] loss = 4.423017, step = 72 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.37531\n","I0202 14:25:11.838021 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37531\n","INFO:tensorflow:loss = 4.2247734, step = 73 (0.727 sec)\n","I0202 14:25:11.838360 140715376195456 basic_session_run_hooks.py:260] loss = 4.2247734, step = 73 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.35521\n","I0202 14:25:12.575897 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35521\n","INFO:tensorflow:loss = 4.4036236, step = 74 (0.738 sec)\n","I0202 14:25:12.576466 140715376195456 basic_session_run_hooks.py:260] loss = 4.4036236, step = 74 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.39492\n","I0202 14:25:13.292788 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39492\n","INFO:tensorflow:loss = 4.962307, step = 75 (0.717 sec)\n","I0202 14:25:13.293118 140715376195456 basic_session_run_hooks.py:260] loss = 4.962307, step = 75 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.39653\n","I0202 14:25:14.008858 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39653\n","INFO:tensorflow:loss = 4.528089, step = 76 (0.716 sec)\n","I0202 14:25:14.009159 140715376195456 basic_session_run_hooks.py:260] loss = 4.528089, step = 76 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.35936\n","I0202 14:25:14.744509 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35936\n","INFO:tensorflow:loss = 4.3323035, step = 77 (0.736 sec)\n","I0202 14:25:14.744813 140715376195456 basic_session_run_hooks.py:260] loss = 4.3323035, step = 77 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.35207\n","I0202 14:25:15.484093 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35207\n","INFO:tensorflow:loss = 3.9516017, step = 78 (0.740 sec)\n","I0202 14:25:15.484389 140715376195456 basic_session_run_hooks.py:260] loss = 3.9516017, step = 78 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.37638\n","I0202 14:25:16.210648 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37638\n","INFO:tensorflow:loss = 4.34644, step = 79 (0.727 sec)\n","I0202 14:25:16.210968 140715376195456 basic_session_run_hooks.py:260] loss = 4.34644, step = 79 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.40329\n","I0202 14:25:16.923263 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40329\n","INFO:tensorflow:loss = 4.7489023, step = 80 (0.713 sec)\n","I0202 14:25:16.923606 140715376195456 basic_session_run_hooks.py:260] loss = 4.7489023, step = 80 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.37966\n","I0202 14:25:17.648083 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37966\n","INFO:tensorflow:loss = 4.2272406, step = 81 (0.725 sec)\n","I0202 14:25:17.648383 140715376195456 basic_session_run_hooks.py:260] loss = 4.2272406, step = 81 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.41566\n","I0202 14:25:18.354457 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41566\n","INFO:tensorflow:loss = 3.8956053, step = 82 (0.706 sec)\n","I0202 14:25:18.354747 140715376195456 basic_session_run_hooks.py:260] loss = 3.8956053, step = 82 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.37848\n","I0202 14:25:19.079891 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37848\n","INFO:tensorflow:loss = 4.191948, step = 83 (0.726 sec)\n","I0202 14:25:19.080411 140715376195456 basic_session_run_hooks.py:260] loss = 4.191948, step = 83 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38397\n","I0202 14:25:19.802460 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38397\n","INFO:tensorflow:loss = 4.0944724, step = 84 (0.722 sec)\n","I0202 14:25:19.802770 140715376195456 basic_session_run_hooks.py:260] loss = 4.0944724, step = 84 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.37321\n","I0202 14:25:20.530672 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37321\n","INFO:tensorflow:loss = 3.758703, step = 85 (0.728 sec)\n","I0202 14:25:20.530986 140715376195456 basic_session_run_hooks.py:260] loss = 3.758703, step = 85 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.36757\n","I0202 14:25:21.261914 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36757\n","INFO:tensorflow:loss = 4.3674645, step = 86 (0.731 sec)\n","I0202 14:25:21.262212 140715376195456 basic_session_run_hooks.py:260] loss = 4.3674645, step = 86 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.34778\n","I0202 14:25:22.003857 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34778\n","INFO:tensorflow:loss = 3.8219125, step = 87 (0.742 sec)\n","I0202 14:25:22.004164 140715376195456 basic_session_run_hooks.py:260] loss = 3.8219125, step = 87 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.39019\n","I0202 14:25:22.723158 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39019\n","INFO:tensorflow:loss = 3.7900965, step = 88 (0.719 sec)\n","I0202 14:25:22.723457 140715376195456 basic_session_run_hooks.py:260] loss = 3.7900965, step = 88 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.41449\n","I0202 14:25:23.430134 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41449\n","INFO:tensorflow:loss = 4.202395, step = 89 (0.707 sec)\n","I0202 14:25:23.430457 140715376195456 basic_session_run_hooks.py:260] loss = 4.202395, step = 89 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 1.38784\n","I0202 14:25:24.150686 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38784\n","INFO:tensorflow:loss = 4.2116275, step = 90 (0.721 sec)\n","I0202 14:25:24.150985 140715376195456 basic_session_run_hooks.py:260] loss = 4.2116275, step = 90 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37408\n","I0202 14:25:24.878538 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37408\n","INFO:tensorflow:loss = 4.32388, step = 91 (0.728 sec)\n","I0202 14:25:24.878948 140715376195456 basic_session_run_hooks.py:260] loss = 4.32388, step = 91 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.3661\n","I0202 14:25:25.610463 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3661\n","INFO:tensorflow:loss = 3.9509873, step = 92 (0.732 sec)\n","I0202 14:25:25.610784 140715376195456 basic_session_run_hooks.py:260] loss = 3.9509873, step = 92 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.40283\n","I0202 14:25:26.323297 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40283\n","INFO:tensorflow:loss = 4.0464206, step = 93 (0.713 sec)\n","I0202 14:25:26.323606 140715376195456 basic_session_run_hooks.py:260] loss = 4.0464206, step = 93 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.3593\n","I0202 14:25:27.058990 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3593\n","INFO:tensorflow:loss = 4.147678, step = 94 (0.736 sec)\n","I0202 14:25:27.059304 140715376195456 basic_session_run_hooks.py:260] loss = 4.147678, step = 94 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.42008\n","I0202 14:25:27.763155 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42008\n","INFO:tensorflow:loss = 4.005101, step = 95 (0.704 sec)\n","I0202 14:25:27.763470 140715376195456 basic_session_run_hooks.py:260] loss = 4.005101, step = 95 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.40897\n","I0202 14:25:28.472898 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40897\n","INFO:tensorflow:loss = 4.263939, step = 96 (0.710 sec)\n","I0202 14:25:28.473191 140715376195456 basic_session_run_hooks.py:260] loss = 4.263939, step = 96 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.35054\n","I0202 14:25:29.213349 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35054\n","INFO:tensorflow:loss = 3.6476152, step = 97 (0.741 sec)\n","I0202 14:25:29.213909 140715376195456 basic_session_run_hooks.py:260] loss = 3.6476152, step = 97 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.38223\n","I0202 14:25:29.936851 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38223\n","INFO:tensorflow:loss = 3.7456424, step = 98 (0.723 sec)\n","I0202 14:25:29.937397 140715376195456 basic_session_run_hooks.py:260] loss = 3.7456424, step = 98 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.40153\n","I0202 14:25:30.650321 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40153\n","INFO:tensorflow:loss = 4.3988376, step = 99 (0.713 sec)\n","I0202 14:25:30.650898 140715376195456 basic_session_run_hooks.py:260] loss = 4.3988376, step = 99 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.34432\n","I0202 14:25:31.394176 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34432\n","INFO:tensorflow:loss = 3.5319388, step = 100 (0.744 sec)\n","I0202 14:25:31.395147 140715376195456 basic_session_run_hooks.py:260] loss = 3.5319388, step = 100 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.39419\n","I0202 14:25:32.111532 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39419\n","INFO:tensorflow:loss = 4.0390196, step = 101 (0.717 sec)\n","I0202 14:25:32.111923 140715376195456 basic_session_run_hooks.py:260] loss = 4.0390196, step = 101 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.35501\n","I0202 14:25:32.849474 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35501\n","INFO:tensorflow:loss = 3.5101688, step = 102 (0.738 sec)\n","I0202 14:25:32.849789 140715376195456 basic_session_run_hooks.py:260] loss = 3.5101688, step = 102 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.40962\n","I0202 14:25:33.558851 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40962\n","INFO:tensorflow:loss = 3.5201848, step = 103 (0.709 sec)\n","I0202 14:25:33.559162 140715376195456 basic_session_run_hooks.py:260] loss = 3.5201848, step = 103 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.35007\n","I0202 14:25:34.299589 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35007\n","INFO:tensorflow:loss = 3.54561, step = 104 (0.741 sec)\n","I0202 14:25:34.299912 140715376195456 basic_session_run_hooks.py:260] loss = 3.54561, step = 104 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.38396\n","I0202 14:25:35.022179 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38396\n","INFO:tensorflow:loss = 3.795339, step = 105 (0.723 sec)\n","I0202 14:25:35.022521 140715376195456 basic_session_run_hooks.py:260] loss = 3.795339, step = 105 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.3772\n","I0202 14:25:35.748240 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3772\n","INFO:tensorflow:loss = 3.870222, step = 106 (0.726 sec)\n","I0202 14:25:35.748600 140715376195456 basic_session_run_hooks.py:260] loss = 3.870222, step = 106 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.35137\n","I0202 14:25:36.488240 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35137\n","INFO:tensorflow:loss = 3.5812008, step = 107 (0.740 sec)\n","I0202 14:25:36.488573 140715376195456 basic_session_run_hooks.py:260] loss = 3.5812008, step = 107 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.39225\n","I0202 14:25:37.206506 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39225\n","INFO:tensorflow:loss = 3.7765822, step = 108 (0.718 sec)\n","I0202 14:25:37.206806 140715376195456 basic_session_run_hooks.py:260] loss = 3.7765822, step = 108 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.4323\n","I0202 14:25:37.904659 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4323\n","INFO:tensorflow:loss = 3.7110643, step = 109 (0.698 sec)\n","I0202 14:25:37.904961 140715376195456 basic_session_run_hooks.py:260] loss = 3.7110643, step = 109 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 1.37377\n","I0202 14:25:38.632601 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37377\n","INFO:tensorflow:loss = 4.0303884, step = 110 (0.728 sec)\n","I0202 14:25:38.632898 140715376195456 basic_session_run_hooks.py:260] loss = 4.0303884, step = 110 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.39115\n","I0202 14:25:39.351449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39115\n","INFO:tensorflow:loss = 3.3661523, step = 111 (0.719 sec)\n","I0202 14:25:39.351868 140715376195456 basic_session_run_hooks.py:260] loss = 3.3661523, step = 111 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.39654\n","I0202 14:25:40.067491 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39654\n","INFO:tensorflow:loss = 4.031725, step = 112 (0.716 sec)\n","I0202 14:25:40.067806 140715376195456 basic_session_run_hooks.py:260] loss = 4.031725, step = 112 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.36903\n","I0202 14:25:40.797914 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36903\n","INFO:tensorflow:loss = 4.256402, step = 113 (0.731 sec)\n","I0202 14:25:40.798355 140715376195456 basic_session_run_hooks.py:260] loss = 4.256402, step = 113 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37827\n","I0202 14:25:41.523469 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37827\n","INFO:tensorflow:loss = 3.9140434, step = 114 (0.725 sec)\n","I0202 14:25:41.523758 140715376195456 basic_session_run_hooks.py:260] loss = 3.9140434, step = 114 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.34272\n","I0202 14:25:42.268206 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34272\n","INFO:tensorflow:loss = 3.5458152, step = 115 (0.745 sec)\n","I0202 14:25:42.268644 140715376195456 basic_session_run_hooks.py:260] loss = 3.5458152, step = 115 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.33249\n","I0202 14:25:43.018708 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33249\n","INFO:tensorflow:loss = 3.6920586, step = 116 (0.750 sec)\n","I0202 14:25:43.019042 140715376195456 basic_session_run_hooks.py:260] loss = 3.6920586, step = 116 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.37116\n","I0202 14:25:43.748005 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37116\n","INFO:tensorflow:loss = 3.7290492, step = 117 (0.729 sec)\n","I0202 14:25:43.748443 140715376195456 basic_session_run_hooks.py:260] loss = 3.7290492, step = 117 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.32811\n","I0202 14:25:44.500943 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32811\n","INFO:tensorflow:loss = 3.84113, step = 118 (0.753 sec)\n","I0202 14:25:44.501248 140715376195456 basic_session_run_hooks.py:260] loss = 3.84113, step = 118 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.34807\n","I0202 14:25:45.242755 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34807\n","INFO:tensorflow:loss = 3.9870706, step = 119 (0.742 sec)\n","I0202 14:25:45.243058 140715376195456 basic_session_run_hooks.py:260] loss = 3.9870706, step = 119 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.32634\n","I0202 14:25:45.996716 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32634\n","INFO:tensorflow:loss = 3.847319, step = 120 (0.754 sec)\n","I0202 14:25:45.997166 140715376195456 basic_session_run_hooks.py:260] loss = 3.847319, step = 120 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.35737\n","I0202 14:25:46.733441 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35737\n","INFO:tensorflow:loss = 3.8464136, step = 121 (0.737 sec)\n","I0202 14:25:46.733761 140715376195456 basic_session_run_hooks.py:260] loss = 3.8464136, step = 121 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.35503\n","I0202 14:25:47.471411 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35503\n","INFO:tensorflow:loss = 3.4769597, step = 122 (0.738 sec)\n","I0202 14:25:47.471862 140715376195456 basic_session_run_hooks.py:260] loss = 3.4769597, step = 122 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.34364\n","I0202 14:25:48.215654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34364\n","INFO:tensorflow:loss = 3.5979962, step = 123 (0.744 sec)\n","I0202 14:25:48.215958 140715376195456 basic_session_run_hooks.py:260] loss = 3.5979962, step = 123 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.42053\n","I0202 14:25:48.919630 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42053\n","INFO:tensorflow:loss = 4.02851, step = 124 (0.704 sec)\n","I0202 14:25:48.920055 140715376195456 basic_session_run_hooks.py:260] loss = 4.02851, step = 124 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.40096\n","I0202 14:25:49.633446 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40096\n","INFO:tensorflow:loss = 3.3549776, step = 125 (0.714 sec)\n","I0202 14:25:49.633756 140715376195456 basic_session_run_hooks.py:260] loss = 3.3549776, step = 125 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.38896\n","I0202 14:25:50.353390 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38896\n","INFO:tensorflow:loss = 3.7508583, step = 126 (0.720 sec)\n","I0202 14:25:50.353743 140715376195456 basic_session_run_hooks.py:260] loss = 3.7508583, step = 126 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.37048\n","I0202 14:25:51.083064 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37048\n","INFO:tensorflow:loss = 3.715406, step = 127 (0.730 sec)\n","I0202 14:25:51.083365 140715376195456 basic_session_run_hooks.py:260] loss = 3.715406, step = 127 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.3751\n","I0202 14:25:51.810303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3751\n","INFO:tensorflow:loss = 3.3485603, step = 128 (0.727 sec)\n","I0202 14:25:51.810653 140715376195456 basic_session_run_hooks.py:260] loss = 3.3485603, step = 128 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.36509\n","I0202 14:25:52.542826 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36509\n","INFO:tensorflow:loss = 4.1714926, step = 129 (0.732 sec)\n","I0202 14:25:52.543129 140715376195456 basic_session_run_hooks.py:260] loss = 4.1714926, step = 129 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39507\n","I0202 14:25:53.259650 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39507\n","INFO:tensorflow:loss = 3.2775297, step = 130 (0.717 sec)\n","I0202 14:25:53.259950 140715376195456 basic_session_run_hooks.py:260] loss = 3.2775297, step = 130 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.39226\n","I0202 14:25:53.977889 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39226\n","INFO:tensorflow:loss = 3.7693462, step = 131 (0.718 sec)\n","I0202 14:25:53.978211 140715376195456 basic_session_run_hooks.py:260] loss = 3.7693462, step = 131 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.37292\n","I0202 14:25:54.706263 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37292\n","INFO:tensorflow:loss = 3.5365047, step = 132 (0.728 sec)\n","I0202 14:25:54.706578 140715376195456 basic_session_run_hooks.py:260] loss = 3.5365047, step = 132 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.3929\n","I0202 14:25:55.424196 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3929\n","INFO:tensorflow:loss = 3.859636, step = 133 (0.718 sec)\n","I0202 14:25:55.424519 140715376195456 basic_session_run_hooks.py:260] loss = 3.859636, step = 133 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.33642\n","I0202 14:25:56.172485 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33642\n","INFO:tensorflow:loss = 3.336136, step = 134 (0.748 sec)\n","I0202 14:25:56.172789 140715376195456 basic_session_run_hooks.py:260] loss = 3.336136, step = 134 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.35984\n","I0202 14:25:56.907850 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35984\n","INFO:tensorflow:loss = 3.6122813, step = 135 (0.735 sec)\n","I0202 14:25:56.908156 140715376195456 basic_session_run_hooks.py:260] loss = 3.6122813, step = 135 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.36614\n","I0202 14:25:57.639827 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36614\n","INFO:tensorflow:loss = 3.7535617, step = 136 (0.732 sec)\n","I0202 14:25:57.640141 140715376195456 basic_session_run_hooks.py:260] loss = 3.7535617, step = 136 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.34949\n","I0202 14:25:58.380849 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34949\n","INFO:tensorflow:loss = 3.6690254, step = 137 (0.741 sec)\n","I0202 14:25:58.381149 140715376195456 basic_session_run_hooks.py:260] loss = 3.6690254, step = 137 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.37246\n","I0202 14:25:59.109480 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37246\n","INFO:tensorflow:loss = 3.3600419, step = 138 (0.729 sec)\n","I0202 14:25:59.109774 140715376195456 basic_session_run_hooks.py:260] loss = 3.3600419, step = 138 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.41698\n","I0202 14:25:59.815192 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41698\n","INFO:tensorflow:loss = 4.0759015, step = 139 (0.706 sec)\n","I0202 14:25:59.815495 140715376195456 basic_session_run_hooks.py:260] loss = 4.0759015, step = 139 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.37926\n","I0202 14:26:00.540222 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37926\n","INFO:tensorflow:loss = 3.1251285, step = 140 (0.725 sec)\n","I0202 14:26:00.540540 140715376195456 basic_session_run_hooks.py:260] loss = 3.1251285, step = 140 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36914\n","I0202 14:26:01.270608 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36914\n","INFO:tensorflow:loss = 3.5302093, step = 141 (0.730 sec)\n","I0202 14:26:01.270912 140715376195456 basic_session_run_hooks.py:260] loss = 3.5302093, step = 141 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.35351\n","I0202 14:26:02.009461 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35351\n","INFO:tensorflow:loss = 3.6394026, step = 142 (0.739 sec)\n","I0202 14:26:02.009790 140715376195456 basic_session_run_hooks.py:260] loss = 3.6394026, step = 142 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.34036\n","I0202 14:26:02.755523 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34036\n","INFO:tensorflow:loss = 3.456467, step = 143 (0.746 sec)\n","I0202 14:26:02.755837 140715376195456 basic_session_run_hooks.py:260] loss = 3.456467, step = 143 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.34603\n","I0202 14:26:03.498434 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34603\n","INFO:tensorflow:loss = 3.178976, step = 144 (0.743 sec)\n","I0202 14:26:03.498863 140715376195456 basic_session_run_hooks.py:260] loss = 3.178976, step = 144 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.41623\n","I0202 14:26:04.204541 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41623\n","INFO:tensorflow:loss = 3.4364233, step = 145 (0.706 sec)\n","I0202 14:26:04.204835 140715376195456 basic_session_run_hooks.py:260] loss = 3.4364233, step = 145 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.36433\n","I0202 14:26:04.937504 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36433\n","INFO:tensorflow:loss = 3.657171, step = 146 (0.733 sec)\n","I0202 14:26:04.937793 140715376195456 basic_session_run_hooks.py:260] loss = 3.657171, step = 146 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.38093\n","I0202 14:26:05.661658 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38093\n","INFO:tensorflow:loss = 3.3677998, step = 147 (0.724 sec)\n","I0202 14:26:05.662003 140715376195456 basic_session_run_hooks.py:260] loss = 3.3677998, step = 147 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.38524\n","I0202 14:26:06.383562 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38524\n","INFO:tensorflow:loss = 3.065253, step = 148 (0.722 sec)\n","I0202 14:26:06.383861 140715376195456 basic_session_run_hooks.py:260] loss = 3.065253, step = 148 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36373\n","I0202 14:26:07.116813 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36373\n","INFO:tensorflow:loss = 4.0917597, step = 149 (0.733 sec)\n","I0202 14:26:07.117224 140715376195456 basic_session_run_hooks.py:260] loss = 4.0917597, step = 149 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.34705\n","I0202 14:26:07.859178 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34705\n","INFO:tensorflow:loss = 3.1994312, step = 150 (0.742 sec)\n","I0202 14:26:07.859618 140715376195456 basic_session_run_hooks.py:260] loss = 3.1994312, step = 150 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.38135\n","I0202 14:26:08.583132 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38135\n","INFO:tensorflow:loss = 3.523146, step = 151 (0.724 sec)\n","I0202 14:26:08.583495 140715376195456 basic_session_run_hooks.py:260] loss = 3.523146, step = 151 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.36081\n","I0202 14:26:09.317999 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36081\n","INFO:tensorflow:loss = 3.4745595, step = 152 (0.735 sec)\n","I0202 14:26:09.318302 140715376195456 basic_session_run_hooks.py:260] loss = 3.4745595, step = 152 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.43046\n","I0202 14:26:10.017096 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43046\n","INFO:tensorflow:loss = 3.7541292, step = 153 (0.699 sec)\n","I0202 14:26:10.017624 140715376195456 basic_session_run_hooks.py:260] loss = 3.7541292, step = 153 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 1.3784\n","I0202 14:26:10.742547 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3784\n","INFO:tensorflow:loss = 3.588964, step = 154 (0.725 sec)\n","I0202 14:26:10.742998 140715376195456 basic_session_run_hooks.py:260] loss = 3.588964, step = 154 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36571\n","I0202 14:26:11.474755 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36571\n","INFO:tensorflow:loss = 3.4016666, step = 155 (0.732 sec)\n","I0202 14:26:11.475059 140715376195456 basic_session_run_hooks.py:260] loss = 3.4016666, step = 155 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.38426\n","I0202 14:26:12.197167 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38426\n","INFO:tensorflow:loss = 3.5571077, step = 156 (0.723 sec)\n","I0202 14:26:12.197592 140715376195456 basic_session_run_hooks.py:260] loss = 3.5571077, step = 156 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.40277\n","I0202 14:26:12.910035 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40277\n","INFO:tensorflow:loss = 3.0344832, step = 157 (0.713 sec)\n","I0202 14:26:12.910465 140715376195456 basic_session_run_hooks.py:260] loss = 3.0344832, step = 157 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.36384\n","I0202 14:26:13.643281 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36384\n","INFO:tensorflow:loss = 3.4451745, step = 158 (0.733 sec)\n","I0202 14:26:13.643733 140715376195456 basic_session_run_hooks.py:260] loss = 3.4451745, step = 158 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36398\n","I0202 14:26:14.376430 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36398\n","INFO:tensorflow:loss = 3.4506993, step = 159 (0.733 sec)\n","I0202 14:26:14.376742 140715376195456 basic_session_run_hooks.py:260] loss = 3.4506993, step = 159 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.3815\n","I0202 14:26:15.100264 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3815\n","INFO:tensorflow:loss = 3.5478005, step = 160 (0.724 sec)\n","I0202 14:26:15.100713 140715376195456 basic_session_run_hooks.py:260] loss = 3.5478005, step = 160 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.41826\n","I0202 14:26:15.805357 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41826\n","INFO:tensorflow:loss = 2.9414587, step = 161 (0.705 sec)\n","I0202 14:26:15.805829 140715376195456 basic_session_run_hooks.py:260] loss = 2.9414587, step = 161 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.36517\n","I0202 14:26:16.537864 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36517\n","INFO:tensorflow:loss = 3.3094902, step = 162 (0.732 sec)\n","I0202 14:26:16.538166 140715376195456 basic_session_run_hooks.py:260] loss = 3.3094902, step = 162 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.35776\n","I0202 14:26:17.274383 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35776\n","INFO:tensorflow:loss = 3.0877407, step = 163 (0.737 sec)\n","I0202 14:26:17.274889 140715376195456 basic_session_run_hooks.py:260] loss = 3.0877407, step = 163 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37733\n","I0202 14:26:18.000447 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37733\n","INFO:tensorflow:loss = 3.3356364, step = 164 (0.726 sec)\n","I0202 14:26:18.000802 140715376195456 basic_session_run_hooks.py:260] loss = 3.3356364, step = 164 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.42106\n","I0202 14:26:18.704094 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42106\n","INFO:tensorflow:loss = 3.0560443, step = 165 (0.704 sec)\n","I0202 14:26:18.704398 140715376195456 basic_session_run_hooks.py:260] loss = 3.0560443, step = 165 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.36626\n","I0202 14:26:19.436046 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36626\n","INFO:tensorflow:loss = 3.3084595, step = 166 (0.732 sec)\n","I0202 14:26:19.436387 140715376195456 basic_session_run_hooks.py:260] loss = 3.3084595, step = 166 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.40221\n","I0202 14:26:20.149186 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40221\n","INFO:tensorflow:loss = 3.5851564, step = 167 (0.713 sec)\n","I0202 14:26:20.149667 140715376195456 basic_session_run_hooks.py:260] loss = 3.5851564, step = 167 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.36709\n","I0202 14:26:20.880665 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36709\n","INFO:tensorflow:loss = 2.9819932, step = 168 (0.731 sec)\n","I0202 14:26:20.881000 140715376195456 basic_session_run_hooks.py:260] loss = 2.9819932, step = 168 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.35283\n","I0202 14:26:21.619867 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35283\n","INFO:tensorflow:loss = 3.3908772, step = 169 (0.739 sec)\n","I0202 14:26:21.620316 140715376195456 basic_session_run_hooks.py:260] loss = 3.3908772, step = 169 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.32356\n","I0202 14:26:22.375400 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32356\n","INFO:tensorflow:loss = 3.2937117, step = 170 (0.756 sec)\n","I0202 14:26:22.375832 140715376195456 basic_session_run_hooks.py:260] loss = 3.2937117, step = 170 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.32393\n","I0202 14:26:23.130740 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32393\n","INFO:tensorflow:loss = 3.4354753, step = 171 (0.755 sec)\n","I0202 14:26:23.131196 140715376195456 basic_session_run_hooks.py:260] loss = 3.4354753, step = 171 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.34357\n","I0202 14:26:23.874997 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34357\n","INFO:tensorflow:loss = 3.1631348, step = 172 (0.744 sec)\n","I0202 14:26:23.875303 140715376195456 basic_session_run_hooks.py:260] loss = 3.1631348, step = 172 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.38734\n","I0202 14:26:24.595807 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38734\n","INFO:tensorflow:loss = 3.5370493, step = 173 (0.721 sec)\n","I0202 14:26:24.596266 140715376195456 basic_session_run_hooks.py:260] loss = 3.5370493, step = 173 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.36134\n","I0202 14:26:25.330375 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36134\n","INFO:tensorflow:loss = 4.0894656, step = 174 (0.734 sec)\n","I0202 14:26:25.330695 140715376195456 basic_session_run_hooks.py:260] loss = 4.0894656, step = 174 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.44178\n","I0202 14:26:26.023962 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.44178\n","INFO:tensorflow:loss = 3.6082416, step = 175 (0.694 sec)\n","I0202 14:26:26.024402 140715376195456 basic_session_run_hooks.py:260] loss = 3.6082416, step = 175 (0.694 sec)\n","INFO:tensorflow:global_step/sec: 1.37641\n","I0202 14:26:26.750519 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37641\n","INFO:tensorflow:loss = 3.1581998, step = 176 (0.726 sec)\n","I0202 14:26:26.750826 140715376195456 basic_session_run_hooks.py:260] loss = 3.1581998, step = 176 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.34442\n","I0202 14:26:27.494327 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34442\n","INFO:tensorflow:loss = 3.2793403, step = 177 (0.744 sec)\n","I0202 14:26:27.494751 140715376195456 basic_session_run_hooks.py:260] loss = 3.2793403, step = 177 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.362\n","I0202 14:26:28.228549 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.362\n","INFO:tensorflow:loss = 3.11168, step = 178 (0.734 sec)\n","I0202 14:26:28.228890 140715376195456 basic_session_run_hooks.py:260] loss = 3.11168, step = 178 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.3907\n","I0202 14:26:28.947617 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3907\n","INFO:tensorflow:loss = 3.2770543, step = 179 (0.719 sec)\n","I0202 14:26:28.947934 140715376195456 basic_session_run_hooks.py:260] loss = 3.2770543, step = 179 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.40721\n","I0202 14:26:29.658223 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40721\n","INFO:tensorflow:loss = 3.7642748, step = 180 (0.711 sec)\n","I0202 14:26:29.658667 140715376195456 basic_session_run_hooks.py:260] loss = 3.7642748, step = 180 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.34476\n","I0202 14:26:30.401845 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34476\n","INFO:tensorflow:loss = 3.5482883, step = 181 (0.743 sec)\n","I0202 14:26:30.402136 140715376195456 basic_session_run_hooks.py:260] loss = 3.5482883, step = 181 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.39528\n","I0202 14:26:31.118601 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39528\n","INFO:tensorflow:loss = 2.991132, step = 182 (0.717 sec)\n","I0202 14:26:31.119033 140715376195456 basic_session_run_hooks.py:260] loss = 2.991132, step = 182 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.32722\n","I0202 14:26:31.872001 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32722\n","INFO:tensorflow:loss = 3.2772553, step = 183 (0.753 sec)\n","I0202 14:26:31.872316 140715376195456 basic_session_run_hooks.py:260] loss = 3.2772553, step = 183 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.31021\n","I0202 14:26:32.635234 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31021\n","INFO:tensorflow:loss = 2.889566, step = 184 (0.763 sec)\n","I0202 14:26:32.635682 140715376195456 basic_session_run_hooks.py:260] loss = 2.889566, step = 184 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 1.40184\n","I0202 14:26:33.348672 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40184\n","INFO:tensorflow:loss = 2.9355266, step = 185 (0.713 sec)\n","I0202 14:26:33.349128 140715376195456 basic_session_run_hooks.py:260] loss = 2.9355266, step = 185 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.38636\n","I0202 14:26:34.069930 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38636\n","INFO:tensorflow:loss = 3.6775577, step = 186 (0.721 sec)\n","I0202 14:26:34.070405 140715376195456 basic_session_run_hooks.py:260] loss = 3.6775577, step = 186 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37424\n","I0202 14:26:34.797596 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37424\n","INFO:tensorflow:loss = 3.3049672, step = 187 (0.728 sec)\n","I0202 14:26:34.798014 140715376195456 basic_session_run_hooks.py:260] loss = 3.3049672, step = 187 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.3861\n","I0202 14:26:35.519019 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3861\n","INFO:tensorflow:loss = 3.3326643, step = 188 (0.721 sec)\n","I0202 14:26:35.519451 140715376195456 basic_session_run_hooks.py:260] loss = 3.3326643, step = 188 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37902\n","I0202 14:26:36.244200 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37902\n","INFO:tensorflow:loss = 3.3173172, step = 189 (0.725 sec)\n","I0202 14:26:36.244656 140715376195456 basic_session_run_hooks.py:260] loss = 3.3173172, step = 189 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.38567\n","I0202 14:26:36.965849 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38567\n","INFO:tensorflow:loss = 3.59011, step = 190 (0.722 sec)\n","I0202 14:26:36.966395 140715376195456 basic_session_run_hooks.py:260] loss = 3.59011, step = 190 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36627\n","I0202 14:26:37.697781 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36627\n","INFO:tensorflow:loss = 3.0862389, step = 191 (0.732 sec)\n","I0202 14:26:37.698123 140715376195456 basic_session_run_hooks.py:260] loss = 3.0862389, step = 191 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.37669\n","I0202 14:26:38.424144 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37669\n","INFO:tensorflow:loss = 3.3417256, step = 192 (0.727 sec)\n","I0202 14:26:38.424642 140715376195456 basic_session_run_hooks.py:260] loss = 3.3417256, step = 192 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.37166\n","I0202 14:26:39.153201 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37166\n","INFO:tensorflow:loss = 3.324887, step = 193 (0.729 sec)\n","I0202 14:26:39.153690 140715376195456 basic_session_run_hooks.py:260] loss = 3.324887, step = 193 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.38841\n","I0202 14:26:39.873454 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38841\n","INFO:tensorflow:loss = 3.514109, step = 194 (0.720 sec)\n","I0202 14:26:39.873912 140715376195456 basic_session_run_hooks.py:260] loss = 3.514109, step = 194 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.40026\n","I0202 14:26:40.587622 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40026\n","INFO:tensorflow:loss = 2.8297327, step = 195 (0.714 sec)\n","I0202 14:26:40.587931 140715376195456 basic_session_run_hooks.py:260] loss = 2.8297327, step = 195 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.37869\n","I0202 14:26:41.312913 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37869\n","INFO:tensorflow:loss = 3.3546958, step = 196 (0.725 sec)\n","I0202 14:26:41.313386 140715376195456 basic_session_run_hooks.py:260] loss = 3.3546958, step = 196 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39515\n","I0202 14:26:42.029709 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39515\n","INFO:tensorflow:loss = 3.115731, step = 197 (0.717 sec)\n","I0202 14:26:42.030212 140715376195456 basic_session_run_hooks.py:260] loss = 3.115731, step = 197 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.3656\n","I0202 14:26:42.762002 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3656\n","INFO:tensorflow:loss = 3.0315852, step = 198 (0.732 sec)\n","I0202 14:26:42.762353 140715376195456 basic_session_run_hooks.py:260] loss = 3.0315852, step = 198 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39576\n","I0202 14:26:43.478465 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39576\n","INFO:tensorflow:loss = 3.5129218, step = 199 (0.717 sec)\n","I0202 14:26:43.478937 140715376195456 basic_session_run_hooks.py:260] loss = 3.5129218, step = 199 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.39454\n","I0202 14:26:44.195534 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39454\n","INFO:tensorflow:loss = 3.1550887, step = 200 (0.718 sec)\n","I0202 14:26:44.196529 140715376195456 basic_session_run_hooks.py:260] loss = 3.1550887, step = 200 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.43074\n","I0202 14:26:44.894488 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43074\n","INFO:tensorflow:loss = 3.1733365, step = 201 (0.699 sec)\n","I0202 14:26:44.895072 140715376195456 basic_session_run_hooks.py:260] loss = 3.1733365, step = 201 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 1.38626\n","I0202 14:26:45.615802 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38626\n","INFO:tensorflow:loss = 2.8774886, step = 202 (0.721 sec)\n","I0202 14:26:45.616220 140715376195456 basic_session_run_hooks.py:260] loss = 2.8774886, step = 202 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.33887\n","I0202 14:26:46.362698 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33887\n","INFO:tensorflow:loss = 2.8311734, step = 203 (0.747 sec)\n","I0202 14:26:46.363124 140715376195456 basic_session_run_hooks.py:260] loss = 2.8311734, step = 203 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.36363\n","I0202 14:26:47.096040 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36363\n","INFO:tensorflow:loss = 3.065273, step = 204 (0.733 sec)\n","I0202 14:26:47.096334 140715376195456 basic_session_run_hooks.py:260] loss = 3.065273, step = 204 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.39714\n","I0202 14:26:47.811817 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39714\n","INFO:tensorflow:loss = 3.243751, step = 205 (0.716 sec)\n","I0202 14:26:47.812281 140715376195456 basic_session_run_hooks.py:260] loss = 3.243751, step = 205 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.36479\n","I0202 14:26:48.544534 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36479\n","INFO:tensorflow:loss = 3.5530367, step = 206 (0.733 sec)\n","I0202 14:26:48.545006 140715376195456 basic_session_run_hooks.py:260] loss = 3.5530367, step = 206 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.35285\n","I0202 14:26:49.283671 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35285\n","INFO:tensorflow:loss = 3.184478, step = 207 (0.739 sec)\n","I0202 14:26:49.284080 140715376195456 basic_session_run_hooks.py:260] loss = 3.184478, step = 207 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.39421\n","I0202 14:26:50.000961 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39421\n","INFO:tensorflow:loss = 3.4736958, step = 208 (0.717 sec)\n","I0202 14:26:50.001271 140715376195456 basic_session_run_hooks.py:260] loss = 3.4736958, step = 208 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.38367\n","I0202 14:26:50.723638 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38367\n","INFO:tensorflow:loss = 2.916335, step = 209 (0.723 sec)\n","I0202 14:26:50.723941 140715376195456 basic_session_run_hooks.py:260] loss = 2.916335, step = 209 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.35554\n","I0202 14:26:51.461362 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35554\n","INFO:tensorflow:loss = 3.0958636, step = 210 (0.738 sec)\n","I0202 14:26:51.461798 140715376195456 basic_session_run_hooks.py:260] loss = 3.0958636, step = 210 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.36614\n","I0202 14:26:52.193369 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36614\n","INFO:tensorflow:loss = 2.9248836, step = 211 (0.732 sec)\n","I0202 14:26:52.193818 140715376195456 basic_session_run_hooks.py:260] loss = 2.9248836, step = 211 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.40676\n","I0202 14:26:52.904217 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40676\n","INFO:tensorflow:loss = 2.9176707, step = 212 (0.711 sec)\n","I0202 14:26:52.904695 140715376195456 basic_session_run_hooks.py:260] loss = 2.9176707, step = 212 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.40697\n","I0202 14:26:53.614954 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40697\n","INFO:tensorflow:loss = 2.8933258, step = 213 (0.711 sec)\n","I0202 14:26:53.615405 140715376195456 basic_session_run_hooks.py:260] loss = 2.8933258, step = 213 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.38123\n","I0202 14:26:54.338943 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38123\n","INFO:tensorflow:loss = 2.8863063, step = 214 (0.724 sec)\n","I0202 14:26:54.339247 140715376195456 basic_session_run_hooks.py:260] loss = 2.8863063, step = 214 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.38394\n","I0202 14:26:55.061540 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38394\n","INFO:tensorflow:loss = 3.2889798, step = 215 (0.723 sec)\n","I0202 14:26:55.061885 140715376195456 basic_session_run_hooks.py:260] loss = 3.2889798, step = 215 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37855\n","I0202 14:26:55.786966 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37855\n","INFO:tensorflow:loss = 2.9601955, step = 216 (0.725 sec)\n","I0202 14:26:55.787283 140715376195456 basic_session_run_hooks.py:260] loss = 2.9601955, step = 216 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.31513\n","I0202 14:26:56.547317 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31513\n","INFO:tensorflow:loss = 3.5824137, step = 217 (0.760 sec)\n","I0202 14:26:56.547768 140715376195456 basic_session_run_hooks.py:260] loss = 3.5824137, step = 217 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 1.32878\n","I0202 14:26:57.299866 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32878\n","INFO:tensorflow:loss = 3.714269, step = 218 (0.753 sec)\n","I0202 14:26:57.300359 140715376195456 basic_session_run_hooks.py:260] loss = 3.714269, step = 218 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.3441\n","I0202 14:26:58.043855 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3441\n","INFO:tensorflow:loss = 3.4120302, step = 219 (0.744 sec)\n","I0202 14:26:58.044267 140715376195456 basic_session_run_hooks.py:260] loss = 3.4120302, step = 219 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.37665\n","I0202 14:26:58.770281 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37665\n","INFO:tensorflow:loss = 2.8918736, step = 220 (0.726 sec)\n","I0202 14:26:58.770608 140715376195456 basic_session_run_hooks.py:260] loss = 2.8918736, step = 220 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.31779\n","I0202 14:26:59.529160 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31779\n","INFO:tensorflow:loss = 2.862329, step = 221 (0.759 sec)\n","I0202 14:26:59.529605 140715376195456 basic_session_run_hooks.py:260] loss = 2.862329, step = 221 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 1.35167\n","I0202 14:27:00.268927 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35167\n","INFO:tensorflow:loss = 3.19838, step = 222 (0.740 sec)\n","I0202 14:27:00.269239 140715376195456 basic_session_run_hooks.py:260] loss = 3.19838, step = 222 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36511\n","I0202 14:27:01.001510 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36511\n","INFO:tensorflow:loss = 3.3418636, step = 223 (0.733 sec)\n","I0202 14:27:01.001811 140715376195456 basic_session_run_hooks.py:260] loss = 3.3418636, step = 223 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.37136\n","I0202 14:27:01.730673 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37136\n","INFO:tensorflow:loss = 3.3497357, step = 224 (0.729 sec)\n","I0202 14:27:01.730980 140715376195456 basic_session_run_hooks.py:260] loss = 3.3497357, step = 224 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.35914\n","I0202 14:27:02.466463 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35914\n","INFO:tensorflow:loss = 3.265897, step = 225 (0.736 sec)\n","I0202 14:27:02.466800 140715376195456 basic_session_run_hooks.py:260] loss = 3.265897, step = 225 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.36224\n","I0202 14:27:03.200572 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36224\n","INFO:tensorflow:loss = 3.3848946, step = 226 (0.734 sec)\n","I0202 14:27:03.201010 140715376195456 basic_session_run_hooks.py:260] loss = 3.3848946, step = 226 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.39082\n","I0202 14:27:03.919552 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39082\n","INFO:tensorflow:loss = 3.3243093, step = 227 (0.719 sec)\n","I0202 14:27:03.919970 140715376195456 basic_session_run_hooks.py:260] loss = 3.3243093, step = 227 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.38441\n","I0202 14:27:04.641840 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38441\n","INFO:tensorflow:loss = 2.9212635, step = 228 (0.722 sec)\n","I0202 14:27:04.642129 140715376195456 basic_session_run_hooks.py:260] loss = 2.9212635, step = 228 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36055\n","I0202 14:27:05.376860 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36055\n","INFO:tensorflow:loss = 3.1837752, step = 229 (0.735 sec)\n","I0202 14:27:05.377275 140715376195456 basic_session_run_hooks.py:260] loss = 3.1837752, step = 229 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.42806\n","I0202 14:27:06.077099 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42806\n","INFO:tensorflow:loss = 3.2679155, step = 230 (0.700 sec)\n","I0202 14:27:06.077396 140715376195456 basic_session_run_hooks.py:260] loss = 3.2679155, step = 230 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.37672\n","I0202 14:27:06.803492 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37672\n","INFO:tensorflow:loss = 3.7038317, step = 231 (0.726 sec)\n","I0202 14:27:06.803799 140715376195456 basic_session_run_hooks.py:260] loss = 3.7038317, step = 231 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.3737\n","I0202 14:27:07.531452 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3737\n","INFO:tensorflow:loss = 3.3272877, step = 232 (0.728 sec)\n","I0202 14:27:07.531910 140715376195456 basic_session_run_hooks.py:260] loss = 3.3272877, step = 232 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.38647\n","I0202 14:27:08.252694 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38647\n","INFO:tensorflow:loss = 3.4424508, step = 233 (0.721 sec)\n","I0202 14:27:08.253123 140715376195456 basic_session_run_hooks.py:260] loss = 3.4424508, step = 233 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.39404\n","I0202 14:27:08.970030 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39404\n","INFO:tensorflow:loss = 3.0355496, step = 234 (0.717 sec)\n","I0202 14:27:08.970379 140715376195456 basic_session_run_hooks.py:260] loss = 3.0355496, step = 234 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.378\n","I0202 14:27:09.695750 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.378\n","INFO:tensorflow:loss = 2.778337, step = 235 (0.726 sec)\n","I0202 14:27:09.696124 140715376195456 basic_session_run_hooks.py:260] loss = 2.778337, step = 235 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.33286\n","I0202 14:27:10.445975 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33286\n","INFO:tensorflow:loss = 3.2072444, step = 236 (0.750 sec)\n","I0202 14:27:10.446449 140715376195456 basic_session_run_hooks.py:260] loss = 3.2072444, step = 236 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.40532\n","I0202 14:27:11.157640 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40532\n","INFO:tensorflow:loss = 2.803085, step = 237 (0.712 sec)\n","I0202 14:27:11.157970 140715376195456 basic_session_run_hooks.py:260] loss = 2.803085, step = 237 (0.712 sec)\n","INFO:tensorflow:global_step/sec: 1.36902\n","I0202 14:27:11.888006 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36902\n","INFO:tensorflow:loss = 3.2264366, step = 238 (0.730 sec)\n","I0202 14:27:11.888430 140715376195456 basic_session_run_hooks.py:260] loss = 3.2264366, step = 238 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.37119\n","I0202 14:27:12.617303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37119\n","INFO:tensorflow:loss = 2.9809952, step = 239 (0.729 sec)\n","I0202 14:27:12.617736 140715376195456 basic_session_run_hooks.py:260] loss = 2.9809952, step = 239 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.37886\n","I0202 14:27:13.342552 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37886\n","INFO:tensorflow:loss = 2.8638813, step = 240 (0.725 sec)\n","I0202 14:27:13.342847 140715376195456 basic_session_run_hooks.py:260] loss = 2.8638813, step = 240 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39025\n","I0202 14:27:14.061832 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39025\n","INFO:tensorflow:loss = 3.4733875, step = 241 (0.719 sec)\n","I0202 14:27:14.062249 140715376195456 basic_session_run_hooks.py:260] loss = 3.4733875, step = 241 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.3897\n","I0202 14:27:14.781408 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3897\n","INFO:tensorflow:loss = 3.4150105, step = 242 (0.719 sec)\n","I0202 14:27:14.781732 140715376195456 basic_session_run_hooks.py:260] loss = 3.4150105, step = 242 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.36089\n","I0202 14:27:15.516224 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36089\n","INFO:tensorflow:loss = 3.203769, step = 243 (0.735 sec)\n","I0202 14:27:15.516713 140715376195456 basic_session_run_hooks.py:260] loss = 3.203769, step = 243 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.37441\n","I0202 14:27:16.243822 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37441\n","INFO:tensorflow:loss = 3.4766881, step = 244 (0.727 sec)\n","I0202 14:27:16.244116 140715376195456 basic_session_run_hooks.py:260] loss = 3.4766881, step = 244 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.40674\n","I0202 14:27:16.954681 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40674\n","INFO:tensorflow:loss = 2.8638313, step = 245 (0.711 sec)\n","I0202 14:27:16.955115 140715376195456 basic_session_run_hooks.py:260] loss = 2.8638313, step = 245 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.36463\n","I0202 14:27:17.687474 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36463\n","INFO:tensorflow:loss = 2.7624364, step = 246 (0.733 sec)\n","I0202 14:27:17.687937 140715376195456 basic_session_run_hooks.py:260] loss = 2.7624364, step = 246 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36946\n","I0202 14:27:18.417706 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36946\n","INFO:tensorflow:loss = 3.4176676, step = 247 (0.730 sec)\n","I0202 14:27:18.418133 140715376195456 basic_session_run_hooks.py:260] loss = 3.4176676, step = 247 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.37978\n","I0202 14:27:19.142460 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37978\n","INFO:tensorflow:loss = 2.788922, step = 248 (0.725 sec)\n","I0202 14:27:19.142760 140715376195456 basic_session_run_hooks.py:260] loss = 2.788922, step = 248 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.32441\n","I0202 14:27:19.897532 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32441\n","INFO:tensorflow:loss = 2.7137723, step = 249 (0.755 sec)\n","I0202 14:27:19.897979 140715376195456 basic_session_run_hooks.py:260] loss = 2.7137723, step = 249 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.38231\n","I0202 14:27:20.620920 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38231\n","INFO:tensorflow:loss = 3.0887027, step = 250 (0.723 sec)\n","I0202 14:27:20.621218 140715376195456 basic_session_run_hooks.py:260] loss = 3.0887027, step = 250 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.39699\n","I0202 14:27:21.336738 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39699\n","INFO:tensorflow:loss = 2.8487887, step = 251 (0.716 sec)\n","I0202 14:27:21.337102 140715376195456 basic_session_run_hooks.py:260] loss = 2.8487887, step = 251 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.38778\n","I0202 14:27:22.057338 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38778\n","INFO:tensorflow:loss = 2.826652, step = 252 (0.721 sec)\n","I0202 14:27:22.057814 140715376195456 basic_session_run_hooks.py:260] loss = 2.826652, step = 252 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.36242\n","I0202 14:27:22.791316 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36242\n","INFO:tensorflow:loss = 3.0139031, step = 253 (0.734 sec)\n","I0202 14:27:22.791775 140715376195456 basic_session_run_hooks.py:260] loss = 3.0139031, step = 253 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.34317\n","I0202 14:27:23.535821 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34317\n","INFO:tensorflow:loss = 2.729911, step = 254 (0.744 sec)\n","I0202 14:27:23.536129 140715376195456 basic_session_run_hooks.py:260] loss = 2.729911, step = 254 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.36332\n","I0202 14:27:24.269325 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36332\n","INFO:tensorflow:loss = 2.6777265, step = 255 (0.734 sec)\n","I0202 14:27:24.269811 140715376195456 basic_session_run_hooks.py:260] loss = 2.6777265, step = 255 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.37072\n","I0202 14:27:24.998865 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37072\n","INFO:tensorflow:loss = 3.1513574, step = 256 (0.730 sec)\n","I0202 14:27:24.999324 140715376195456 basic_session_run_hooks.py:260] loss = 3.1513574, step = 256 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.35309\n","I0202 14:27:25.737919 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35309\n","INFO:tensorflow:loss = 3.1056085, step = 257 (0.739 sec)\n","I0202 14:27:25.738367 140715376195456 basic_session_run_hooks.py:260] loss = 3.1056085, step = 257 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.37274\n","I0202 14:27:26.466383 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37274\n","INFO:tensorflow:loss = 3.2401166, step = 258 (0.728 sec)\n","I0202 14:27:26.466703 140715376195456 basic_session_run_hooks.py:260] loss = 3.2401166, step = 258 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.36952\n","I0202 14:27:27.196604 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36952\n","INFO:tensorflow:loss = 3.4268517, step = 259 (0.730 sec)\n","I0202 14:27:27.197053 140715376195456 basic_session_run_hooks.py:260] loss = 3.4268517, step = 259 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.33769\n","I0202 14:27:27.944140 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33769\n","INFO:tensorflow:loss = 2.8457253, step = 260 (0.748 sec)\n","I0202 14:27:27.944584 140715376195456 basic_session_run_hooks.py:260] loss = 2.8457253, step = 260 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.35783\n","I0202 14:27:28.680621 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35783\n","INFO:tensorflow:loss = 2.9731095, step = 261 (0.736 sec)\n","I0202 14:27:28.680922 140715376195456 basic_session_run_hooks.py:260] loss = 2.9731095, step = 261 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.36833\n","I0202 14:27:29.411474 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36833\n","INFO:tensorflow:loss = 2.9970555, step = 262 (0.731 sec)\n","I0202 14:27:29.411947 140715376195456 basic_session_run_hooks.py:260] loss = 2.9970555, step = 262 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.34661\n","I0202 14:27:30.154016 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34661\n","INFO:tensorflow:loss = 3.3683102, step = 263 (0.742 sec)\n","I0202 14:27:30.154445 140715376195456 basic_session_run_hooks.py:260] loss = 3.3683102, step = 263 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.35224\n","I0202 14:27:30.893537 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35224\n","INFO:tensorflow:loss = 3.1787817, step = 264 (0.739 sec)\n","I0202 14:27:30.893828 140715376195456 basic_session_run_hooks.py:260] loss = 3.1787817, step = 264 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.36286\n","I0202 14:27:31.627281 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36286\n","INFO:tensorflow:loss = 3.0679884, step = 265 (0.734 sec)\n","I0202 14:27:31.627746 140715376195456 basic_session_run_hooks.py:260] loss = 3.0679884, step = 265 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.4025\n","I0202 14:27:32.340318 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4025\n","INFO:tensorflow:loss = 3.6278136, step = 266 (0.713 sec)\n","I0202 14:27:32.340731 140715376195456 basic_session_run_hooks.py:260] loss = 3.6278136, step = 266 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.37836\n","I0202 14:27:33.065805 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37836\n","INFO:tensorflow:loss = 3.0651162, step = 267 (0.725 sec)\n","I0202 14:27:33.066103 140715376195456 basic_session_run_hooks.py:260] loss = 3.0651162, step = 267 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.37188\n","I0202 14:27:33.794716 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37188\n","INFO:tensorflow:loss = 2.968412, step = 268 (0.729 sec)\n","I0202 14:27:33.795141 140715376195456 basic_session_run_hooks.py:260] loss = 2.968412, step = 268 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.40217\n","I0202 14:27:34.507911 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40217\n","INFO:tensorflow:loss = 3.4953992, step = 269 (0.713 sec)\n","I0202 14:27:34.508555 140715376195456 basic_session_run_hooks.py:260] loss = 3.4953992, step = 269 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.35953\n","I0202 14:27:35.243485 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35953\n","INFO:tensorflow:loss = 2.795941, step = 270 (0.735 sec)\n","I0202 14:27:35.243951 140715376195456 basic_session_run_hooks.py:260] loss = 2.795941, step = 270 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35627\n","I0202 14:27:35.980772 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35627\n","INFO:tensorflow:loss = 2.8770752, step = 271 (0.737 sec)\n","I0202 14:27:35.981063 140715376195456 basic_session_run_hooks.py:260] loss = 2.8770752, step = 271 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.35356\n","I0202 14:27:36.719584 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35356\n","INFO:tensorflow:loss = 2.9339883, step = 272 (0.739 sec)\n","I0202 14:27:36.719986 140715376195456 basic_session_run_hooks.py:260] loss = 2.9339883, step = 272 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.43712\n","I0202 14:27:37.415392 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43712\n","INFO:tensorflow:loss = 3.7094493, step = 273 (0.696 sec)\n","I0202 14:27:37.415700 140715376195456 basic_session_run_hooks.py:260] loss = 3.7094493, step = 273 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 1.38661\n","I0202 14:27:38.136589 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38661\n","INFO:tensorflow:loss = 2.5980432, step = 274 (0.721 sec)\n","I0202 14:27:38.136880 140715376195456 basic_session_run_hooks.py:260] loss = 2.5980432, step = 274 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.36821\n","I0202 14:27:38.867486 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36821\n","INFO:tensorflow:loss = 3.0114255, step = 275 (0.731 sec)\n","I0202 14:27:38.867844 140715376195456 basic_session_run_hooks.py:260] loss = 3.0114255, step = 275 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.36427\n","I0202 14:27:39.600497 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36427\n","INFO:tensorflow:loss = 3.1499774, step = 276 (0.733 sec)\n","I0202 14:27:39.600818 140715376195456 basic_session_run_hooks.py:260] loss = 3.1499774, step = 276 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36847\n","I0202 14:27:40.331189 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36847\n","INFO:tensorflow:loss = 3.800207, step = 277 (0.731 sec)\n","I0202 14:27:40.331619 140715376195456 basic_session_run_hooks.py:260] loss = 3.800207, step = 277 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.42137\n","I0202 14:27:41.034761 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42137\n","INFO:tensorflow:loss = 3.1419258, step = 278 (0.703 sec)\n","I0202 14:27:41.035101 140715376195456 basic_session_run_hooks.py:260] loss = 3.1419258, step = 278 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.37589\n","I0202 14:27:41.761557 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37589\n","INFO:tensorflow:loss = 2.9051433, step = 279 (0.727 sec)\n","I0202 14:27:41.761856 140715376195456 basic_session_run_hooks.py:260] loss = 2.9051433, step = 279 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.3887\n","I0202 14:27:42.481649 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3887\n","INFO:tensorflow:loss = 3.115671, step = 280 (0.720 sec)\n","I0202 14:27:42.481939 140715376195456 basic_session_run_hooks.py:260] loss = 3.115671, step = 280 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.39649\n","I0202 14:27:43.197729 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39649\n","INFO:tensorflow:loss = 2.87199, step = 281 (0.716 sec)\n","I0202 14:27:43.198019 140715376195456 basic_session_run_hooks.py:260] loss = 2.87199, step = 281 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.39528\n","I0202 14:27:43.914440 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39528\n","INFO:tensorflow:loss = 2.8906987, step = 282 (0.717 sec)\n","I0202 14:27:43.914731 140715376195456 basic_session_run_hooks.py:260] loss = 2.8906987, step = 282 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.36357\n","I0202 14:27:44.647811 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36357\n","INFO:tensorflow:loss = 3.0582254, step = 283 (0.734 sec)\n","I0202 14:27:44.648279 140715376195456 basic_session_run_hooks.py:260] loss = 3.0582254, step = 283 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.42227\n","I0202 14:27:45.350898 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42227\n","INFO:tensorflow:loss = 3.0015602, step = 284 (0.703 sec)\n","I0202 14:27:45.351201 140715376195456 basic_session_run_hooks.py:260] loss = 3.0015602, step = 284 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.38213\n","I0202 14:27:46.074454 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38213\n","INFO:tensorflow:loss = 2.693504, step = 285 (0.724 sec)\n","I0202 14:27:46.074899 140715376195456 basic_session_run_hooks.py:260] loss = 2.693504, step = 285 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.36238\n","I0202 14:27:46.808452 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36238\n","INFO:tensorflow:loss = 2.75753, step = 286 (0.734 sec)\n","I0202 14:27:46.808745 140715376195456 basic_session_run_hooks.py:260] loss = 2.75753, step = 286 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.41774\n","I0202 14:27:47.513767 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41774\n","INFO:tensorflow:loss = 3.008767, step = 287 (0.705 sec)\n","I0202 14:27:47.514056 140715376195456 basic_session_run_hooks.py:260] loss = 3.008767, step = 287 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.37301\n","I0202 14:27:48.242125 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37301\n","INFO:tensorflow:loss = 2.952395, step = 288 (0.728 sec)\n","I0202 14:27:48.242432 140715376195456 basic_session_run_hooks.py:260] loss = 2.952395, step = 288 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.35738\n","I0202 14:27:48.978820 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35738\n","INFO:tensorflow:loss = 2.9360251, step = 289 (0.737 sec)\n","I0202 14:27:48.979243 140715376195456 basic_session_run_hooks.py:260] loss = 2.9360251, step = 289 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.45107\n","I0202 14:27:49.667978 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.45107\n","INFO:tensorflow:loss = 2.7408113, step = 290 (0.689 sec)\n","I0202 14:27:49.668296 140715376195456 basic_session_run_hooks.py:260] loss = 2.7408113, step = 290 (0.689 sec)\n","INFO:tensorflow:global_step/sec: 1.33157\n","I0202 14:27:50.418958 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33157\n","INFO:tensorflow:loss = 2.9711053, step = 291 (0.751 sec)\n","I0202 14:27:50.419266 140715376195456 basic_session_run_hooks.py:260] loss = 2.9711053, step = 291 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.36533\n","I0202 14:27:51.151394 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36533\n","INFO:tensorflow:loss = 3.3881586, step = 292 (0.732 sec)\n","I0202 14:27:51.151700 140715376195456 basic_session_run_hooks.py:260] loss = 3.3881586, step = 292 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.3843\n","I0202 14:27:51.873774 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3843\n","INFO:tensorflow:loss = 3.4546957, step = 293 (0.722 sec)\n","I0202 14:27:51.874080 140715376195456 basic_session_run_hooks.py:260] loss = 3.4546957, step = 293 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.37453\n","I0202 14:27:52.601309 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37453\n","INFO:tensorflow:loss = 3.0712757, step = 294 (0.728 sec)\n","I0202 14:27:52.601624 140715376195456 basic_session_run_hooks.py:260] loss = 3.0712757, step = 294 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.36914\n","I0202 14:27:53.331680 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36914\n","INFO:tensorflow:loss = 2.7546766, step = 295 (0.730 sec)\n","I0202 14:27:53.331984 140715376195456 basic_session_run_hooks.py:260] loss = 2.7546766, step = 295 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.39085\n","I0202 14:27:54.050669 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39085\n","INFO:tensorflow:loss = 3.1307213, step = 296 (0.719 sec)\n","I0202 14:27:54.050984 140715376195456 basic_session_run_hooks.py:260] loss = 3.1307213, step = 296 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.38447\n","I0202 14:27:54.772987 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38447\n","INFO:tensorflow:loss = 3.4378507, step = 297 (0.722 sec)\n","I0202 14:27:54.773320 140715376195456 basic_session_run_hooks.py:260] loss = 3.4378507, step = 297 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.37958\n","I0202 14:27:55.497844 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37958\n","INFO:tensorflow:loss = 3.5016341, step = 298 (0.725 sec)\n","I0202 14:27:55.498151 140715376195456 basic_session_run_hooks.py:260] loss = 3.5016341, step = 298 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39133\n","I0202 14:27:56.216566 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39133\n","INFO:tensorflow:loss = 3.4818451, step = 299 (0.719 sec)\n","I0202 14:27:56.216861 140715376195456 basic_session_run_hooks.py:260] loss = 3.4818451, step = 299 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.35991\n","I0202 14:27:56.951897 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35991\n","INFO:tensorflow:loss = 2.9855952, step = 300 (0.736 sec)\n","I0202 14:27:56.952812 140715376195456 basic_session_run_hooks.py:260] loss = 2.9855952, step = 300 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.38552\n","I0202 14:27:57.673635 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38552\n","INFO:tensorflow:loss = 3.0259905, step = 301 (0.721 sec)\n","I0202 14:27:57.674223 140715376195456 basic_session_run_hooks.py:260] loss = 3.0259905, step = 301 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37348\n","I0202 14:27:58.401739 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37348\n","INFO:tensorflow:loss = 3.335586, step = 302 (0.728 sec)\n","I0202 14:27:58.402039 140715376195456 basic_session_run_hooks.py:260] loss = 3.335586, step = 302 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.39087\n","I0202 14:27:59.120707 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39087\n","INFO:tensorflow:loss = 3.131386, step = 303 (0.719 sec)\n","I0202 14:27:59.120999 140715376195456 basic_session_run_hooks.py:260] loss = 3.131386, step = 303 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.36348\n","I0202 14:27:59.854103 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36348\n","INFO:tensorflow:loss = 2.7735245, step = 304 (0.733 sec)\n","I0202 14:27:59.854397 140715376195456 basic_session_run_hooks.py:260] loss = 2.7735245, step = 304 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.32788\n","I0202 14:28:00.607205 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32788\n","INFO:tensorflow:loss = 3.7624424, step = 305 (0.753 sec)\n","I0202 14:28:00.607816 140715376195456 basic_session_run_hooks.py:260] loss = 3.7624424, step = 305 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.33341\n","I0202 14:28:01.357154 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33341\n","INFO:tensorflow:loss = 3.56423, step = 306 (0.750 sec)\n","I0202 14:28:01.357460 140715376195456 basic_session_run_hooks.py:260] loss = 3.56423, step = 306 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.33468\n","I0202 14:28:02.106395 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33468\n","INFO:tensorflow:loss = 3.50373, step = 307 (0.749 sec)\n","I0202 14:28:02.106731 140715376195456 basic_session_run_hooks.py:260] loss = 3.50373, step = 307 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.35867\n","I0202 14:28:02.842451 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35867\n","INFO:tensorflow:loss = 2.862491, step = 308 (0.736 sec)\n","I0202 14:28:02.842786 140715376195456 basic_session_run_hooks.py:260] loss = 2.862491, step = 308 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.40077\n","I0202 14:28:03.556303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40077\n","INFO:tensorflow:loss = 3.0938656, step = 309 (0.714 sec)\n","I0202 14:28:03.556750 140715376195456 basic_session_run_hooks.py:260] loss = 3.0938656, step = 309 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.33992\n","I0202 14:28:04.302616 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33992\n","INFO:tensorflow:loss = 3.173112, step = 310 (0.746 sec)\n","I0202 14:28:04.302901 140715376195456 basic_session_run_hooks.py:260] loss = 3.173112, step = 310 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.3846\n","I0202 14:28:05.024845 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3846\n","INFO:tensorflow:loss = 2.996485, step = 311 (0.722 sec)\n","I0202 14:28:05.025138 140715376195456 basic_session_run_hooks.py:260] loss = 2.996485, step = 311 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.38145\n","I0202 14:28:05.748722 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38145\n","INFO:tensorflow:loss = 3.1199093, step = 312 (0.724 sec)\n","I0202 14:28:05.749010 140715376195456 basic_session_run_hooks.py:260] loss = 3.1199093, step = 312 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.36619\n","I0202 14:28:06.480706 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36619\n","INFO:tensorflow:loss = 3.0234318, step = 313 (0.732 sec)\n","I0202 14:28:06.481146 140715376195456 basic_session_run_hooks.py:260] loss = 3.0234318, step = 313 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.35337\n","I0202 14:28:07.219607 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35337\n","INFO:tensorflow:loss = 3.087248, step = 314 (0.739 sec)\n","I0202 14:28:07.219910 140715376195456 basic_session_run_hooks.py:260] loss = 3.087248, step = 314 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.38616\n","I0202 14:28:07.941023 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38616\n","INFO:tensorflow:loss = 2.8900433, step = 315 (0.721 sec)\n","I0202 14:28:07.941342 140715376195456 basic_session_run_hooks.py:260] loss = 2.8900433, step = 315 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.36483\n","I0202 14:28:08.673687 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36483\n","INFO:tensorflow:loss = 3.144709, step = 316 (0.733 sec)\n","I0202 14:28:08.673974 140715376195456 basic_session_run_hooks.py:260] loss = 3.144709, step = 316 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36446\n","I0202 14:28:09.406609 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36446\n","INFO:tensorflow:loss = 2.9082866, step = 317 (0.733 sec)\n","I0202 14:28:09.406900 140715376195456 basic_session_run_hooks.py:260] loss = 2.9082866, step = 317 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.38724\n","I0202 14:28:10.127474 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38724\n","INFO:tensorflow:loss = 2.6391563, step = 318 (0.721 sec)\n","I0202 14:28:10.127769 140715376195456 basic_session_run_hooks.py:260] loss = 2.6391563, step = 318 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.38692\n","I0202 14:28:10.848578 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38692\n","INFO:tensorflow:loss = 3.8758953, step = 319 (0.721 sec)\n","I0202 14:28:10.849004 140715376195456 basic_session_run_hooks.py:260] loss = 3.8758953, step = 319 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.34937\n","I0202 14:28:11.589576 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34937\n","INFO:tensorflow:loss = 2.8772123, step = 320 (0.741 sec)\n","I0202 14:28:11.589900 140715376195456 basic_session_run_hooks.py:260] loss = 2.8772123, step = 320 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.35437\n","I0202 14:28:12.327908 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35437\n","INFO:tensorflow:loss = 3.3478162, step = 321 (0.738 sec)\n","I0202 14:28:12.328206 140715376195456 basic_session_run_hooks.py:260] loss = 3.3478162, step = 321 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.40646\n","I0202 14:28:13.038908 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40646\n","INFO:tensorflow:loss = 2.9425368, step = 322 (0.711 sec)\n","I0202 14:28:13.039194 140715376195456 basic_session_run_hooks.py:260] loss = 2.9425368, step = 322 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.38971\n","I0202 14:28:13.758511 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38971\n","INFO:tensorflow:loss = 3.1651487, step = 323 (0.720 sec)\n","I0202 14:28:13.758801 140715376195456 basic_session_run_hooks.py:260] loss = 3.1651487, step = 323 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.3758\n","I0202 14:28:14.485325 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3758\n","INFO:tensorflow:loss = 2.802019, step = 324 (0.727 sec)\n","I0202 14:28:14.485795 140715376195456 basic_session_run_hooks.py:260] loss = 2.802019, step = 324 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.38196\n","I0202 14:28:15.208962 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38196\n","INFO:tensorflow:loss = 2.9627798, step = 325 (0.724 sec)\n","I0202 14:28:15.209503 140715376195456 basic_session_run_hooks.py:260] loss = 2.9627798, step = 325 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.43608\n","I0202 14:28:15.905287 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43608\n","INFO:tensorflow:loss = 3.0353262, step = 326 (0.696 sec)\n","I0202 14:28:15.905645 140715376195456 basic_session_run_hooks.py:260] loss = 3.0353262, step = 326 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 1.36897\n","I0202 14:28:16.635751 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36897\n","INFO:tensorflow:loss = 2.9412272, step = 327 (0.731 sec)\n","I0202 14:28:16.636159 140715376195456 basic_session_run_hooks.py:260] loss = 2.9412272, step = 327 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37336\n","I0202 14:28:17.363903 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37336\n","INFO:tensorflow:loss = 2.8646574, step = 328 (0.728 sec)\n","I0202 14:28:17.364195 140715376195456 basic_session_run_hooks.py:260] loss = 2.8646574, step = 328 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.41897\n","I0202 14:28:18.068660 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41897\n","INFO:tensorflow:loss = 3.129096, step = 329 (0.705 sec)\n","I0202 14:28:18.069114 140715376195456 basic_session_run_hooks.py:260] loss = 3.129096, step = 329 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.38755\n","I0202 14:28:18.789337 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38755\n","INFO:tensorflow:loss = 2.9236352, step = 330 (0.721 sec)\n","I0202 14:28:18.789802 140715376195456 basic_session_run_hooks.py:260] loss = 2.9236352, step = 330 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.38678\n","I0202 14:28:19.510446 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38678\n","INFO:tensorflow:loss = 3.0468445, step = 331 (0.721 sec)\n","I0202 14:28:19.510778 140715376195456 basic_session_run_hooks.py:260] loss = 3.0468445, step = 331 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.41978\n","I0202 14:28:20.214793 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41978\n","INFO:tensorflow:loss = 3.31568, step = 332 (0.704 sec)\n","I0202 14:28:20.215236 140715376195456 basic_session_run_hooks.py:260] loss = 3.31568, step = 332 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.38252\n","I0202 14:28:20.938091 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38252\n","INFO:tensorflow:loss = 2.6322305, step = 333 (0.723 sec)\n","I0202 14:28:20.938521 140715376195456 basic_session_run_hooks.py:260] loss = 2.6322305, step = 333 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.35122\n","I0202 14:28:21.678158 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35122\n","INFO:tensorflow:loss = 2.5283244, step = 334 (0.740 sec)\n","I0202 14:28:21.678601 140715376195456 basic_session_run_hooks.py:260] loss = 2.5283244, step = 334 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36667\n","I0202 14:28:22.409878 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36667\n","INFO:tensorflow:loss = 2.9912226, step = 335 (0.732 sec)\n","I0202 14:28:22.410176 140715376195456 basic_session_run_hooks.py:260] loss = 2.9912226, step = 335 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39226\n","I0202 14:28:23.128136 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39226\n","INFO:tensorflow:loss = 3.0529232, step = 336 (0.718 sec)\n","I0202 14:28:23.128564 140715376195456 basic_session_run_hooks.py:260] loss = 3.0529232, step = 336 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.42432\n","I0202 14:28:23.830211 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42432\n","INFO:tensorflow:loss = 2.7160866, step = 337 (0.702 sec)\n","I0202 14:28:23.830684 140715376195456 basic_session_run_hooks.py:260] loss = 2.7160866, step = 337 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.40706\n","I0202 14:28:24.540904 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40706\n","INFO:tensorflow:loss = 2.9990373, step = 338 (0.711 sec)\n","I0202 14:28:24.541371 140715376195456 basic_session_run_hooks.py:260] loss = 2.9990373, step = 338 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.37589\n","I0202 14:28:25.267710 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37589\n","INFO:tensorflow:loss = 2.3955846, step = 339 (0.727 sec)\n","I0202 14:28:25.267992 140715376195456 basic_session_run_hooks.py:260] loss = 2.3955846, step = 339 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.39182\n","I0202 14:28:25.986207 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39182\n","INFO:tensorflow:loss = 2.8198504, step = 340 (0.719 sec)\n","I0202 14:28:25.986687 140715376195456 basic_session_run_hooks.py:260] loss = 2.8198504, step = 340 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.38791\n","I0202 14:28:26.706700 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38791\n","INFO:tensorflow:loss = 2.9132328, step = 341 (0.720 sec)\n","I0202 14:28:26.707118 140715376195456 basic_session_run_hooks.py:260] loss = 2.9132328, step = 341 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.37011\n","I0202 14:28:27.436605 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37011\n","INFO:tensorflow:loss = 2.4014726, step = 342 (0.730 sec)\n","I0202 14:28:27.437023 140715376195456 basic_session_run_hooks.py:260] loss = 2.4014726, step = 342 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.39184\n","I0202 14:28:28.155058 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39184\n","INFO:tensorflow:loss = 2.3359804, step = 343 (0.719 sec)\n","I0202 14:28:28.155525 140715376195456 basic_session_run_hooks.py:260] loss = 2.3359804, step = 343 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.38266\n","I0202 14:28:28.878298 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38266\n","INFO:tensorflow:loss = 3.1439097, step = 344 (0.723 sec)\n","I0202 14:28:28.878786 140715376195456 basic_session_run_hooks.py:260] loss = 3.1439097, step = 344 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.3922\n","I0202 14:28:29.596594 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3922\n","INFO:tensorflow:loss = 2.6567302, step = 345 (0.718 sec)\n","I0202 14:28:29.596890 140715376195456 basic_session_run_hooks.py:260] loss = 2.6567302, step = 345 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.41124\n","I0202 14:28:30.305181 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41124\n","INFO:tensorflow:loss = 2.876536, step = 346 (0.709 sec)\n","I0202 14:28:30.305608 140715376195456 basic_session_run_hooks.py:260] loss = 2.876536, step = 346 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.35311\n","I0202 14:28:31.044201 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35311\n","INFO:tensorflow:loss = 2.9864626, step = 347 (0.739 sec)\n","I0202 14:28:31.044540 140715376195456 basic_session_run_hooks.py:260] loss = 2.9864626, step = 347 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.34014\n","I0202 14:28:31.790400 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34014\n","INFO:tensorflow:loss = 2.689066, step = 348 (0.746 sec)\n","I0202 14:28:31.790713 140715376195456 basic_session_run_hooks.py:260] loss = 2.689066, step = 348 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.35785\n","I0202 14:28:32.526877 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35785\n","INFO:tensorflow:loss = 2.8998272, step = 349 (0.737 sec)\n","I0202 14:28:32.527353 140715376195456 basic_session_run_hooks.py:260] loss = 2.8998272, step = 349 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37863\n","I0202 14:28:33.252247 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37863\n","INFO:tensorflow:loss = 2.8782706, step = 350 (0.725 sec)\n","I0202 14:28:33.252564 140715376195456 basic_session_run_hooks.py:260] loss = 2.8782706, step = 350 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.40995\n","I0202 14:28:33.961496 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40995\n","INFO:tensorflow:loss = 3.1215436, step = 351 (0.709 sec)\n","I0202 14:28:33.961923 140715376195456 basic_session_run_hooks.py:260] loss = 3.1215436, step = 351 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.35649\n","I0202 14:28:34.698658 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35649\n","INFO:tensorflow:loss = 4.0519204, step = 352 (0.737 sec)\n","I0202 14:28:34.698958 140715376195456 basic_session_run_hooks.py:260] loss = 4.0519204, step = 352 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.38016\n","I0202 14:28:35.423221 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38016\n","INFO:tensorflow:loss = 3.2648234, step = 353 (0.725 sec)\n","I0202 14:28:35.423664 140715376195456 basic_session_run_hooks.py:260] loss = 3.2648234, step = 353 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.4051\n","I0202 14:28:36.134911 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4051\n","INFO:tensorflow:loss = 3.279367, step = 354 (0.712 sec)\n","I0202 14:28:36.135206 140715376195456 basic_session_run_hooks.py:260] loss = 3.279367, step = 354 (0.712 sec)\n","INFO:tensorflow:global_step/sec: 1.38194\n","I0202 14:28:36.858534 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38194\n","INFO:tensorflow:loss = 3.0846488, step = 355 (0.724 sec)\n","I0202 14:28:36.858955 140715376195456 basic_session_run_hooks.py:260] loss = 3.0846488, step = 355 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.36856\n","I0202 14:28:37.589215 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36856\n","INFO:tensorflow:loss = 2.5532215, step = 356 (0.731 sec)\n","I0202 14:28:37.589692 140715376195456 basic_session_run_hooks.py:260] loss = 2.5532215, step = 356 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.35766\n","I0202 14:28:38.325785 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35766\n","INFO:tensorflow:loss = 3.2041326, step = 357 (0.737 sec)\n","I0202 14:28:38.326195 140715376195456 basic_session_run_hooks.py:260] loss = 3.2041326, step = 357 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.36074\n","I0202 14:28:39.060683 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36074\n","INFO:tensorflow:loss = 3.2161622, step = 358 (0.735 sec)\n","I0202 14:28:39.061142 140715376195456 basic_session_run_hooks.py:260] loss = 3.2161622, step = 358 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35705\n","I0202 14:28:39.797589 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35705\n","INFO:tensorflow:loss = 3.6137772, step = 359 (0.737 sec)\n","I0202 14:28:39.798044 140715376195456 basic_session_run_hooks.py:260] loss = 3.6137772, step = 359 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.38323\n","I0202 14:28:40.520533 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38323\n","INFO:tensorflow:loss = 3.17548, step = 360 (0.723 sec)\n","I0202 14:28:40.520958 140715376195456 basic_session_run_hooks.py:260] loss = 3.17548, step = 360 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.34586\n","I0202 14:28:41.263562 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34586\n","INFO:tensorflow:loss = 2.7062056, step = 361 (0.743 sec)\n","I0202 14:28:41.263988 140715376195456 basic_session_run_hooks.py:260] loss = 2.7062056, step = 361 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.27784\n","I0202 14:28:42.046141 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.27784\n","INFO:tensorflow:loss = 2.5214608, step = 362 (0.783 sec)\n","I0202 14:28:42.046560 140715376195456 basic_session_run_hooks.py:260] loss = 2.5214608, step = 362 (0.783 sec)\n","INFO:tensorflow:global_step/sec: 1.36926\n","I0202 14:28:42.776458 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36926\n","INFO:tensorflow:loss = 2.760162, step = 363 (0.730 sec)\n","I0202 14:28:42.776803 140715376195456 basic_session_run_hooks.py:260] loss = 2.760162, step = 363 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.32671\n","I0202 14:28:43.530187 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32671\n","INFO:tensorflow:loss = 3.2144434, step = 364 (0.754 sec)\n","I0202 14:28:43.530538 140715376195456 basic_session_run_hooks.py:260] loss = 3.2144434, step = 364 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.32665\n","I0202 14:28:44.283948 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32665\n","INFO:tensorflow:loss = 3.3304095, step = 365 (0.754 sec)\n","I0202 14:28:44.284331 140715376195456 basic_session_run_hooks.py:260] loss = 3.3304095, step = 365 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.38982\n","I0202 14:28:45.003556 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38982\n","INFO:tensorflow:loss = 3.2811296, step = 366 (0.720 sec)\n","I0202 14:28:45.003922 140715376195456 basic_session_run_hooks.py:260] loss = 3.2811296, step = 366 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.34334\n","I0202 14:28:45.747872 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34334\n","INFO:tensorflow:loss = 2.6559227, step = 367 (0.744 sec)\n","I0202 14:28:45.748200 140715376195456 basic_session_run_hooks.py:260] loss = 2.6559227, step = 367 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.33958\n","I0202 14:28:46.494461 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33958\n","INFO:tensorflow:loss = 2.6760654, step = 368 (0.747 sec)\n","I0202 14:28:46.494812 140715376195456 basic_session_run_hooks.py:260] loss = 2.6760654, step = 368 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.35422\n","I0202 14:28:47.232846 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35422\n","INFO:tensorflow:loss = 3.0746512, step = 369 (0.738 sec)\n","I0202 14:28:47.233208 140715376195456 basic_session_run_hooks.py:260] loss = 3.0746512, step = 369 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.37023\n","I0202 14:28:47.962638 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37023\n","INFO:tensorflow:loss = 3.1120365, step = 370 (0.730 sec)\n","I0202 14:28:47.962984 140715376195456 basic_session_run_hooks.py:260] loss = 3.1120365, step = 370 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.38018\n","I0202 14:28:48.687180 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38018\n","INFO:tensorflow:loss = 3.0572686, step = 371 (0.725 sec)\n","I0202 14:28:48.687582 140715376195456 basic_session_run_hooks.py:260] loss = 3.0572686, step = 371 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.35029\n","I0202 14:28:49.427745 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35029\n","INFO:tensorflow:loss = 2.5938215, step = 372 (0.740 sec)\n","I0202 14:28:49.428079 140715376195456 basic_session_run_hooks.py:260] loss = 2.5938215, step = 372 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.34369\n","I0202 14:28:50.171966 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34369\n","INFO:tensorflow:loss = 3.1091692, step = 373 (0.744 sec)\n","I0202 14:28:50.172342 140715376195456 basic_session_run_hooks.py:260] loss = 3.1091692, step = 373 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.36148\n","I0202 14:28:50.906488 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36148\n","INFO:tensorflow:loss = 2.5621877, step = 374 (0.735 sec)\n","I0202 14:28:50.906856 140715376195456 basic_session_run_hooks.py:260] loss = 2.5621877, step = 374 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35445\n","I0202 14:28:51.644782 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35445\n","INFO:tensorflow:loss = 2.5604491, step = 375 (0.738 sec)\n","I0202 14:28:51.645114 140715376195456 basic_session_run_hooks.py:260] loss = 2.5604491, step = 375 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.33218\n","I0202 14:28:52.395433 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33218\n","INFO:tensorflow:loss = 3.5107915, step = 376 (0.751 sec)\n","I0202 14:28:52.395855 140715376195456 basic_session_run_hooks.py:260] loss = 3.5107915, step = 376 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.3966\n","I0202 14:28:53.111463 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3966\n","INFO:tensorflow:loss = 2.8140616, step = 377 (0.716 sec)\n","I0202 14:28:53.111771 140715376195456 basic_session_run_hooks.py:260] loss = 2.8140616, step = 377 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.38638\n","I0202 14:28:53.832739 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38638\n","INFO:tensorflow:loss = 3.0714676, step = 378 (0.721 sec)\n","I0202 14:28:53.833176 140715376195456 basic_session_run_hooks.py:260] loss = 3.0714676, step = 378 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.39624\n","I0202 14:28:54.548969 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39624\n","INFO:tensorflow:loss = 2.9562967, step = 379 (0.716 sec)\n","I0202 14:28:54.549262 140715376195456 basic_session_run_hooks.py:260] loss = 2.9562967, step = 379 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.36712\n","I0202 14:28:55.280447 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36712\n","INFO:tensorflow:loss = 2.9757562, step = 380 (0.732 sec)\n","I0202 14:28:55.280776 140715376195456 basic_session_run_hooks.py:260] loss = 2.9757562, step = 380 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.36692\n","I0202 14:28:56.012065 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36692\n","INFO:tensorflow:loss = 2.4869645, step = 381 (0.732 sec)\n","I0202 14:28:56.012441 140715376195456 basic_session_run_hooks.py:260] loss = 2.4869645, step = 381 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.38853\n","I0202 14:28:56.732208 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38853\n","INFO:tensorflow:loss = 2.886821, step = 382 (0.720 sec)\n","I0202 14:28:56.732538 140715376195456 basic_session_run_hooks.py:260] loss = 2.886821, step = 382 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.37187\n","I0202 14:28:57.461101 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37187\n","INFO:tensorflow:loss = 2.75632, step = 383 (0.729 sec)\n","I0202 14:28:57.461529 140715376195456 basic_session_run_hooks.py:260] loss = 2.75632, step = 383 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.3972\n","I0202 14:28:58.176826 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3972\n","INFO:tensorflow:loss = 2.978864, step = 384 (0.716 sec)\n","I0202 14:28:58.177118 140715376195456 basic_session_run_hooks.py:260] loss = 2.978864, step = 384 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.37876\n","I0202 14:28:58.902118 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37876\n","INFO:tensorflow:loss = 2.9993787, step = 385 (0.725 sec)\n","I0202 14:28:58.902548 140715376195456 basic_session_run_hooks.py:260] loss = 2.9993787, step = 385 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.38686\n","I0202 14:28:59.623185 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38686\n","INFO:tensorflow:loss = 2.8963432, step = 386 (0.721 sec)\n","I0202 14:28:59.623548 140715376195456 basic_session_run_hooks.py:260] loss = 2.8963432, step = 386 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.3981\n","I0202 14:29:00.338446 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3981\n","INFO:tensorflow:loss = 2.435517, step = 387 (0.715 sec)\n","I0202 14:29:00.338786 140715376195456 basic_session_run_hooks.py:260] loss = 2.435517, step = 387 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.42084\n","I0202 14:29:01.042236 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42084\n","INFO:tensorflow:loss = 2.594228, step = 388 (0.704 sec)\n","I0202 14:29:01.042660 140715376195456 basic_session_run_hooks.py:260] loss = 2.594228, step = 388 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.38709\n","I0202 14:29:01.763199 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38709\n","INFO:tensorflow:loss = 2.8870416, step = 389 (0.721 sec)\n","I0202 14:29:01.763570 140715376195456 basic_session_run_hooks.py:260] loss = 2.8870416, step = 389 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.40295\n","I0202 14:29:02.475957 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40295\n","INFO:tensorflow:loss = 2.837347, step = 390 (0.713 sec)\n","I0202 14:29:02.476378 140715376195456 basic_session_run_hooks.py:260] loss = 2.837347, step = 390 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.34823\n","I0202 14:29:03.217684 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34823\n","INFO:tensorflow:loss = 2.6900346, step = 391 (0.742 sec)\n","I0202 14:29:03.218003 140715376195456 basic_session_run_hooks.py:260] loss = 2.6900346, step = 391 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.37201\n","I0202 14:29:03.946552 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37201\n","INFO:tensorflow:loss = 2.9431858, step = 392 (0.729 sec)\n","I0202 14:29:03.946867 140715376195456 basic_session_run_hooks.py:260] loss = 2.9431858, step = 392 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.40788\n","I0202 14:29:04.656823 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40788\n","INFO:tensorflow:loss = 3.0383444, step = 393 (0.710 sec)\n","I0202 14:29:04.657112 140715376195456 basic_session_run_hooks.py:260] loss = 3.0383444, step = 393 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.38601\n","I0202 14:29:05.378303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38601\n","INFO:tensorflow:loss = 3.2594113, step = 394 (0.721 sec)\n","I0202 14:29:05.378614 140715376195456 basic_session_run_hooks.py:260] loss = 3.2594113, step = 394 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.37859\n","I0202 14:29:06.103703 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37859\n","INFO:tensorflow:loss = 2.8195071, step = 395 (0.725 sec)\n","I0202 14:29:06.104020 140715376195456 basic_session_run_hooks.py:260] loss = 2.8195071, step = 395 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.3913\n","I0202 14:29:06.822456 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3913\n","INFO:tensorflow:loss = 3.1560397, step = 396 (0.719 sec)\n","I0202 14:29:06.822858 140715376195456 basic_session_run_hooks.py:260] loss = 3.1560397, step = 396 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.37305\n","I0202 14:29:07.550748 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37305\n","INFO:tensorflow:loss = 2.8772345, step = 397 (0.728 sec)\n","I0202 14:29:07.551043 140715376195456 basic_session_run_hooks.py:260] loss = 2.8772345, step = 397 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.39396\n","I0202 14:29:08.268133 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39396\n","INFO:tensorflow:loss = 3.1395254, step = 398 (0.718 sec)\n","I0202 14:29:08.268560 140715376195456 basic_session_run_hooks.py:260] loss = 3.1395254, step = 398 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.46792\n","I0202 14:29:08.949364 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.46792\n","INFO:tensorflow:loss = 2.499354, step = 399 (0.681 sec)\n","I0202 14:29:08.949828 140715376195456 basic_session_run_hooks.py:260] loss = 2.499354, step = 399 (0.681 sec)\n","INFO:tensorflow:global_step/sec: 1.40908\n","I0202 14:29:09.659039 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40908\n","INFO:tensorflow:loss = 2.7379727, step = 400 (0.710 sec)\n","I0202 14:29:09.659962 140715376195456 basic_session_run_hooks.py:260] loss = 2.7379727, step = 400 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.37687\n","I0202 14:29:10.385324 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37687\n","INFO:tensorflow:loss = 2.5481472, step = 401 (0.726 sec)\n","I0202 14:29:10.385914 140715376195456 basic_session_run_hooks.py:260] loss = 2.5481472, step = 401 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.3772\n","I0202 14:29:11.111496 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3772\n","INFO:tensorflow:loss = 3.1460278, step = 402 (0.726 sec)\n","I0202 14:29:11.111804 140715376195456 basic_session_run_hooks.py:260] loss = 3.1460278, step = 402 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.32141\n","I0202 14:29:11.868214 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32141\n","INFO:tensorflow:loss = 2.635091, step = 403 (0.757 sec)\n","I0202 14:29:11.868550 140715376195456 basic_session_run_hooks.py:260] loss = 2.635091, step = 403 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 1.37839\n","I0202 14:29:12.593693 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37839\n","INFO:tensorflow:loss = 3.0557466, step = 404 (0.726 sec)\n","I0202 14:29:12.594175 140715376195456 basic_session_run_hooks.py:260] loss = 3.0557466, step = 404 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.33131\n","I0202 14:29:13.344851 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33131\n","INFO:tensorflow:loss = 2.9493318, step = 405 (0.751 sec)\n","I0202 14:29:13.345227 140715376195456 basic_session_run_hooks.py:260] loss = 2.9493318, step = 405 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.35752\n","I0202 14:29:14.081499 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35752\n","INFO:tensorflow:loss = 2.8892286, step = 406 (0.737 sec)\n","I0202 14:29:14.081816 140715376195456 basic_session_run_hooks.py:260] loss = 2.8892286, step = 406 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37647\n","I0202 14:29:14.807957 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37647\n","INFO:tensorflow:loss = 2.9280815, step = 407 (0.726 sec)\n","I0202 14:29:14.808258 140715376195456 basic_session_run_hooks.py:260] loss = 2.9280815, step = 407 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38416\n","I0202 14:29:15.530455 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38416\n","INFO:tensorflow:loss = 2.6966434, step = 408 (0.723 sec)\n","I0202 14:29:15.530812 140715376195456 basic_session_run_hooks.py:260] loss = 2.6966434, step = 408 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.34862\n","I0202 14:29:16.271946 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34862\n","INFO:tensorflow:loss = 2.6864996, step = 409 (0.741 sec)\n","I0202 14:29:16.272293 140715376195456 basic_session_run_hooks.py:260] loss = 2.6864996, step = 409 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.35054\n","I0202 14:29:17.012393 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35054\n","INFO:tensorflow:loss = 3.8760593, step = 410 (0.740 sec)\n","I0202 14:29:17.012742 140715376195456 basic_session_run_hooks.py:260] loss = 3.8760593, step = 410 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.37641\n","I0202 14:29:17.738924 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37641\n","INFO:tensorflow:loss = 2.480624, step = 411 (0.726 sec)\n","I0202 14:29:17.739221 140715376195456 basic_session_run_hooks.py:260] loss = 2.480624, step = 411 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.33737\n","I0202 14:29:18.486638 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33737\n","INFO:tensorflow:loss = 2.8439941, step = 412 (0.748 sec)\n","I0202 14:29:18.487078 140715376195456 basic_session_run_hooks.py:260] loss = 2.8439941, step = 412 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.35182\n","I0202 14:29:19.226375 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35182\n","INFO:tensorflow:loss = 2.6076422, step = 413 (0.740 sec)\n","I0202 14:29:19.226700 140715376195456 basic_session_run_hooks.py:260] loss = 2.6076422, step = 413 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.38783\n","I0202 14:29:19.946927 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38783\n","INFO:tensorflow:loss = 2.9181817, step = 414 (0.721 sec)\n","I0202 14:29:19.947238 140715376195456 basic_session_run_hooks.py:260] loss = 2.9181817, step = 414 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.36248\n","I0202 14:29:20.680873 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36248\n","INFO:tensorflow:loss = 2.7306938, step = 415 (0.734 sec)\n","I0202 14:29:20.681295 140715376195456 basic_session_run_hooks.py:260] loss = 2.7306938, step = 415 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.30586\n","I0202 14:29:21.446654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30586\n","INFO:tensorflow:loss = 3.049531, step = 416 (0.766 sec)\n","I0202 14:29:21.447063 140715376195456 basic_session_run_hooks.py:260] loss = 3.049531, step = 416 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 1.38636\n","I0202 14:29:22.167976 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38636\n","INFO:tensorflow:loss = 2.7298326, step = 417 (0.721 sec)\n","I0202 14:29:22.168300 140715376195456 basic_session_run_hooks.py:260] loss = 2.7298326, step = 417 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.38661\n","I0202 14:29:22.889175 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38661\n","INFO:tensorflow:loss = 2.4950705, step = 418 (0.721 sec)\n","I0202 14:29:22.889628 140715376195456 basic_session_run_hooks.py:260] loss = 2.4950705, step = 418 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.30988\n","I0202 14:29:23.652599 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30988\n","INFO:tensorflow:loss = 2.427349, step = 419 (0.763 sec)\n","I0202 14:29:23.652895 140715376195456 basic_session_run_hooks.py:260] loss = 2.427349, step = 419 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 1.38174\n","I0202 14:29:24.376303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38174\n","INFO:tensorflow:loss = 2.9323792, step = 420 (0.724 sec)\n","I0202 14:29:24.376746 140715376195456 basic_session_run_hooks.py:260] loss = 2.9323792, step = 420 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.403\n","I0202 14:29:25.089076 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.403\n","INFO:tensorflow:loss = 2.7361178, step = 421 (0.713 sec)\n","I0202 14:29:25.089511 140715376195456 basic_session_run_hooks.py:260] loss = 2.7361178, step = 421 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.40628\n","I0202 14:29:25.800169 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40628\n","INFO:tensorflow:loss = 3.2393405, step = 422 (0.711 sec)\n","I0202 14:29:25.800494 140715376195456 basic_session_run_hooks.py:260] loss = 3.2393405, step = 422 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.3838\n","I0202 14:29:26.522809 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3838\n","INFO:tensorflow:loss = 2.797671, step = 423 (0.723 sec)\n","I0202 14:29:26.523104 140715376195456 basic_session_run_hooks.py:260] loss = 2.797671, step = 423 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37774\n","I0202 14:29:27.248654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37774\n","INFO:tensorflow:loss = 2.5885139, step = 424 (0.726 sec)\n","I0202 14:29:27.249077 140715376195456 basic_session_run_hooks.py:260] loss = 2.5885139, step = 424 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.4241\n","I0202 14:29:27.950841 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4241\n","INFO:tensorflow:loss = 3.140435, step = 425 (0.702 sec)\n","I0202 14:29:27.951254 140715376195456 basic_session_run_hooks.py:260] loss = 3.140435, step = 425 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.36869\n","I0202 14:29:28.681465 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36869\n","INFO:tensorflow:loss = 2.7238095, step = 426 (0.731 sec)\n","I0202 14:29:28.681764 140715376195456 basic_session_run_hooks.py:260] loss = 2.7238095, step = 426 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37997\n","I0202 14:29:29.406123 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37997\n","INFO:tensorflow:loss = 3.151362, step = 427 (0.725 sec)\n","I0202 14:29:29.406556 140715376195456 basic_session_run_hooks.py:260] loss = 3.151362, step = 427 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39187\n","I0202 14:29:30.124597 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39187\n","INFO:tensorflow:loss = 2.8235388, step = 428 (0.719 sec)\n","I0202 14:29:30.125058 140715376195456 basic_session_run_hooks.py:260] loss = 2.8235388, step = 428 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.42263\n","I0202 14:29:30.827507 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42263\n","INFO:tensorflow:loss = 2.6936684, step = 429 (0.703 sec)\n","I0202 14:29:30.827794 140715376195456 basic_session_run_hooks.py:260] loss = 2.6936684, step = 429 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.42932\n","I0202 14:29:31.527161 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42932\n","INFO:tensorflow:loss = 2.6999705, step = 430 (0.700 sec)\n","I0202 14:29:31.527601 140715376195456 basic_session_run_hooks.py:260] loss = 2.6999705, step = 430 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.38206\n","I0202 14:29:32.250702 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38206\n","INFO:tensorflow:loss = 3.3264396, step = 431 (0.724 sec)\n","I0202 14:29:32.251144 140715376195456 basic_session_run_hooks.py:260] loss = 3.3264396, step = 431 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.4367\n","I0202 14:29:32.946729 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4367\n","INFO:tensorflow:loss = 2.6803641, step = 432 (0.696 sec)\n","I0202 14:29:32.947145 140715376195456 basic_session_run_hooks.py:260] loss = 2.6803641, step = 432 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 1.39964\n","I0202 14:29:33.661187 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39964\n","INFO:tensorflow:loss = 2.6544323, step = 433 (0.714 sec)\n","I0202 14:29:33.661626 140715376195456 basic_session_run_hooks.py:260] loss = 2.6544323, step = 433 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.33879\n","I0202 14:29:34.408134 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33879\n","INFO:tensorflow:loss = 2.564294, step = 434 (0.747 sec)\n","I0202 14:29:34.408578 140715376195456 basic_session_run_hooks.py:260] loss = 2.564294, step = 434 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.39152\n","I0202 14:29:35.126806 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39152\n","INFO:tensorflow:loss = 3.539905, step = 435 (0.719 sec)\n","I0202 14:29:35.127125 140715376195456 basic_session_run_hooks.py:260] loss = 3.539905, step = 435 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.39585\n","I0202 14:29:35.843194 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39585\n","INFO:tensorflow:loss = 2.8932762, step = 436 (0.716 sec)\n","I0202 14:29:35.843533 140715376195456 basic_session_run_hooks.py:260] loss = 2.8932762, step = 436 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.36297\n","I0202 14:29:36.576881 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36297\n","INFO:tensorflow:loss = 2.6199167, step = 437 (0.734 sec)\n","I0202 14:29:36.577327 140715376195456 basic_session_run_hooks.py:260] loss = 2.6199167, step = 437 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.37566\n","I0202 14:29:37.303830 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37566\n","INFO:tensorflow:loss = 2.4581177, step = 438 (0.727 sec)\n","I0202 14:29:37.304148 140715376195456 basic_session_run_hooks.py:260] loss = 2.4581177, step = 438 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.3757\n","I0202 14:29:38.030697 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3757\n","INFO:tensorflow:loss = 3.1170452, step = 439 (0.727 sec)\n","I0202 14:29:38.031141 140715376195456 basic_session_run_hooks.py:260] loss = 3.1170452, step = 439 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.36619\n","I0202 14:29:38.762672 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36619\n","INFO:tensorflow:loss = 2.599576, step = 440 (0.732 sec)\n","I0202 14:29:38.763036 140715376195456 basic_session_run_hooks.py:260] loss = 2.599576, step = 440 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.36367\n","I0202 14:29:39.495982 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36367\n","INFO:tensorflow:loss = 2.7807646, step = 441 (0.733 sec)\n","I0202 14:29:39.496271 140715376195456 basic_session_run_hooks.py:260] loss = 2.7807646, step = 441 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.39114\n","I0202 14:29:40.214818 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39114\n","INFO:tensorflow:loss = 2.5144956, step = 442 (0.719 sec)\n","I0202 14:29:40.215266 140715376195456 basic_session_run_hooks.py:260] loss = 2.5144956, step = 442 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.37885\n","I0202 14:29:40.940050 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37885\n","INFO:tensorflow:loss = 3.1948628, step = 443 (0.725 sec)\n","I0202 14:29:40.940355 140715376195456 basic_session_run_hooks.py:260] loss = 3.1948628, step = 443 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36391\n","I0202 14:29:41.673241 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36391\n","INFO:tensorflow:loss = 2.8849707, step = 444 (0.733 sec)\n","I0202 14:29:41.673712 140715376195456 basic_session_run_hooks.py:260] loss = 2.8849707, step = 444 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.45435\n","I0202 14:29:42.360833 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.45435\n","INFO:tensorflow:loss = 3.465341, step = 445 (0.687 sec)\n","I0202 14:29:42.361139 140715376195456 basic_session_run_hooks.py:260] loss = 3.465341, step = 445 (0.687 sec)\n","INFO:tensorflow:global_step/sec: 1.41611\n","I0202 14:29:43.066987 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41611\n","INFO:tensorflow:loss = 3.158741, step = 446 (0.706 sec)\n","I0202 14:29:43.067454 140715376195456 basic_session_run_hooks.py:260] loss = 3.158741, step = 446 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.34973\n","I0202 14:29:43.807868 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34973\n","INFO:tensorflow:loss = 3.4742231, step = 447 (0.741 sec)\n","I0202 14:29:43.808159 140715376195456 basic_session_run_hooks.py:260] loss = 3.4742231, step = 447 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.32898\n","I0202 14:29:44.560330 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32898\n","INFO:tensorflow:loss = 3.1665921, step = 448 (0.753 sec)\n","I0202 14:29:44.560759 140715376195456 basic_session_run_hooks.py:260] loss = 3.1665921, step = 448 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.38594\n","I0202 14:29:45.281915 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38594\n","INFO:tensorflow:loss = 2.8767736, step = 449 (0.721 sec)\n","I0202 14:29:45.282216 140715376195456 basic_session_run_hooks.py:260] loss = 2.8767736, step = 449 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.39537\n","I0202 14:29:45.998551 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39537\n","INFO:tensorflow:loss = 2.694652, step = 450 (0.717 sec)\n","I0202 14:29:45.998847 140715376195456 basic_session_run_hooks.py:260] loss = 2.694652, step = 450 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.33944\n","I0202 14:29:46.745113 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33944\n","INFO:tensorflow:loss = 2.8510382, step = 451 (0.747 sec)\n","I0202 14:29:46.745567 140715376195456 basic_session_run_hooks.py:260] loss = 2.8510382, step = 451 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.38344\n","I0202 14:29:47.467961 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38344\n","INFO:tensorflow:loss = 2.3221414, step = 452 (0.723 sec)\n","I0202 14:29:47.468383 140715376195456 basic_session_run_hooks.py:260] loss = 2.3221414, step = 452 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.35081\n","I0202 14:29:48.208232 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35081\n","INFO:tensorflow:loss = 3.5901628, step = 453 (0.740 sec)\n","I0202 14:29:48.208666 140715376195456 basic_session_run_hooks.py:260] loss = 3.5901628, step = 453 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36466\n","I0202 14:29:48.941022 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36466\n","INFO:tensorflow:loss = 2.9653542, step = 454 (0.733 sec)\n","I0202 14:29:48.941359 140715376195456 basic_session_run_hooks.py:260] loss = 2.9653542, step = 454 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.39052\n","I0202 14:29:49.660171 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39052\n","INFO:tensorflow:loss = 2.9839706, step = 455 (0.719 sec)\n","I0202 14:29:49.660497 140715376195456 basic_session_run_hooks.py:260] loss = 2.9839706, step = 455 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.33741\n","I0202 14:29:50.407900 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33741\n","INFO:tensorflow:loss = 2.5907948, step = 456 (0.748 sec)\n","I0202 14:29:50.408315 140715376195456 basic_session_run_hooks.py:260] loss = 2.5907948, step = 456 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.42875\n","I0202 14:29:51.107825 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42875\n","INFO:tensorflow:loss = 2.728295, step = 457 (0.700 sec)\n","I0202 14:29:51.108172 140715376195456 basic_session_run_hooks.py:260] loss = 2.728295, step = 457 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.29784\n","I0202 14:29:51.878335 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29784\n","INFO:tensorflow:loss = 2.8935459, step = 458 (0.771 sec)\n","I0202 14:29:51.878779 140715376195456 basic_session_run_hooks.py:260] loss = 2.8935459, step = 458 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 1.31743\n","I0202 14:29:52.637376 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31743\n","INFO:tensorflow:loss = 2.520677, step = 459 (0.759 sec)\n","I0202 14:29:52.637846 140715376195456 basic_session_run_hooks.py:260] loss = 2.520677, step = 459 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 1.29555\n","I0202 14:29:53.409260 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29555\n","INFO:tensorflow:loss = 2.9482532, step = 460 (0.772 sec)\n","I0202 14:29:53.409772 140715376195456 basic_session_run_hooks.py:260] loss = 2.9482532, step = 460 (0.772 sec)\n","INFO:tensorflow:global_step/sec: 1.325\n","I0202 14:29:54.163969 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.325\n","INFO:tensorflow:loss = 2.5208254, step = 461 (0.755 sec)\n","I0202 14:29:54.164299 140715376195456 basic_session_run_hooks.py:260] loss = 2.5208254, step = 461 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.36184\n","I0202 14:29:54.898259 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36184\n","INFO:tensorflow:loss = 2.55267, step = 462 (0.734 sec)\n","I0202 14:29:54.898603 140715376195456 basic_session_run_hooks.py:260] loss = 2.55267, step = 462 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.33899\n","I0202 14:29:55.645123 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33899\n","INFO:tensorflow:loss = 2.4692392, step = 463 (0.747 sec)\n","I0202 14:29:55.645587 140715376195456 basic_session_run_hooks.py:260] loss = 2.4692392, step = 463 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.30915\n","I0202 14:29:56.408948 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30915\n","INFO:tensorflow:loss = 3.2425096, step = 464 (0.764 sec)\n","I0202 14:29:56.409257 140715376195456 basic_session_run_hooks.py:260] loss = 3.2425096, step = 464 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 1.33322\n","I0202 14:29:57.159017 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33322\n","INFO:tensorflow:loss = 2.9199882, step = 465 (0.750 sec)\n","I0202 14:29:57.159310 140715376195456 basic_session_run_hooks.py:260] loss = 2.9199882, step = 465 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.31633\n","I0202 14:29:57.918708 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31633\n","INFO:tensorflow:loss = 2.4997134, step = 466 (0.760 sec)\n","I0202 14:29:57.919001 140715376195456 basic_session_run_hooks.py:260] loss = 2.4997134, step = 466 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 1.41906\n","I0202 14:29:58.623395 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41906\n","INFO:tensorflow:loss = 2.483652, step = 467 (0.705 sec)\n","I0202 14:29:58.623820 140715376195456 basic_session_run_hooks.py:260] loss = 2.483652, step = 467 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.3663\n","I0202 14:29:59.355292 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3663\n","INFO:tensorflow:loss = 2.4899101, step = 468 (0.732 sec)\n","I0202 14:29:59.355722 140715376195456 basic_session_run_hooks.py:260] loss = 2.4899101, step = 468 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.36666\n","I0202 14:30:00.087024 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36666\n","INFO:tensorflow:loss = 2.723469, step = 469 (0.732 sec)\n","I0202 14:30:00.087330 140715376195456 basic_session_run_hooks.py:260] loss = 2.723469, step = 469 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.36954\n","I0202 14:30:00.817188 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36954\n","INFO:tensorflow:loss = 2.3800836, step = 470 (0.730 sec)\n","I0202 14:30:00.817623 140715376195456 basic_session_run_hooks.py:260] loss = 2.3800836, step = 470 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.37214\n","I0202 14:30:01.545972 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37214\n","INFO:tensorflow:loss = 2.509431, step = 471 (0.729 sec)\n","I0202 14:30:01.546304 140715376195456 basic_session_run_hooks.py:260] loss = 2.509431, step = 471 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.36022\n","I0202 14:30:02.281152 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36022\n","INFO:tensorflow:loss = 2.7632544, step = 472 (0.735 sec)\n","I0202 14:30:02.281615 140715376195456 basic_session_run_hooks.py:260] loss = 2.7632544, step = 472 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35045\n","I0202 14:30:03.021645 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35045\n","INFO:tensorflow:loss = 2.891443, step = 473 (0.740 sec)\n","I0202 14:30:03.021972 140715376195456 basic_session_run_hooks.py:260] loss = 2.891443, step = 473 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36114\n","I0202 14:30:03.756311 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36114\n","INFO:tensorflow:loss = 2.8790843, step = 474 (0.735 sec)\n","I0202 14:30:03.756646 140715376195456 basic_session_run_hooks.py:260] loss = 2.8790843, step = 474 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.33123\n","I0202 14:30:04.507552 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33123\n","INFO:tensorflow:loss = 2.5497108, step = 475 (0.751 sec)\n","I0202 14:30:04.507885 140715376195456 basic_session_run_hooks.py:260] loss = 2.5497108, step = 475 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.32469\n","I0202 14:30:05.262411 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32469\n","INFO:tensorflow:loss = 3.1908126, step = 476 (0.755 sec)\n","I0202 14:30:05.262752 140715376195456 basic_session_run_hooks.py:260] loss = 3.1908126, step = 476 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.35032\n","I0202 14:30:06.002981 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35032\n","INFO:tensorflow:loss = 2.9058263, step = 477 (0.741 sec)\n","I0202 14:30:06.003323 140715376195456 basic_session_run_hooks.py:260] loss = 2.9058263, step = 477 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.36699\n","I0202 14:30:06.734523 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36699\n","INFO:tensorflow:loss = 2.8258488, step = 478 (0.732 sec)\n","I0202 14:30:06.734950 140715376195456 basic_session_run_hooks.py:260] loss = 2.8258488, step = 478 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.37192\n","I0202 14:30:07.463449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37192\n","INFO:tensorflow:loss = 2.6999707, step = 479 (0.729 sec)\n","I0202 14:30:07.463755 140715376195456 basic_session_run_hooks.py:260] loss = 2.6999707, step = 479 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.38768\n","I0202 14:30:08.184091 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38768\n","INFO:tensorflow:loss = 2.3503666, step = 480 (0.721 sec)\n","I0202 14:30:08.184587 140715376195456 basic_session_run_hooks.py:260] loss = 2.3503666, step = 480 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.39226\n","I0202 14:30:08.902307 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39226\n","INFO:tensorflow:loss = 3.4057896, step = 481 (0.718 sec)\n","I0202 14:30:08.902648 140715376195456 basic_session_run_hooks.py:260] loss = 3.4057896, step = 481 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.36371\n","I0202 14:30:09.635603 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36371\n","INFO:tensorflow:loss = 2.5149646, step = 482 (0.733 sec)\n","I0202 14:30:09.635910 140715376195456 basic_session_run_hooks.py:260] loss = 2.5149646, step = 482 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.38457\n","I0202 14:30:10.357839 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38457\n","INFO:tensorflow:loss = 2.9363773, step = 483 (0.722 sec)\n","I0202 14:30:10.358248 140715376195456 basic_session_run_hooks.py:260] loss = 2.9363773, step = 483 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.33782\n","I0202 14:30:11.105385 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33782\n","INFO:tensorflow:loss = 2.626111, step = 484 (0.748 sec)\n","I0202 14:30:11.105832 140715376195456 basic_session_run_hooks.py:260] loss = 2.626111, step = 484 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.36115\n","I0202 14:30:11.840001 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36115\n","INFO:tensorflow:loss = 3.142375, step = 485 (0.734 sec)\n","I0202 14:30:11.840319 140715376195456 basic_session_run_hooks.py:260] loss = 3.142375, step = 485 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.34379\n","I0202 14:30:12.584164 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34379\n","INFO:tensorflow:loss = 2.9968092, step = 486 (0.744 sec)\n","I0202 14:30:12.584482 140715376195456 basic_session_run_hooks.py:260] loss = 2.9968092, step = 486 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.37601\n","I0202 14:30:13.310897 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37601\n","INFO:tensorflow:loss = 2.9815538, step = 487 (0.727 sec)\n","I0202 14:30:13.311298 140715376195456 basic_session_run_hooks.py:260] loss = 2.9815538, step = 487 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.38206\n","I0202 14:30:14.034506 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38206\n","INFO:tensorflow:loss = 3.0972736, step = 488 (0.724 sec)\n","I0202 14:30:14.034814 140715376195456 basic_session_run_hooks.py:260] loss = 3.0972736, step = 488 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.38454\n","I0202 14:30:14.756733 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38454\n","INFO:tensorflow:loss = 2.79426, step = 489 (0.722 sec)\n","I0202 14:30:14.757104 140715376195456 basic_session_run_hooks.py:260] loss = 2.79426, step = 489 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.31273\n","I0202 14:30:15.518515 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31273\n","INFO:tensorflow:loss = 2.683807, step = 490 (0.762 sec)\n","I0202 14:30:15.518965 140715376195456 basic_session_run_hooks.py:260] loss = 2.683807, step = 490 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 1.38199\n","I0202 14:30:16.242087 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38199\n","INFO:tensorflow:loss = 2.9775615, step = 491 (0.723 sec)\n","I0202 14:30:16.242409 140715376195456 basic_session_run_hooks.py:260] loss = 2.9775615, step = 491 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.39349\n","I0202 14:30:16.959709 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39349\n","INFO:tensorflow:loss = 2.9567156, step = 492 (0.718 sec)\n","I0202 14:30:16.960156 140715376195456 basic_session_run_hooks.py:260] loss = 2.9567156, step = 492 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.42077\n","I0202 14:30:17.663585 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42077\n","INFO:tensorflow:loss = 2.5543823, step = 493 (0.704 sec)\n","I0202 14:30:17.663904 140715376195456 basic_session_run_hooks.py:260] loss = 2.5543823, step = 493 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.3791\n","I0202 14:30:18.388666 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3791\n","INFO:tensorflow:loss = 2.910149, step = 494 (0.725 sec)\n","I0202 14:30:18.389076 140715376195456 basic_session_run_hooks.py:260] loss = 2.910149, step = 494 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39042\n","I0202 14:30:19.107872 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39042\n","INFO:tensorflow:loss = 2.7413254, step = 495 (0.719 sec)\n","I0202 14:30:19.108305 140715376195456 basic_session_run_hooks.py:260] loss = 2.7413254, step = 495 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.41484\n","I0202 14:30:19.814686 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41484\n","INFO:tensorflow:loss = 2.9560292, step = 496 (0.707 sec)\n","I0202 14:30:19.815032 140715376195456 basic_session_run_hooks.py:260] loss = 2.9560292, step = 496 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 1.38875\n","I0202 14:30:20.534730 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38875\n","INFO:tensorflow:loss = 3.2111576, step = 497 (0.720 sec)\n","I0202 14:30:20.535135 140715376195456 basic_session_run_hooks.py:260] loss = 3.2111576, step = 497 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.36651\n","I0202 14:30:21.266558 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36651\n","INFO:tensorflow:loss = 2.9236598, step = 498 (0.732 sec)\n","I0202 14:30:21.266909 140715376195456 basic_session_run_hooks.py:260] loss = 2.9236598, step = 498 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.41679\n","I0202 14:30:21.972355 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41679\n","INFO:tensorflow:loss = 2.6012082, step = 499 (0.706 sec)\n","I0202 14:30:21.972793 140715376195456 basic_session_run_hooks.py:260] loss = 2.6012082, step = 499 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.38016\n","I0202 14:30:22.696911 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38016\n","INFO:tensorflow:loss = 3.2313452, step = 500 (0.725 sec)\n","I0202 14:30:22.697895 140715376195456 basic_session_run_hooks.py:260] loss = 3.2313452, step = 500 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36751\n","I0202 14:30:23.428166 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36751\n","INFO:tensorflow:loss = 3.0002851, step = 501 (0.731 sec)\n","I0202 14:30:23.428807 140715376195456 basic_session_run_hooks.py:260] loss = 3.0002851, step = 501 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.42473\n","I0202 14:30:24.130048 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42473\n","INFO:tensorflow:loss = 2.9949849, step = 502 (0.702 sec)\n","I0202 14:30:24.130367 140715376195456 basic_session_run_hooks.py:260] loss = 2.9949849, step = 502 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.35367\n","I0202 14:30:24.868794 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35367\n","INFO:tensorflow:loss = 2.413839, step = 503 (0.739 sec)\n","I0202 14:30:24.869086 140715376195456 basic_session_run_hooks.py:260] loss = 2.413839, step = 503 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.34975\n","I0202 14:30:25.609642 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34975\n","INFO:tensorflow:loss = 2.5438154, step = 504 (0.741 sec)\n","I0202 14:30:25.609951 140715376195456 basic_session_run_hooks.py:260] loss = 2.5438154, step = 504 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.30733\n","I0202 14:30:26.374588 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30733\n","INFO:tensorflow:loss = 2.9065654, step = 505 (0.765 sec)\n","I0202 14:30:26.374902 140715376195456 basic_session_run_hooks.py:260] loss = 2.9065654, step = 505 (0.765 sec)\n","INFO:tensorflow:global_step/sec: 1.39083\n","I0202 14:30:27.093604 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39083\n","INFO:tensorflow:loss = 3.2087493, step = 506 (0.719 sec)\n","I0202 14:30:27.093918 140715376195456 basic_session_run_hooks.py:260] loss = 3.2087493, step = 506 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.35446\n","I0202 14:30:27.831863 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35446\n","INFO:tensorflow:loss = 3.1342096, step = 507 (0.738 sec)\n","I0202 14:30:27.832170 140715376195456 basic_session_run_hooks.py:260] loss = 3.1342096, step = 507 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.4023\n","I0202 14:30:28.544973 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4023\n","INFO:tensorflow:loss = 3.0606735, step = 508 (0.713 sec)\n","I0202 14:30:28.545266 140715376195456 basic_session_run_hooks.py:260] loss = 3.0606735, step = 508 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.36086\n","I0202 14:30:29.279814 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36086\n","INFO:tensorflow:loss = 2.3809006, step = 509 (0.735 sec)\n","I0202 14:30:29.280122 140715376195456 basic_session_run_hooks.py:260] loss = 2.3809006, step = 509 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.38523\n","I0202 14:30:30.001733 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38523\n","INFO:tensorflow:loss = 3.3703146, step = 510 (0.722 sec)\n","I0202 14:30:30.002071 140715376195456 basic_session_run_hooks.py:260] loss = 3.3703146, step = 510 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36048\n","I0202 14:30:30.736758 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36048\n","INFO:tensorflow:loss = 2.6755638, step = 511 (0.735 sec)\n","I0202 14:30:30.737061 140715376195456 basic_session_run_hooks.py:260] loss = 2.6755638, step = 511 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35306\n","I0202 14:30:31.475812 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35306\n","INFO:tensorflow:loss = 2.7492874, step = 512 (0.739 sec)\n","I0202 14:30:31.476116 140715376195456 basic_session_run_hooks.py:260] loss = 2.7492874, step = 512 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.38264\n","I0202 14:30:32.199081 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38264\n","INFO:tensorflow:loss = 2.4524348, step = 513 (0.723 sec)\n","I0202 14:30:32.199383 140715376195456 basic_session_run_hooks.py:260] loss = 2.4524348, step = 513 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37852\n","I0202 14:30:32.924492 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37852\n","INFO:tensorflow:loss = 2.7938623, step = 514 (0.725 sec)\n","I0202 14:30:32.924786 140715376195456 basic_session_run_hooks.py:260] loss = 2.7938623, step = 514 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36842\n","I0202 14:30:33.655258 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36842\n","INFO:tensorflow:loss = 2.9130678, step = 515 (0.731 sec)\n","I0202 14:30:33.655722 140715376195456 basic_session_run_hooks.py:260] loss = 2.9130678, step = 515 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.34563\n","I0202 14:30:34.398399 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34563\n","INFO:tensorflow:loss = 2.7365615, step = 516 (0.743 sec)\n","I0202 14:30:34.398720 140715376195456 basic_session_run_hooks.py:260] loss = 2.7365615, step = 516 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.37198\n","I0202 14:30:35.127303 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37198\n","INFO:tensorflow:loss = 2.455582, step = 517 (0.729 sec)\n","I0202 14:30:35.127810 140715376195456 basic_session_run_hooks.py:260] loss = 2.455582, step = 517 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.35943\n","I0202 14:30:35.862884 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35943\n","INFO:tensorflow:loss = 2.6156304, step = 518 (0.735 sec)\n","I0202 14:30:35.863274 140715376195456 basic_session_run_hooks.py:260] loss = 2.6156304, step = 518 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.30137\n","I0202 14:30:36.631328 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30137\n","INFO:tensorflow:loss = 3.046715, step = 519 (0.769 sec)\n","I0202 14:30:36.631858 140715376195456 basic_session_run_hooks.py:260] loss = 3.046715, step = 519 (0.769 sec)\n","INFO:tensorflow:global_step/sec: 1.33631\n","I0202 14:30:37.379618 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33631\n","INFO:tensorflow:loss = 2.595584, step = 520 (0.748 sec)\n","I0202 14:30:37.379925 140715376195456 basic_session_run_hooks.py:260] loss = 2.595584, step = 520 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.42789\n","I0202 14:30:38.079963 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42789\n","INFO:tensorflow:loss = 2.9038558, step = 521 (0.700 sec)\n","I0202 14:30:38.080263 140715376195456 basic_session_run_hooks.py:260] loss = 2.9038558, step = 521 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.32695\n","I0202 14:30:38.833589 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32695\n","INFO:tensorflow:loss = 2.614873, step = 522 (0.754 sec)\n","I0202 14:30:38.833902 140715376195456 basic_session_run_hooks.py:260] loss = 2.614873, step = 522 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.3945\n","I0202 14:30:39.550690 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3945\n","INFO:tensorflow:loss = 3.2148573, step = 523 (0.717 sec)\n","I0202 14:30:39.550993 140715376195456 basic_session_run_hooks.py:260] loss = 3.2148573, step = 523 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.3368\n","I0202 14:30:40.298751 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3368\n","INFO:tensorflow:loss = 2.4226668, step = 524 (0.748 sec)\n","I0202 14:30:40.299255 140715376195456 basic_session_run_hooks.py:260] loss = 2.4226668, step = 524 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.40099\n","I0202 14:30:41.012549 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40099\n","INFO:tensorflow:loss = 2.5205064, step = 525 (0.714 sec)\n","I0202 14:30:41.012851 140715376195456 basic_session_run_hooks.py:260] loss = 2.5205064, step = 525 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.35164\n","I0202 14:30:41.752367 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35164\n","INFO:tensorflow:loss = 2.6758397, step = 526 (0.740 sec)\n","I0202 14:30:41.752694 140715376195456 basic_session_run_hooks.py:260] loss = 2.6758397, step = 526 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.32323\n","I0202 14:30:42.508068 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32323\n","INFO:tensorflow:loss = 2.2774088, step = 527 (0.756 sec)\n","I0202 14:30:42.508372 140715376195456 basic_session_run_hooks.py:260] loss = 2.2774088, step = 527 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.38504\n","I0202 14:30:43.230117 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38504\n","INFO:tensorflow:loss = 2.9592743, step = 528 (0.722 sec)\n","I0202 14:30:43.230454 140715376195456 basic_session_run_hooks.py:260] loss = 2.9592743, step = 528 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.37266\n","I0202 14:30:43.958632 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37266\n","INFO:tensorflow:loss = 3.0720208, step = 529 (0.729 sec)\n","I0202 14:30:43.959130 140715376195456 basic_session_run_hooks.py:260] loss = 3.0720208, step = 529 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.39139\n","I0202 14:30:44.677309 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39139\n","INFO:tensorflow:loss = 2.6899323, step = 530 (0.719 sec)\n","I0202 14:30:44.677801 140715376195456 basic_session_run_hooks.py:260] loss = 2.6899323, step = 530 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.35908\n","I0202 14:30:45.413091 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35908\n","INFO:tensorflow:loss = 2.8062472, step = 531 (0.736 sec)\n","I0202 14:30:45.413389 140715376195456 basic_session_run_hooks.py:260] loss = 2.8062472, step = 531 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.37129\n","I0202 14:30:46.142378 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37129\n","INFO:tensorflow:loss = 3.0194135, step = 532 (0.730 sec)\n","I0202 14:30:46.142901 140715376195456 basic_session_run_hooks.py:260] loss = 3.0194135, step = 532 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.33373\n","I0202 14:30:46.892097 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33373\n","INFO:tensorflow:loss = 2.4702492, step = 533 (0.749 sec)\n","I0202 14:30:46.892395 140715376195456 basic_session_run_hooks.py:260] loss = 2.4702492, step = 533 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.32534\n","I0202 14:30:47.646631 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32534\n","INFO:tensorflow:loss = 2.7808325, step = 534 (0.755 sec)\n","I0202 14:30:47.646945 140715376195456 basic_session_run_hooks.py:260] loss = 2.7808325, step = 534 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.38423\n","I0202 14:30:48.369057 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38423\n","INFO:tensorflow:loss = 2.4460804, step = 535 (0.722 sec)\n","I0202 14:30:48.369369 140715376195456 basic_session_run_hooks.py:260] loss = 2.4460804, step = 535 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.39681\n","I0202 14:30:49.084983 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39681\n","INFO:tensorflow:loss = 2.9561052, step = 536 (0.716 sec)\n","I0202 14:30:49.085488 140715376195456 basic_session_run_hooks.py:260] loss = 2.9561052, step = 536 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.37513\n","I0202 14:30:49.812159 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37513\n","INFO:tensorflow:loss = 2.7943394, step = 537 (0.727 sec)\n","I0202 14:30:49.812466 140715376195456 basic_session_run_hooks.py:260] loss = 2.7943394, step = 537 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.37369\n","I0202 14:30:50.540159 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37369\n","INFO:tensorflow:loss = 2.7230673, step = 538 (0.728 sec)\n","I0202 14:30:50.540660 140715376195456 basic_session_run_hooks.py:260] loss = 2.7230673, step = 538 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.37901\n","I0202 14:30:51.265282 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37901\n","INFO:tensorflow:loss = 2.8856008, step = 539 (0.725 sec)\n","I0202 14:30:51.265612 140715376195456 basic_session_run_hooks.py:260] loss = 2.8856008, step = 539 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.38239\n","I0202 14:30:51.988695 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38239\n","INFO:tensorflow:loss = 2.7685914, step = 540 (0.723 sec)\n","I0202 14:30:51.989036 140715376195456 basic_session_run_hooks.py:260] loss = 2.7685914, step = 540 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37067\n","I0202 14:30:52.718235 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37067\n","INFO:tensorflow:loss = 3.5103374, step = 541 (0.730 sec)\n","I0202 14:30:52.718750 140715376195456 basic_session_run_hooks.py:260] loss = 3.5103374, step = 541 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.38454\n","I0202 14:30:53.440536 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38454\n","INFO:tensorflow:loss = 2.2763424, step = 542 (0.722 sec)\n","I0202 14:30:53.440871 140715376195456 basic_session_run_hooks.py:260] loss = 2.2763424, step = 542 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.3787\n","I0202 14:30:54.165845 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3787\n","INFO:tensorflow:loss = 3.080332, step = 543 (0.725 sec)\n","I0202 14:30:54.166141 140715376195456 basic_session_run_hooks.py:260] loss = 3.080332, step = 543 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.37282\n","I0202 14:30:54.894272 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37282\n","INFO:tensorflow:loss = 2.295583, step = 544 (0.729 sec)\n","I0202 14:30:54.894772 140715376195456 basic_session_run_hooks.py:260] loss = 2.295583, step = 544 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.37194\n","I0202 14:30:55.623181 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37194\n","INFO:tensorflow:loss = 2.5741806, step = 545 (0.729 sec)\n","I0202 14:30:55.623541 140715376195456 basic_session_run_hooks.py:260] loss = 2.5741806, step = 545 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.3591\n","I0202 14:30:56.358932 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3591\n","INFO:tensorflow:loss = 2.9821558, step = 546 (0.736 sec)\n","I0202 14:30:56.359221 140715376195456 basic_session_run_hooks.py:260] loss = 2.9821558, step = 546 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.37325\n","I0202 14:30:57.087226 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37325\n","INFO:tensorflow:loss = 2.7039478, step = 547 (0.728 sec)\n","I0202 14:30:57.087637 140715376195456 basic_session_run_hooks.py:260] loss = 2.7039478, step = 547 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.32202\n","I0202 14:30:57.843578 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32202\n","INFO:tensorflow:loss = 2.9908373, step = 548 (0.756 sec)\n","I0202 14:30:57.843882 140715376195456 basic_session_run_hooks.py:260] loss = 2.9908373, step = 548 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.37776\n","I0202 14:30:58.569360 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37776\n","INFO:tensorflow:loss = 2.72166, step = 549 (0.726 sec)\n","I0202 14:30:58.569713 140715376195456 basic_session_run_hooks.py:260] loss = 2.72166, step = 549 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.36101\n","I0202 14:30:59.304113 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36101\n","INFO:tensorflow:loss = 2.4838278, step = 550 (0.735 sec)\n","I0202 14:30:59.304589 140715376195456 basic_session_run_hooks.py:260] loss = 2.4838278, step = 550 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.37849\n","I0202 14:31:00.029589 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37849\n","INFO:tensorflow:loss = 2.5540216, step = 551 (0.725 sec)\n","I0202 14:31:00.029932 140715376195456 basic_session_run_hooks.py:260] loss = 2.5540216, step = 551 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.3924\n","I0202 14:31:00.747722 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3924\n","INFO:tensorflow:loss = 2.6784792, step = 552 (0.718 sec)\n","I0202 14:31:00.748026 140715376195456 basic_session_run_hooks.py:260] loss = 2.6784792, step = 552 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.38342\n","I0202 14:31:01.470603 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38342\n","INFO:tensorflow:loss = 3.185681, step = 553 (0.723 sec)\n","I0202 14:31:01.470912 140715376195456 basic_session_run_hooks.py:260] loss = 3.185681, step = 553 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.40973\n","I0202 14:31:02.179942 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40973\n","INFO:tensorflow:loss = 2.6688619, step = 554 (0.709 sec)\n","I0202 14:31:02.180264 140715376195456 basic_session_run_hooks.py:260] loss = 2.6688619, step = 554 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.35492\n","I0202 14:31:02.917986 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35492\n","INFO:tensorflow:loss = 2.677106, step = 555 (0.738 sec)\n","I0202 14:31:02.918302 140715376195456 basic_session_run_hooks.py:260] loss = 2.677106, step = 555 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.35324\n","I0202 14:31:03.656946 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35324\n","INFO:tensorflow:loss = 2.478939, step = 556 (0.739 sec)\n","I0202 14:31:03.657250 140715376195456 basic_session_run_hooks.py:260] loss = 2.478939, step = 556 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.35394\n","I0202 14:31:04.395562 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35394\n","INFO:tensorflow:loss = 2.8021324, step = 557 (0.739 sec)\n","I0202 14:31:04.395862 140715376195456 basic_session_run_hooks.py:260] loss = 2.8021324, step = 557 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.37725\n","I0202 14:31:05.121621 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37725\n","INFO:tensorflow:loss = 2.5779812, step = 558 (0.726 sec)\n","I0202 14:31:05.121948 140715376195456 basic_session_run_hooks.py:260] loss = 2.5779812, step = 558 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38321\n","I0202 14:31:05.844605 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38321\n","INFO:tensorflow:loss = 2.6296115, step = 559 (0.723 sec)\n","I0202 14:31:05.844903 140715376195456 basic_session_run_hooks.py:260] loss = 2.6296115, step = 559 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37872\n","I0202 14:31:06.569904 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37872\n","INFO:tensorflow:loss = 2.9346228, step = 560 (0.725 sec)\n","I0202 14:31:06.570209 140715376195456 basic_session_run_hooks.py:260] loss = 2.9346228, step = 560 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.40185\n","I0202 14:31:07.283220 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40185\n","INFO:tensorflow:loss = 2.5660915, step = 561 (0.714 sec)\n","I0202 14:31:07.283721 140715376195456 basic_session_run_hooks.py:260] loss = 2.5660915, step = 561 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.37921\n","I0202 14:31:08.008283 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37921\n","INFO:tensorflow:loss = 2.5969567, step = 562 (0.725 sec)\n","I0202 14:31:08.008610 140715376195456 basic_session_run_hooks.py:260] loss = 2.5969567, step = 562 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39486\n","I0202 14:31:08.725183 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39486\n","INFO:tensorflow:loss = 2.966094, step = 563 (0.717 sec)\n","I0202 14:31:08.725501 140715376195456 basic_session_run_hooks.py:260] loss = 2.966094, step = 563 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.39085\n","I0202 14:31:09.444188 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39085\n","INFO:tensorflow:loss = 2.899629, step = 564 (0.719 sec)\n","I0202 14:31:09.444506 140715376195456 basic_session_run_hooks.py:260] loss = 2.899629, step = 564 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.38444\n","I0202 14:31:10.166510 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38444\n","INFO:tensorflow:loss = 2.839495, step = 565 (0.722 sec)\n","I0202 14:31:10.166982 140715376195456 basic_session_run_hooks.py:260] loss = 2.839495, step = 565 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.34715\n","I0202 14:31:10.908817 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34715\n","INFO:tensorflow:loss = 2.6632004, step = 566 (0.742 sec)\n","I0202 14:31:10.909121 140715376195456 basic_session_run_hooks.py:260] loss = 2.6632004, step = 566 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.32972\n","I0202 14:31:11.660835 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32972\n","INFO:tensorflow:loss = 2.7682104, step = 567 (0.752 sec)\n","I0202 14:31:11.661187 140715376195456 basic_session_run_hooks.py:260] loss = 2.7682104, step = 567 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 1.32281\n","I0202 14:31:12.416795 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32281\n","INFO:tensorflow:loss = 2.9420748, step = 568 (0.756 sec)\n","I0202 14:31:12.417085 140715376195456 basic_session_run_hooks.py:260] loss = 2.9420748, step = 568 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.35749\n","I0202 14:31:13.153479 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35749\n","INFO:tensorflow:loss = 2.9241512, step = 569 (0.737 sec)\n","I0202 14:31:13.153787 140715376195456 basic_session_run_hooks.py:260] loss = 2.9241512, step = 569 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.2887\n","I0202 14:31:13.929441 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.2887\n","INFO:tensorflow:loss = 3.3587635, step = 570 (0.776 sec)\n","I0202 14:31:13.929956 140715376195456 basic_session_run_hooks.py:260] loss = 3.3587635, step = 570 (0.776 sec)\n","INFO:tensorflow:global_step/sec: 1.38141\n","I0202 14:31:14.653338 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38141\n","INFO:tensorflow:loss = 2.365406, step = 571 (0.724 sec)\n","I0202 14:31:14.653864 140715376195456 basic_session_run_hooks.py:260] loss = 2.365406, step = 571 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.35247\n","I0202 14:31:15.392710 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35247\n","INFO:tensorflow:loss = 2.2465115, step = 572 (0.739 sec)\n","I0202 14:31:15.393211 140715376195456 basic_session_run_hooks.py:260] loss = 2.2465115, step = 572 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.34551\n","I0202 14:31:16.135940 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34551\n","INFO:tensorflow:loss = 3.0870647, step = 573 (0.743 sec)\n","I0202 14:31:16.136265 140715376195456 basic_session_run_hooks.py:260] loss = 3.0870647, step = 573 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.34256\n","I0202 14:31:16.880773 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34256\n","INFO:tensorflow:loss = 3.2215369, step = 574 (0.745 sec)\n","I0202 14:31:16.881305 140715376195456 basic_session_run_hooks.py:260] loss = 3.2215369, step = 574 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.41318\n","I0202 14:31:17.588392 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41318\n","INFO:tensorflow:loss = 2.7410252, step = 575 (0.708 sec)\n","I0202 14:31:17.588937 140715376195456 basic_session_run_hooks.py:260] loss = 2.7410252, step = 575 (0.708 sec)\n","INFO:tensorflow:global_step/sec: 1.31957\n","I0202 14:31:18.346214 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31957\n","INFO:tensorflow:loss = 2.5850515, step = 576 (0.758 sec)\n","I0202 14:31:18.346711 140715376195456 basic_session_run_hooks.py:260] loss = 2.5850515, step = 576 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 1.37937\n","I0202 14:31:19.071211 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37937\n","INFO:tensorflow:loss = 2.4055066, step = 577 (0.725 sec)\n","I0202 14:31:19.071532 140715376195456 basic_session_run_hooks.py:260] loss = 2.4055066, step = 577 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.39826\n","I0202 14:31:19.786382 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39826\n","INFO:tensorflow:loss = 2.3010092, step = 578 (0.715 sec)\n","I0202 14:31:19.786902 140715376195456 basic_session_run_hooks.py:260] loss = 2.3010092, step = 578 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.36863\n","I0202 14:31:20.517022 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36863\n","INFO:tensorflow:loss = 2.550178, step = 579 (0.730 sec)\n","I0202 14:31:20.517320 140715376195456 basic_session_run_hooks.py:260] loss = 2.550178, step = 579 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.39457\n","I0202 14:31:21.234095 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39457\n","INFO:tensorflow:loss = 2.4803622, step = 580 (0.717 sec)\n","I0202 14:31:21.234398 140715376195456 basic_session_run_hooks.py:260] loss = 2.4803622, step = 580 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.38658\n","I0202 14:31:21.955299 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38658\n","INFO:tensorflow:loss = 3.0860624, step = 581 (0.721 sec)\n","I0202 14:31:21.955632 140715376195456 basic_session_run_hooks.py:260] loss = 3.0860624, step = 581 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.35325\n","I0202 14:31:22.694270 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35325\n","INFO:tensorflow:loss = 2.7251148, step = 582 (0.739 sec)\n","I0202 14:31:22.694773 140715376195456 basic_session_run_hooks.py:260] loss = 2.7251148, step = 582 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.36354\n","I0202 14:31:23.427654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36354\n","INFO:tensorflow:loss = 2.749702, step = 583 (0.733 sec)\n","I0202 14:31:23.427957 140715376195456 basic_session_run_hooks.py:260] loss = 2.749702, step = 583 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.33743\n","I0202 14:31:24.175334 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33743\n","INFO:tensorflow:loss = 2.7549007, step = 584 (0.748 sec)\n","I0202 14:31:24.175899 140715376195456 basic_session_run_hooks.py:260] loss = 2.7549007, step = 584 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.38632\n","I0202 14:31:24.896671 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38632\n","INFO:tensorflow:loss = 2.5164158, step = 585 (0.721 sec)\n","I0202 14:31:24.897152 140715376195456 basic_session_run_hooks.py:260] loss = 2.5164158, step = 585 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.35172\n","I0202 14:31:25.636477 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35172\n","INFO:tensorflow:loss = 3.0123556, step = 586 (0.740 sec)\n","I0202 14:31:25.636978 140715376195456 basic_session_run_hooks.py:260] loss = 3.0123556, step = 586 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.37463\n","I0202 14:31:26.363932 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37463\n","INFO:tensorflow:loss = 2.4000041, step = 587 (0.727 sec)\n","I0202 14:31:26.364250 140715376195456 basic_session_run_hooks.py:260] loss = 2.4000041, step = 587 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.38255\n","I0202 14:31:27.087260 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38255\n","INFO:tensorflow:loss = 2.6841216, step = 588 (0.724 sec)\n","I0202 14:31:27.087824 140715376195456 basic_session_run_hooks.py:260] loss = 2.6841216, step = 588 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.32203\n","I0202 14:31:27.843654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32203\n","INFO:tensorflow:loss = 2.492052, step = 589 (0.756 sec)\n","I0202 14:31:27.843964 140715376195456 basic_session_run_hooks.py:260] loss = 2.492052, step = 589 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.3314\n","I0202 14:31:28.594753 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3314\n","INFO:tensorflow:loss = 2.5803475, step = 590 (0.751 sec)\n","I0202 14:31:28.595238 140715376195456 basic_session_run_hooks.py:260] loss = 2.5803475, step = 590 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.3158\n","I0202 14:31:29.354725 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3158\n","INFO:tensorflow:loss = 2.9008238, step = 591 (0.760 sec)\n","I0202 14:31:29.355257 140715376195456 basic_session_run_hooks.py:260] loss = 2.9008238, step = 591 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 1.33796\n","I0202 14:31:30.102150 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33796\n","INFO:tensorflow:loss = 2.7102654, step = 592 (0.747 sec)\n","I0202 14:31:30.102664 140715376195456 basic_session_run_hooks.py:260] loss = 2.7102654, step = 592 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.34844\n","I0202 14:31:30.843761 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34844\n","INFO:tensorflow:loss = 2.8080492, step = 593 (0.742 sec)\n","I0202 14:31:30.844303 140715376195456 basic_session_run_hooks.py:260] loss = 2.8080492, step = 593 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.36202\n","I0202 14:31:31.577942 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36202\n","INFO:tensorflow:loss = 3.209667, step = 594 (0.734 sec)\n","I0202 14:31:31.578247 140715376195456 basic_session_run_hooks.py:260] loss = 3.209667, step = 594 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.3605\n","I0202 14:31:32.312967 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3605\n","INFO:tensorflow:loss = 2.949155, step = 595 (0.735 sec)\n","I0202 14:31:32.313495 140715376195456 basic_session_run_hooks.py:260] loss = 2.949155, step = 595 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.36371\n","I0202 14:31:33.046256 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36371\n","INFO:tensorflow:loss = 2.71977, step = 596 (0.733 sec)\n","I0202 14:31:33.046778 140715376195456 basic_session_run_hooks.py:260] loss = 2.71977, step = 596 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.34543\n","I0202 14:31:33.789534 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34543\n","INFO:tensorflow:loss = 3.0178182, step = 597 (0.743 sec)\n","I0202 14:31:33.789851 140715376195456 basic_session_run_hooks.py:260] loss = 3.0178182, step = 597 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.34773\n","I0202 14:31:34.531513 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34773\n","INFO:tensorflow:loss = 2.5904472, step = 598 (0.742 sec)\n","I0202 14:31:34.531818 140715376195456 basic_session_run_hooks.py:260] loss = 2.5904472, step = 598 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.39431\n","I0202 14:31:35.248688 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39431\n","INFO:tensorflow:loss = 2.5809278, step = 599 (0.717 sec)\n","I0202 14:31:35.248980 140715376195456 basic_session_run_hooks.py:260] loss = 2.5809278, step = 599 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.36642\n","I0202 14:31:35.980581 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36642\n","INFO:tensorflow:loss = 3.1700752, step = 600 (0.733 sec)\n","I0202 14:31:35.981890 140715376195456 basic_session_run_hooks.py:260] loss = 3.1700752, step = 600 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.39592\n","I0202 14:31:36.696949 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39592\n","INFO:tensorflow:loss = 2.7225585, step = 601 (0.716 sec)\n","I0202 14:31:36.697564 140715376195456 basic_session_run_hooks.py:260] loss = 2.7225585, step = 601 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.3497\n","I0202 14:31:37.437826 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3497\n","INFO:tensorflow:loss = 2.8258102, step = 602 (0.741 sec)\n","I0202 14:31:37.438243 140715376195456 basic_session_run_hooks.py:260] loss = 2.8258102, step = 602 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.38421\n","I0202 14:31:38.160248 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38421\n","INFO:tensorflow:loss = 2.6221342, step = 603 (0.722 sec)\n","I0202 14:31:38.160592 140715376195456 basic_session_run_hooks.py:260] loss = 2.6221342, step = 603 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36163\n","I0202 14:31:38.894662 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36163\n","INFO:tensorflow:loss = 2.2317655, step = 604 (0.734 sec)\n","I0202 14:31:38.894962 140715376195456 basic_session_run_hooks.py:260] loss = 2.2317655, step = 604 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.35402\n","I0202 14:31:39.633210 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35402\n","INFO:tensorflow:loss = 2.7111957, step = 605 (0.739 sec)\n","I0202 14:31:39.633568 140715376195456 basic_session_run_hooks.py:260] loss = 2.7111957, step = 605 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.35272\n","I0202 14:31:40.372512 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35272\n","INFO:tensorflow:loss = 3.0315208, step = 606 (0.739 sec)\n","I0202 14:31:40.372845 140715376195456 basic_session_run_hooks.py:260] loss = 3.0315208, step = 606 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.40777\n","I0202 14:31:41.082811 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40777\n","INFO:tensorflow:loss = 2.8309436, step = 607 (0.710 sec)\n","I0202 14:31:41.083244 140715376195456 basic_session_run_hooks.py:260] loss = 2.8309436, step = 607 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.38342\n","I0202 14:31:41.805646 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38342\n","INFO:tensorflow:loss = 2.2626307, step = 608 (0.723 sec)\n","I0202 14:31:41.806064 140715376195456 basic_session_run_hooks.py:260] loss = 2.2626307, step = 608 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.32775\n","I0202 14:31:42.558799 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32775\n","INFO:tensorflow:loss = 2.857999, step = 609 (0.753 sec)\n","I0202 14:31:42.559098 140715376195456 basic_session_run_hooks.py:260] loss = 2.857999, step = 609 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.37542\n","I0202 14:31:43.285862 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37542\n","INFO:tensorflow:loss = 3.027207, step = 610 (0.727 sec)\n","I0202 14:31:43.286270 140715376195456 basic_session_run_hooks.py:260] loss = 3.027207, step = 610 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.42974\n","I0202 14:31:43.985268 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42974\n","INFO:tensorflow:loss = 2.8760653, step = 611 (0.699 sec)\n","I0202 14:31:43.985588 140715376195456 basic_session_run_hooks.py:260] loss = 2.8760653, step = 611 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 1.3371\n","I0202 14:31:44.733168 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3371\n","INFO:tensorflow:loss = 3.0150776, step = 612 (0.748 sec)\n","I0202 14:31:44.733613 140715376195456 basic_session_run_hooks.py:260] loss = 3.0150776, step = 612 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.37891\n","I0202 14:31:45.458382 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37891\n","INFO:tensorflow:loss = 3.6101625, step = 613 (0.725 sec)\n","I0202 14:31:45.458852 140715376195456 basic_session_run_hooks.py:260] loss = 3.6101625, step = 613 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.40089\n","I0202 14:31:46.172215 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40089\n","INFO:tensorflow:loss = 2.7518272, step = 614 (0.714 sec)\n","I0202 14:31:46.172740 140715376195456 basic_session_run_hooks.py:260] loss = 2.7518272, step = 614 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.35687\n","I0202 14:31:46.909189 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35687\n","INFO:tensorflow:loss = 2.87052, step = 615 (0.737 sec)\n","I0202 14:31:46.909666 140715376195456 basic_session_run_hooks.py:260] loss = 2.87052, step = 615 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37021\n","I0202 14:31:47.639013 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37021\n","INFO:tensorflow:loss = 2.674565, step = 616 (0.730 sec)\n","I0202 14:31:47.639464 140715376195456 basic_session_run_hooks.py:260] loss = 2.674565, step = 616 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.32452\n","I0202 14:31:48.394032 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32452\n","INFO:tensorflow:loss = 2.32261, step = 617 (0.755 sec)\n","I0202 14:31:48.394500 140715376195456 basic_session_run_hooks.py:260] loss = 2.32261, step = 617 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.36153\n","I0202 14:31:49.128512 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36153\n","INFO:tensorflow:loss = 2.4078028, step = 618 (0.734 sec)\n","I0202 14:31:49.128954 140715376195456 basic_session_run_hooks.py:260] loss = 2.4078028, step = 618 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.33963\n","I0202 14:31:49.874961 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33963\n","INFO:tensorflow:loss = 2.9118109, step = 619 (0.746 sec)\n","I0202 14:31:49.875435 140715376195456 basic_session_run_hooks.py:260] loss = 2.9118109, step = 619 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.33762\n","I0202 14:31:50.622568 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33762\n","INFO:tensorflow:loss = 2.2563388, step = 620 (0.747 sec)\n","I0202 14:31:50.622879 140715376195456 basic_session_run_hooks.py:260] loss = 2.2563388, step = 620 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.32886\n","I0202 14:31:51.375077 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32886\n","INFO:tensorflow:loss = 2.5853884, step = 621 (0.753 sec)\n","I0202 14:31:51.375562 140715376195456 basic_session_run_hooks.py:260] loss = 2.5853884, step = 621 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.33236\n","I0202 14:31:52.125632 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33236\n","INFO:tensorflow:loss = 2.572051, step = 622 (0.751 sec)\n","I0202 14:31:52.126090 140715376195456 basic_session_run_hooks.py:260] loss = 2.572051, step = 622 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.30982\n","I0202 14:31:52.889078 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30982\n","INFO:tensorflow:loss = 2.814441, step = 623 (0.763 sec)\n","I0202 14:31:52.889389 140715376195456 basic_session_run_hooks.py:260] loss = 2.814441, step = 623 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 1.31675\n","I0202 14:31:53.648555 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31675\n","INFO:tensorflow:loss = 2.7454054, step = 624 (0.759 sec)\n","I0202 14:31:53.648862 140715376195456 basic_session_run_hooks.py:260] loss = 2.7454054, step = 624 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 1.35815\n","I0202 14:31:54.384810 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35815\n","INFO:tensorflow:loss = 2.2381327, step = 625 (0.736 sec)\n","I0202 14:31:54.385266 140715376195456 basic_session_run_hooks.py:260] loss = 2.2381327, step = 625 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.39453\n","I0202 14:31:55.101910 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39453\n","INFO:tensorflow:loss = 2.486476, step = 626 (0.717 sec)\n","I0202 14:31:55.102224 140715376195456 basic_session_run_hooks.py:260] loss = 2.486476, step = 626 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.36136\n","I0202 14:31:55.836503 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36136\n","INFO:tensorflow:loss = 3.1359513, step = 627 (0.735 sec)\n","I0202 14:31:55.836813 140715376195456 basic_session_run_hooks.py:260] loss = 3.1359513, step = 627 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.34267\n","I0202 14:31:56.581265 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34267\n","INFO:tensorflow:loss = 2.7078123, step = 628 (0.745 sec)\n","I0202 14:31:56.581699 140715376195456 basic_session_run_hooks.py:260] loss = 2.7078123, step = 628 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.41872\n","I0202 14:31:57.286128 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41872\n","INFO:tensorflow:loss = 2.6381223, step = 629 (0.705 sec)\n","I0202 14:31:57.286489 140715376195456 basic_session_run_hooks.py:260] loss = 2.6381223, step = 629 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.40772\n","I0202 14:31:57.996492 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40772\n","INFO:tensorflow:loss = 2.8136058, step = 630 (0.710 sec)\n","I0202 14:31:57.996909 140715376195456 basic_session_run_hooks.py:260] loss = 2.8136058, step = 630 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.34603\n","I0202 14:31:58.739413 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34603\n","INFO:tensorflow:loss = 2.3244884, step = 631 (0.743 sec)\n","I0202 14:31:58.739757 140715376195456 basic_session_run_hooks.py:260] loss = 2.3244884, step = 631 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.32303\n","I0202 14:31:59.495258 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32303\n","INFO:tensorflow:loss = 2.6521866, step = 632 (0.756 sec)\n","I0202 14:31:59.495613 140715376195456 basic_session_run_hooks.py:260] loss = 2.6521866, step = 632 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.44548\n","I0202 14:32:00.187052 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.44548\n","INFO:tensorflow:loss = 3.064522, step = 633 (0.692 sec)\n","I0202 14:32:00.187509 140715376195456 basic_session_run_hooks.py:260] loss = 3.064522, step = 633 (0.692 sec)\n","INFO:tensorflow:global_step/sec: 1.37936\n","I0202 14:32:00.912040 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37936\n","INFO:tensorflow:loss = 2.7318072, step = 634 (0.725 sec)\n","I0202 14:32:00.912339 140715376195456 basic_session_run_hooks.py:260] loss = 2.7318072, step = 634 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.35072\n","I0202 14:32:01.652383 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35072\n","INFO:tensorflow:loss = 2.3440886, step = 635 (0.741 sec)\n","I0202 14:32:01.652845 140715376195456 basic_session_run_hooks.py:260] loss = 2.3440886, step = 635 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.36878\n","I0202 14:32:02.382978 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36878\n","INFO:tensorflow:loss = 2.7301319, step = 636 (0.731 sec)\n","I0202 14:32:02.383412 140715376195456 basic_session_run_hooks.py:260] loss = 2.7301319, step = 636 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.41109\n","I0202 14:32:03.091640 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41109\n","INFO:tensorflow:loss = 2.5945468, step = 637 (0.709 sec)\n","I0202 14:32:03.091950 140715376195456 basic_session_run_hooks.py:260] loss = 2.5945468, step = 637 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.40588\n","I0202 14:32:03.802925 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40588\n","INFO:tensorflow:loss = 2.7846808, step = 638 (0.711 sec)\n","I0202 14:32:03.803329 140715376195456 basic_session_run_hooks.py:260] loss = 2.7846808, step = 638 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.33783\n","I0202 14:32:04.550409 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33783\n","INFO:tensorflow:loss = 2.5270278, step = 639 (0.747 sec)\n","I0202 14:32:04.550733 140715376195456 basic_session_run_hooks.py:260] loss = 2.5270278, step = 639 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.3978\n","I0202 14:32:05.265853 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3978\n","INFO:tensorflow:loss = 2.686809, step = 640 (0.715 sec)\n","I0202 14:32:05.266154 140715376195456 basic_session_run_hooks.py:260] loss = 2.686809, step = 640 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.35319\n","I0202 14:32:06.004847 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35319\n","INFO:tensorflow:loss = 2.1584277, step = 641 (0.739 sec)\n","I0202 14:32:06.005351 140715376195456 basic_session_run_hooks.py:260] loss = 2.1584277, step = 641 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.31664\n","I0202 14:32:06.764355 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31664\n","INFO:tensorflow:loss = 2.9191153, step = 642 (0.759 sec)\n","I0202 14:32:06.764795 140715376195456 basic_session_run_hooks.py:260] loss = 2.9191153, step = 642 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 1.33313\n","I0202 14:32:07.514449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33313\n","INFO:tensorflow:loss = 2.6118927, step = 643 (0.750 sec)\n","I0202 14:32:07.514904 140715376195456 basic_session_run_hooks.py:260] loss = 2.6118927, step = 643 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.39358\n","I0202 14:32:08.232050 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39358\n","INFO:tensorflow:loss = 2.8276653, step = 644 (0.718 sec)\n","I0202 14:32:08.232546 140715376195456 basic_session_run_hooks.py:260] loss = 2.8276653, step = 644 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.30578\n","I0202 14:32:08.997849 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30578\n","INFO:tensorflow:loss = 2.85135, step = 645 (0.766 sec)\n","I0202 14:32:08.998173 140715376195456 basic_session_run_hooks.py:260] loss = 2.85135, step = 645 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 1.31348\n","I0202 14:32:09.759178 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31348\n","INFO:tensorflow:loss = 2.7354968, step = 646 (0.761 sec)\n","I0202 14:32:09.759609 140715376195456 basic_session_run_hooks.py:260] loss = 2.7354968, step = 646 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 1.3355\n","I0202 14:32:10.507960 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3355\n","INFO:tensorflow:loss = 2.5679426, step = 647 (0.749 sec)\n","I0202 14:32:10.508265 140715376195456 basic_session_run_hooks.py:260] loss = 2.5679426, step = 647 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.34062\n","I0202 14:32:11.253876 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34062\n","INFO:tensorflow:loss = 2.9075208, step = 648 (0.746 sec)\n","I0202 14:32:11.254205 140715376195456 basic_session_run_hooks.py:260] loss = 2.9075208, step = 648 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.36449\n","I0202 14:32:11.986769 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36449\n","INFO:tensorflow:loss = 3.228138, step = 649 (0.733 sec)\n","I0202 14:32:11.987096 140715376195456 basic_session_run_hooks.py:260] loss = 3.228138, step = 649 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.33371\n","I0202 14:32:12.736570 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33371\n","INFO:tensorflow:loss = 2.822351, step = 650 (0.750 sec)\n","I0202 14:32:12.736982 140715376195456 basic_session_run_hooks.py:260] loss = 2.822351, step = 650 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.32675\n","I0202 14:32:13.490256 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32675\n","INFO:tensorflow:loss = 2.9173799, step = 651 (0.754 sec)\n","I0202 14:32:13.490580 140715376195456 basic_session_run_hooks.py:260] loss = 2.9173799, step = 651 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.37187\n","I0202 14:32:14.219187 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37187\n","INFO:tensorflow:loss = 2.5728283, step = 652 (0.729 sec)\n","I0202 14:32:14.219618 140715376195456 basic_session_run_hooks.py:260] loss = 2.5728283, step = 652 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.36246\n","I0202 14:32:14.953152 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36246\n","INFO:tensorflow:loss = 2.4864557, step = 653 (0.734 sec)\n","I0202 14:32:14.953629 140715376195456 basic_session_run_hooks.py:260] loss = 2.4864557, step = 653 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.3527\n","I0202 14:32:15.692485 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3527\n","INFO:tensorflow:loss = 2.3773153, step = 654 (0.739 sec)\n","I0202 14:32:15.692948 140715376195456 basic_session_run_hooks.py:260] loss = 2.3773153, step = 654 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.38519\n","I0202 14:32:16.414353 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38519\n","INFO:tensorflow:loss = 2.9838297, step = 655 (0.722 sec)\n","I0202 14:32:16.414932 140715376195456 basic_session_run_hooks.py:260] loss = 2.9838297, step = 655 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.37063\n","I0202 14:32:17.143955 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37063\n","INFO:tensorflow:loss = 2.8267891, step = 656 (0.729 sec)\n","I0202 14:32:17.144374 140715376195456 basic_session_run_hooks.py:260] loss = 2.8267891, step = 656 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.38596\n","I0202 14:32:17.865495 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38596\n","INFO:tensorflow:loss = 2.9558263, step = 657 (0.722 sec)\n","I0202 14:32:17.865946 140715376195456 basic_session_run_hooks.py:260] loss = 2.9558263, step = 657 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.40249\n","I0202 14:32:18.578501 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40249\n","INFO:tensorflow:loss = 2.2401338, step = 658 (0.713 sec)\n","I0202 14:32:18.578805 140715376195456 basic_session_run_hooks.py:260] loss = 2.2401338, step = 658 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.38065\n","I0202 14:32:19.302767 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38065\n","INFO:tensorflow:loss = 2.4420455, step = 659 (0.724 sec)\n","I0202 14:32:19.303061 140715376195456 basic_session_run_hooks.py:260] loss = 2.4420455, step = 659 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.37092\n","I0202 14:32:20.032218 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37092\n","INFO:tensorflow:loss = 2.5421374, step = 660 (0.730 sec)\n","I0202 14:32:20.032672 140715376195456 basic_session_run_hooks.py:260] loss = 2.5421374, step = 660 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.38208\n","I0202 14:32:20.755755 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38208\n","INFO:tensorflow:loss = 2.6850796, step = 661 (0.724 sec)\n","I0202 14:32:20.756202 140715376195456 basic_session_run_hooks.py:260] loss = 2.6850796, step = 661 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.37714\n","I0202 14:32:21.481894 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37714\n","INFO:tensorflow:loss = 2.75387, step = 662 (0.726 sec)\n","I0202 14:32:21.482185 140715376195456 basic_session_run_hooks.py:260] loss = 2.75387, step = 662 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38472\n","I0202 14:32:22.204068 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38472\n","INFO:tensorflow:loss = 2.670796, step = 663 (0.722 sec)\n","I0202 14:32:22.204520 140715376195456 basic_session_run_hooks.py:260] loss = 2.670796, step = 663 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.42477\n","I0202 14:32:22.905945 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42477\n","INFO:tensorflow:loss = 2.7975924, step = 664 (0.702 sec)\n","I0202 14:32:22.906455 140715376195456 basic_session_run_hooks.py:260] loss = 2.7975924, step = 664 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.37355\n","I0202 14:32:23.633980 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37355\n","INFO:tensorflow:loss = 3.1421428, step = 665 (0.728 sec)\n","I0202 14:32:23.634269 140715376195456 basic_session_run_hooks.py:260] loss = 3.1421428, step = 665 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 1.39892\n","I0202 14:32:24.348829 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39892\n","INFO:tensorflow:loss = 2.6721687, step = 666 (0.715 sec)\n","I0202 14:32:24.349123 140715376195456 basic_session_run_hooks.py:260] loss = 2.6721687, step = 666 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.43728\n","I0202 14:32:25.044607 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43728\n","INFO:tensorflow:loss = 2.3862138, step = 667 (0.696 sec)\n","I0202 14:32:25.045066 140715376195456 basic_session_run_hooks.py:260] loss = 2.3862138, step = 667 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 1.41849\n","I0202 14:32:25.749571 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41849\n","INFO:tensorflow:loss = 3.2385337, step = 668 (0.705 sec)\n","I0202 14:32:25.749876 140715376195456 basic_session_run_hooks.py:260] loss = 3.2385337, step = 668 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.38589\n","I0202 14:32:26.471115 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38589\n","INFO:tensorflow:loss = 2.4057071, step = 669 (0.722 sec)\n","I0202 14:32:26.471575 140715376195456 basic_session_run_hooks.py:260] loss = 2.4057071, step = 669 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.38917\n","I0202 14:32:27.190972 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38917\n","INFO:tensorflow:loss = 2.6749165, step = 670 (0.720 sec)\n","I0202 14:32:27.191287 140715376195456 basic_session_run_hooks.py:260] loss = 2.6749165, step = 670 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.36441\n","I0202 14:32:27.923884 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36441\n","INFO:tensorflow:loss = 2.6419933, step = 671 (0.733 sec)\n","I0202 14:32:27.924186 140715376195456 basic_session_run_hooks.py:260] loss = 2.6419933, step = 671 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36075\n","I0202 14:32:28.658818 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36075\n","INFO:tensorflow:loss = 2.8724983, step = 672 (0.735 sec)\n","I0202 14:32:28.659366 140715376195456 basic_session_run_hooks.py:260] loss = 2.8724983, step = 672 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.38272\n","I0202 14:32:29.382010 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38272\n","INFO:tensorflow:loss = 2.7241611, step = 673 (0.723 sec)\n","I0202 14:32:29.382472 140715376195456 basic_session_run_hooks.py:260] loss = 2.7241611, step = 673 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.33557\n","I0202 14:32:30.130724 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33557\n","INFO:tensorflow:loss = 2.6131525, step = 674 (0.749 sec)\n","I0202 14:32:30.131030 140715376195456 basic_session_run_hooks.py:260] loss = 2.6131525, step = 674 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.3672\n","I0202 14:32:30.862130 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3672\n","INFO:tensorflow:loss = 3.0212107, step = 675 (0.732 sec)\n","I0202 14:32:30.862588 140715376195456 basic_session_run_hooks.py:260] loss = 3.0212107, step = 675 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39176\n","I0202 14:32:31.580659 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39176\n","INFO:tensorflow:loss = 2.864784, step = 676 (0.719 sec)\n","I0202 14:32:31.581099 140715376195456 basic_session_run_hooks.py:260] loss = 2.864784, step = 676 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.37165\n","I0202 14:32:32.309703 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37165\n","INFO:tensorflow:loss = 2.959688, step = 677 (0.729 sec)\n","I0202 14:32:32.310163 140715376195456 basic_session_run_hooks.py:260] loss = 2.959688, step = 677 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.35853\n","I0202 14:32:33.045787 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35853\n","INFO:tensorflow:loss = 2.5456862, step = 678 (0.736 sec)\n","I0202 14:32:33.046208 140715376195456 basic_session_run_hooks.py:260] loss = 2.5456862, step = 678 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.38262\n","I0202 14:32:33.769062 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38262\n","INFO:tensorflow:loss = 3.0427659, step = 679 (0.723 sec)\n","I0202 14:32:33.769552 140715376195456 basic_session_run_hooks.py:260] loss = 3.0427659, step = 679 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.38046\n","I0202 14:32:34.493449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38046\n","INFO:tensorflow:loss = 2.7507966, step = 680 (0.724 sec)\n","I0202 14:32:34.493756 140715376195456 basic_session_run_hooks.py:260] loss = 2.7507966, step = 680 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.36375\n","I0202 14:32:35.226719 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36375\n","INFO:tensorflow:loss = 3.0062745, step = 681 (0.733 sec)\n","I0202 14:32:35.227158 140715376195456 basic_session_run_hooks.py:260] loss = 3.0062745, step = 681 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.42187\n","I0202 14:32:35.930011 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42187\n","INFO:tensorflow:loss = 2.4465528, step = 682 (0.703 sec)\n","I0202 14:32:35.930318 140715376195456 basic_session_run_hooks.py:260] loss = 2.4465528, step = 682 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.33861\n","I0202 14:32:36.677065 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33861\n","INFO:tensorflow:loss = 2.4464345, step = 683 (0.747 sec)\n","I0202 14:32:36.677523 140715376195456 basic_session_run_hooks.py:260] loss = 2.4464345, step = 683 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.36151\n","I0202 14:32:37.411644 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36151\n","INFO:tensorflow:loss = 3.046325, step = 684 (0.734 sec)\n","I0202 14:32:37.411945 140715376195456 basic_session_run_hooks.py:260] loss = 3.046325, step = 684 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.37666\n","I0202 14:32:38.137971 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37666\n","INFO:tensorflow:loss = 2.6794941, step = 685 (0.726 sec)\n","I0202 14:32:38.138439 140715376195456 basic_session_run_hooks.py:260] loss = 2.6794941, step = 685 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.41714\n","I0202 14:32:38.843612 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41714\n","INFO:tensorflow:loss = 2.8067966, step = 686 (0.705 sec)\n","I0202 14:32:38.843913 140715376195456 basic_session_run_hooks.py:260] loss = 2.8067966, step = 686 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.3957\n","I0202 14:32:39.560069 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3957\n","INFO:tensorflow:loss = 2.8853574, step = 687 (0.717 sec)\n","I0202 14:32:39.560553 140715376195456 basic_session_run_hooks.py:260] loss = 2.8853574, step = 687 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.41843\n","I0202 14:32:40.265088 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41843\n","INFO:tensorflow:loss = 2.4850574, step = 688 (0.705 sec)\n","I0202 14:32:40.265533 140715376195456 basic_session_run_hooks.py:260] loss = 2.4850574, step = 688 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.4062\n","I0202 14:32:40.976226 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4062\n","INFO:tensorflow:loss = 2.1540809, step = 689 (0.711 sec)\n","I0202 14:32:40.976698 140715376195456 basic_session_run_hooks.py:260] loss = 2.1540809, step = 689 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 1.38565\n","I0202 14:32:41.697911 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38565\n","INFO:tensorflow:loss = 2.5547128, step = 690 (0.722 sec)\n","I0202 14:32:41.698231 140715376195456 basic_session_run_hooks.py:260] loss = 2.5547128, step = 690 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.4218\n","I0202 14:32:42.401237 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4218\n","INFO:tensorflow:loss = 2.705176, step = 691 (0.703 sec)\n","I0202 14:32:42.401713 140715376195456 basic_session_run_hooks.py:260] loss = 2.705176, step = 691 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.38571\n","I0202 14:32:43.122888 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38571\n","INFO:tensorflow:loss = 2.650871, step = 692 (0.722 sec)\n","I0202 14:32:43.123211 140715376195456 basic_session_run_hooks.py:260] loss = 2.650871, step = 692 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.31383\n","I0202 14:32:43.884004 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31383\n","INFO:tensorflow:loss = 2.2807496, step = 693 (0.761 sec)\n","I0202 14:32:43.884477 140715376195456 basic_session_run_hooks.py:260] loss = 2.2807496, step = 693 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 1.31004\n","I0202 14:32:44.647341 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31004\n","INFO:tensorflow:loss = 3.1169114, step = 694 (0.763 sec)\n","I0202 14:32:44.647770 140715376195456 basic_session_run_hooks.py:260] loss = 3.1169114, step = 694 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 1.32221\n","I0202 14:32:45.403684 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32221\n","INFO:tensorflow:loss = 3.069157, step = 695 (0.756 sec)\n","I0202 14:32:45.404156 140715376195456 basic_session_run_hooks.py:260] loss = 3.069157, step = 695 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 1.38725\n","I0202 14:32:46.124532 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38725\n","INFO:tensorflow:loss = 2.415334, step = 696 (0.721 sec)\n","I0202 14:32:46.124841 140715376195456 basic_session_run_hooks.py:260] loss = 2.415334, step = 696 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.2946\n","I0202 14:32:46.896966 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.2946\n","INFO:tensorflow:loss = 2.639792, step = 697 (0.773 sec)\n","I0202 14:32:46.897456 140715376195456 basic_session_run_hooks.py:260] loss = 2.639792, step = 697 (0.773 sec)\n","INFO:tensorflow:global_step/sec: 1.34807\n","I0202 14:32:47.638738 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34807\n","INFO:tensorflow:loss = 2.1908104, step = 698 (0.742 sec)\n","I0202 14:32:47.639156 140715376195456 basic_session_run_hooks.py:260] loss = 2.1908104, step = 698 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.30899\n","I0202 14:32:48.402701 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30899\n","INFO:tensorflow:loss = 2.3093092, step = 699 (0.764 sec)\n","I0202 14:32:48.403056 140715376195456 basic_session_run_hooks.py:260] loss = 2.3093092, step = 699 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 1.34803\n","I0202 14:32:49.144567 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34803\n","INFO:tensorflow:loss = 2.6766582, step = 700 (0.742 sec)\n","I0202 14:32:49.145460 140715376195456 basic_session_run_hooks.py:260] loss = 2.6766582, step = 700 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.34494\n","I0202 14:32:49.888069 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34494\n","INFO:tensorflow:loss = 2.8742394, step = 701 (0.743 sec)\n","I0202 14:32:49.888375 140715376195456 basic_session_run_hooks.py:260] loss = 2.8742394, step = 701 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.34297\n","I0202 14:32:50.632656 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34297\n","INFO:tensorflow:loss = 2.6459792, step = 702 (0.745 sec)\n","I0202 14:32:50.633100 140715376195456 basic_session_run_hooks.py:260] loss = 2.6459792, step = 702 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.32529\n","I0202 14:32:51.387238 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32529\n","INFO:tensorflow:loss = 2.695021, step = 703 (0.754 sec)\n","I0202 14:32:51.387569 140715376195456 basic_session_run_hooks.py:260] loss = 2.695021, step = 703 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.35784\n","I0202 14:32:52.123693 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35784\n","INFO:tensorflow:loss = 2.1353874, step = 704 (0.737 sec)\n","I0202 14:32:52.124139 140715376195456 basic_session_run_hooks.py:260] loss = 2.1353874, step = 704 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37842\n","I0202 14:32:52.849158 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37842\n","INFO:tensorflow:loss = 2.7505338, step = 705 (0.725 sec)\n","I0202 14:32:52.849491 140715376195456 basic_session_run_hooks.py:260] loss = 2.7505338, step = 705 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.36535\n","I0202 14:32:53.581607 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36535\n","INFO:tensorflow:loss = 2.481107, step = 706 (0.733 sec)\n","I0202 14:32:53.582076 140715376195456 basic_session_run_hooks.py:260] loss = 2.481107, step = 706 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.33525\n","I0202 14:32:54.330514 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33525\n","INFO:tensorflow:loss = 2.6402676, step = 707 (0.749 sec)\n","I0202 14:32:54.330956 140715376195456 basic_session_run_hooks.py:260] loss = 2.6402676, step = 707 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.40315\n","I0202 14:32:55.043163 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40315\n","INFO:tensorflow:loss = 3.1681397, step = 708 (0.713 sec)\n","I0202 14:32:55.043499 140715376195456 basic_session_run_hooks.py:260] loss = 3.1681397, step = 708 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.36394\n","I0202 14:32:55.776333 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36394\n","INFO:tensorflow:loss = 2.7258086, step = 709 (0.733 sec)\n","I0202 14:32:55.776777 140715376195456 basic_session_run_hooks.py:260] loss = 2.7258086, step = 709 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.35194\n","I0202 14:32:56.516009 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35194\n","INFO:tensorflow:loss = 2.582618, step = 710 (0.740 sec)\n","I0202 14:32:56.516434 140715376195456 basic_session_run_hooks.py:260] loss = 2.582618, step = 710 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36763\n","I0202 14:32:57.247204 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36763\n","INFO:tensorflow:loss = 2.7525127, step = 711 (0.731 sec)\n","I0202 14:32:57.247530 140715376195456 basic_session_run_hooks.py:260] loss = 2.7525127, step = 711 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.43523\n","I0202 14:32:57.943981 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43523\n","INFO:tensorflow:loss = 2.3964574, step = 712 (0.697 sec)\n","I0202 14:32:57.944449 140715376195456 basic_session_run_hooks.py:260] loss = 2.3964574, step = 712 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 1.30055\n","I0202 14:32:58.712852 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30055\n","INFO:tensorflow:loss = 2.4966643, step = 713 (0.769 sec)\n","I0202 14:32:58.713146 140715376195456 basic_session_run_hooks.py:260] loss = 2.4966643, step = 713 (0.769 sec)\n","INFO:tensorflow:global_step/sec: 1.38338\n","I0202 14:32:59.435714 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38338\n","INFO:tensorflow:loss = 2.7379277, step = 714 (0.723 sec)\n","I0202 14:32:59.436123 140715376195456 basic_session_run_hooks.py:260] loss = 2.7379277, step = 714 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.37528\n","I0202 14:33:00.162854 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37528\n","INFO:tensorflow:loss = 2.8824656, step = 715 (0.727 sec)\n","I0202 14:33:00.163146 140715376195456 basic_session_run_hooks.py:260] loss = 2.8824656, step = 715 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.4179\n","I0202 14:33:00.868110 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4179\n","INFO:tensorflow:loss = 2.7131822, step = 716 (0.705 sec)\n","I0202 14:33:00.868405 140715376195456 basic_session_run_hooks.py:260] loss = 2.7131822, step = 716 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.36396\n","I0202 14:33:01.601300 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36396\n","INFO:tensorflow:loss = 2.76951, step = 717 (0.733 sec)\n","I0202 14:33:01.601789 140715376195456 basic_session_run_hooks.py:260] loss = 2.76951, step = 717 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.38146\n","I0202 14:33:02.325170 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38146\n","INFO:tensorflow:loss = 3.04672, step = 718 (0.724 sec)\n","I0202 14:33:02.325600 140715376195456 basic_session_run_hooks.py:260] loss = 3.04672, step = 718 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.39693\n","I0202 14:33:03.041009 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39693\n","INFO:tensorflow:loss = 3.2084317, step = 719 (0.716 sec)\n","I0202 14:33:03.041441 140715376195456 basic_session_run_hooks.py:260] loss = 3.2084317, step = 719 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.37688\n","I0202 14:33:03.767295 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37688\n","INFO:tensorflow:loss = 2.8864648, step = 720 (0.726 sec)\n","I0202 14:33:03.767644 140715376195456 basic_session_run_hooks.py:260] loss = 2.8864648, step = 720 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.37653\n","I0202 14:33:04.493737 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37653\n","INFO:tensorflow:loss = 2.6514099, step = 721 (0.726 sec)\n","I0202 14:33:04.494144 140715376195456 basic_session_run_hooks.py:260] loss = 2.6514099, step = 721 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.39848\n","I0202 14:33:05.208819 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39848\n","INFO:tensorflow:loss = 2.4386976, step = 722 (0.715 sec)\n","I0202 14:33:05.209267 140715376195456 basic_session_run_hooks.py:260] loss = 2.4386976, step = 722 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.35417\n","I0202 14:33:05.947276 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35417\n","INFO:tensorflow:loss = 2.5447917, step = 723 (0.738 sec)\n","I0202 14:33:05.947750 140715376195456 basic_session_run_hooks.py:260] loss = 2.5447917, step = 723 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.36209\n","I0202 14:33:06.681468 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36209\n","INFO:tensorflow:loss = 2.7010698, step = 724 (0.735 sec)\n","I0202 14:33:06.682634 140715376195456 basic_session_run_hooks.py:260] loss = 2.7010698, step = 724 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.40044\n","I0202 14:33:07.395516 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40044\n","INFO:tensorflow:loss = 2.6653776, step = 725 (0.713 sec)\n","I0202 14:33:07.395823 140715376195456 basic_session_run_hooks.py:260] loss = 2.6653776, step = 725 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.37891\n","I0202 14:33:08.120707 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37891\n","INFO:tensorflow:loss = 2.764122, step = 726 (0.725 sec)\n","I0202 14:33:08.121134 140715376195456 basic_session_run_hooks.py:260] loss = 2.764122, step = 726 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.35132\n","I0202 14:33:08.860721 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35132\n","INFO:tensorflow:loss = 2.7975605, step = 727 (0.740 sec)\n","I0202 14:33:08.861013 140715376195456 basic_session_run_hooks.py:260] loss = 2.7975605, step = 727 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.44167\n","I0202 14:33:09.554397 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.44167\n","INFO:tensorflow:loss = 2.5386138, step = 728 (0.694 sec)\n","I0202 14:33:09.554875 140715376195456 basic_session_run_hooks.py:260] loss = 2.5386138, step = 728 (0.694 sec)\n","INFO:tensorflow:global_step/sec: 1.3559\n","I0202 14:33:10.291875 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3559\n","INFO:tensorflow:loss = 2.6525872, step = 729 (0.737 sec)\n","I0202 14:33:10.292320 140715376195456 basic_session_run_hooks.py:260] loss = 2.6525872, step = 729 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.39808\n","I0202 14:33:11.007176 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39808\n","INFO:tensorflow:loss = 2.6065927, step = 730 (0.715 sec)\n","I0202 14:33:11.007508 140715376195456 basic_session_run_hooks.py:260] loss = 2.6065927, step = 730 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.35589\n","I0202 14:33:11.744703 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35589\n","INFO:tensorflow:loss = 2.7105963, step = 731 (0.738 sec)\n","I0202 14:33:11.745152 140715376195456 basic_session_run_hooks.py:260] loss = 2.7105963, step = 731 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.35866\n","I0202 14:33:12.480708 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35866\n","INFO:tensorflow:loss = 2.6188676, step = 732 (0.736 sec)\n","I0202 14:33:12.481005 140715376195456 basic_session_run_hooks.py:260] loss = 2.6188676, step = 732 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.34945\n","I0202 14:33:13.221762 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34945\n","INFO:tensorflow:loss = 2.7897782, step = 733 (0.741 sec)\n","I0202 14:33:13.222187 140715376195456 basic_session_run_hooks.py:260] loss = 2.7897782, step = 733 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.36094\n","I0202 14:33:13.956598 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36094\n","INFO:tensorflow:loss = 2.8975575, step = 734 (0.735 sec)\n","I0202 14:33:13.956917 140715376195456 basic_session_run_hooks.py:260] loss = 2.8975575, step = 734 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.36727\n","I0202 14:33:14.687916 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36727\n","INFO:tensorflow:loss = 2.4888296, step = 735 (0.731 sec)\n","I0202 14:33:14.688375 140715376195456 basic_session_run_hooks.py:260] loss = 2.4888296, step = 735 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37508\n","I0202 14:33:15.415131 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37508\n","INFO:tensorflow:loss = 2.55455, step = 736 (0.727 sec)\n","I0202 14:33:15.415444 140715376195456 basic_session_run_hooks.py:260] loss = 2.55455, step = 736 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.42663\n","I0202 14:33:16.116090 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42663\n","INFO:tensorflow:loss = 2.873462, step = 737 (0.701 sec)\n","I0202 14:33:16.116521 140715376195456 basic_session_run_hooks.py:260] loss = 2.873462, step = 737 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 1.35855\n","I0202 14:33:16.852214 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35855\n","INFO:tensorflow:loss = 2.4547582, step = 738 (0.736 sec)\n","I0202 14:33:16.852741 140715376195456 basic_session_run_hooks.py:260] loss = 2.4547582, step = 738 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.34439\n","I0202 14:33:17.595999 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34439\n","INFO:tensorflow:loss = 2.2040825, step = 739 (0.744 sec)\n","I0202 14:33:17.596295 140715376195456 basic_session_run_hooks.py:260] loss = 2.2040825, step = 739 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.37044\n","I0202 14:33:18.325695 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37044\n","INFO:tensorflow:loss = 2.5248258, step = 740 (0.730 sec)\n","I0202 14:33:18.326100 140715376195456 basic_session_run_hooks.py:260] loss = 2.5248258, step = 740 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.37535\n","I0202 14:33:19.052780 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37535\n","INFO:tensorflow:loss = 2.3193617, step = 741 (0.727 sec)\n","I0202 14:33:19.053267 140715376195456 basic_session_run_hooks.py:260] loss = 2.3193617, step = 741 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.32862\n","I0202 14:33:19.805471 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32862\n","INFO:tensorflow:loss = 2.5415158, step = 742 (0.753 sec)\n","I0202 14:33:19.805789 140715376195456 basic_session_run_hooks.py:260] loss = 2.5415158, step = 742 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.3405\n","I0202 14:33:20.551460 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3405\n","INFO:tensorflow:loss = 2.578712, step = 743 (0.746 sec)\n","I0202 14:33:20.551907 140715376195456 basic_session_run_hooks.py:260] loss = 2.578712, step = 743 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.33049\n","I0202 14:33:21.303040 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33049\n","INFO:tensorflow:loss = 2.3306024, step = 744 (0.752 sec)\n","I0202 14:33:21.303485 140715376195456 basic_session_run_hooks.py:260] loss = 2.3306024, step = 744 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 1.38062\n","I0202 14:33:22.027362 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38062\n","INFO:tensorflow:loss = 2.3024306, step = 745 (0.724 sec)\n","I0202 14:33:22.027827 140715376195456 basic_session_run_hooks.py:260] loss = 2.3024306, step = 745 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.30957\n","I0202 14:33:22.790966 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30957\n","INFO:tensorflow:loss = 2.6340864, step = 746 (0.764 sec)\n","I0202 14:33:22.791390 140715376195456 basic_session_run_hooks.py:260] loss = 2.6340864, step = 746 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 1.33499\n","I0202 14:33:23.540038 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33499\n","INFO:tensorflow:loss = 3.1275802, step = 747 (0.749 sec)\n","I0202 14:33:23.540469 140715376195456 basic_session_run_hooks.py:260] loss = 3.1275802, step = 747 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.37506\n","I0202 14:33:24.267267 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37506\n","INFO:tensorflow:loss = 2.635388, step = 748 (0.727 sec)\n","I0202 14:33:24.267770 140715376195456 basic_session_run_hooks.py:260] loss = 2.635388, step = 748 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.33744\n","I0202 14:33:25.014963 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33744\n","INFO:tensorflow:loss = 2.6606808, step = 749 (0.747 sec)\n","I0202 14:33:25.015260 140715376195456 basic_session_run_hooks.py:260] loss = 2.6606808, step = 749 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.38067\n","I0202 14:33:25.739238 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38067\n","INFO:tensorflow:loss = 2.2683463, step = 750 (0.724 sec)\n","I0202 14:33:25.739675 140715376195456 basic_session_run_hooks.py:260] loss = 2.2683463, step = 750 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.39613\n","I0202 14:33:26.455558 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39613\n","INFO:tensorflow:loss = 2.8167143, step = 751 (0.718 sec)\n","I0202 14:33:26.457922 140715376195456 basic_session_run_hooks.py:260] loss = 2.8167143, step = 751 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.34625\n","I0202 14:33:27.198320 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34625\n","INFO:tensorflow:loss = 3.0546567, step = 752 (0.741 sec)\n","I0202 14:33:27.198816 140715376195456 basic_session_run_hooks.py:260] loss = 3.0546567, step = 752 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.3865\n","I0202 14:33:27.919587 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3865\n","INFO:tensorflow:loss = 2.9633148, step = 753 (0.721 sec)\n","I0202 14:33:27.920021 140715376195456 basic_session_run_hooks.py:260] loss = 2.9633148, step = 753 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.39665\n","I0202 14:33:28.635607 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39665\n","INFO:tensorflow:loss = 2.8677125, step = 754 (0.716 sec)\n","I0202 14:33:28.635921 140715376195456 basic_session_run_hooks.py:260] loss = 2.8677125, step = 754 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.42224\n","I0202 14:33:29.338675 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42224\n","INFO:tensorflow:loss = 2.3047028, step = 755 (0.703 sec)\n","I0202 14:33:29.339093 140715376195456 basic_session_run_hooks.py:260] loss = 2.3047028, step = 755 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 1.36788\n","I0202 14:33:30.069732 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36788\n","INFO:tensorflow:loss = 2.57663, step = 756 (0.731 sec)\n","I0202 14:33:30.070027 140715376195456 basic_session_run_hooks.py:260] loss = 2.57663, step = 756 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37136\n","I0202 14:33:30.798947 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37136\n","INFO:tensorflow:loss = 2.5139704, step = 757 (0.729 sec)\n","I0202 14:33:30.799370 140715376195456 basic_session_run_hooks.py:260] loss = 2.5139704, step = 757 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.24839\n","I0202 14:33:31.599971 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.24839\n","INFO:tensorflow:loss = 2.2051685, step = 758 (0.801 sec)\n","I0202 14:33:31.600568 140715376195456 basic_session_run_hooks.py:260] loss = 2.2051685, step = 758 (0.801 sec)\n","INFO:tensorflow:global_step/sec: 1.39453\n","I0202 14:33:32.317067 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39453\n","INFO:tensorflow:loss = 2.2711117, step = 759 (0.717 sec)\n","I0202 14:33:32.317491 140715376195456 basic_session_run_hooks.py:260] loss = 2.2711117, step = 759 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.3457\n","I0202 14:33:33.060175 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3457\n","INFO:tensorflow:loss = 2.4330935, step = 760 (0.743 sec)\n","I0202 14:33:33.060613 140715376195456 basic_session_run_hooks.py:260] loss = 2.4330935, step = 760 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.39639\n","I0202 14:33:33.776298 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39639\n","INFO:tensorflow:loss = 2.3001535, step = 761 (0.716 sec)\n","I0202 14:33:33.776624 140715376195456 basic_session_run_hooks.py:260] loss = 2.3001535, step = 761 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.38041\n","I0202 14:33:34.500711 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38041\n","INFO:tensorflow:loss = 2.637944, step = 762 (0.725 sec)\n","I0202 14:33:34.501127 140715376195456 basic_session_run_hooks.py:260] loss = 2.637944, step = 762 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.34685\n","I0202 14:33:35.243210 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34685\n","INFO:tensorflow:loss = 2.5111642, step = 763 (0.742 sec)\n","I0202 14:33:35.243546 140715376195456 basic_session_run_hooks.py:260] loss = 2.5111642, step = 763 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.36865\n","I0202 14:33:35.973889 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36865\n","INFO:tensorflow:loss = 2.5908515, step = 764 (0.731 sec)\n","I0202 14:33:35.974314 140715376195456 basic_session_run_hooks.py:260] loss = 2.5908515, step = 764 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.38821\n","I0202 14:33:36.694197 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38821\n","INFO:tensorflow:loss = 2.8240569, step = 765 (0.720 sec)\n","I0202 14:33:36.694649 140715376195456 basic_session_run_hooks.py:260] loss = 2.8240569, step = 765 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.37807\n","I0202 14:33:37.419849 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37807\n","INFO:tensorflow:loss = 2.4271474, step = 766 (0.726 sec)\n","I0202 14:33:37.420149 140715376195456 basic_session_run_hooks.py:260] loss = 2.4271474, step = 766 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.35822\n","I0202 14:33:38.156111 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35822\n","INFO:tensorflow:loss = 2.1621125, step = 767 (0.736 sec)\n","I0202 14:33:38.156558 140715376195456 basic_session_run_hooks.py:260] loss = 2.1621125, step = 767 (0.736 sec)\n","INFO:tensorflow:Saving checkpoints for 769 into /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt.\n","I0202 14:33:38.888098 140715376195456 basic_session_run_hooks.py:606] Saving checkpoints for 769 into /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","I0202 14:33:41.416852 140715376195456 dataset_builder.py:163] Reading unweighted datasets: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","I0202 14:33:41.417815 140715376195456 dataset_builder.py:80] Reading record datasets for input file: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0202 14:33:41.417956 140715376195456 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0202 14:33:42.246237 140715376195456 estimator.py:1145] Calling model_fn.\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aec88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aec88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.330620 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aec88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aec88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.358557 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.394931 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d476fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.452002 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.483335 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d471a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d471a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.551938 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d471a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d471a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53ff7780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53ff7780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.579457 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53ff7780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53ff7780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.615746 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d471ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476fac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476fac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.673538 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476fac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d476fac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4588668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4588668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.702407 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4588668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4588668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4588668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4588668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.771247 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4588668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4588668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53fd79b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53fd79b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.805922 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53fd79b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ffa53fd79b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d447f320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d447f320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.846454 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d447f320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d447f320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4543470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4543470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.913726 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4543470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4543470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d444a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d444a710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:42.943672 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d444a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d444a710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44de6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44de6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.012590 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44de6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44de6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47bc978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47bc978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.040783 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47bc978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47bc978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d435a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d435a908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.078297 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d435a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d435a908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d43fb080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d43fb080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.135615 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d43fb080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d43fb080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.162791 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44776a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44776a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.230339 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44776a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d44776a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4264cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4264cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.260300 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4264cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4264cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d428a748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d428a748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.302224 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d428a748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d428a748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4264470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4264470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.359738 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4264470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4264470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d45435c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d45435c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.388048 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d45435c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d45435c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41b59e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41b59e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.446451 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41b59e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41b59e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4532ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4532ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.472559 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4532ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4532ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40c29b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40c29b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.509402 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40c29b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40c29b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d428ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d428ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.566343 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d428ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d428ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d44770f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d44770f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.598630 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d44770f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d44770f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.657247 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40b89e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40b89e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.685780 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40b89e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d40b89e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.726233 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.786652 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4078e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceee70b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceee70b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.813809 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceee70b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceee70b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4324dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4324dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.870783 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4324dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4324dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cef3b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cef3b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.901965 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cef3b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cef3b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.939258 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ceee7550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ceee7550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:43.997377 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ceee7550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ceee7550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced84e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced84e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.025240 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced84e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced84e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41edf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41edf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.085504 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41edf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d41edf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d410c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d410c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.115905 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d410c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d410c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced1c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced1c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.152449 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced1c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ced1c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ced84f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ced84f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.221440 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ced84f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ced84f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4078e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4078e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.250242 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4078e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4078e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d410cb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d410cb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.309520 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d410cb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d410cb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.335215 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cefd8da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc0630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc0630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.370837 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc0630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc0630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cec2c6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cec2c6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.430361 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cec2c6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cec2c6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceefbef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceefbef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.456915 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceefbef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ceefbef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea86940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea86940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.525198 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea86940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea86940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.555486 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cee54b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9c0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9c0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.595773 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9c0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9c0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea586a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea586a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.663057 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea586a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cea586a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9addd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9addd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.690114 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9addd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce9addd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9950b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9950b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.752148 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9950b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9950b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.778495 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce97a828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce97a828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.822803 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce97a828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce97a828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9addd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9addd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.883835 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9addd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce9addd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cec57c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cec57c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.911364 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cec57c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cec57c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.969094 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc07b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc07b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:44.996057 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc07b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cebc07b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.032707 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.089646 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce85e518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.123444 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.187178 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.215784 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea3f1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce70e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce70e8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.253019 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce70e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce70e8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.317846 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce6da518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.346524 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cea32048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70e668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70e668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.411004 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70e668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70e668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce5634a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce5634a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.437863 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce5634a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce5634a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce4fb8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce4fb8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.476193 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce4fb8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce4fb8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce59f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce59f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.539077 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce59f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce59f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.565790 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce8b2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce52ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce52ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.625178 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce52ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce52ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce7c3d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce7c3d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.651151 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce7c3d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce7c3d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce49e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce49e780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.687894 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce49e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce49e780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.759444 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce328dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce328dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.785734 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce328dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce328dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.847399 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce70ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce694ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce694ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.874694 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce694ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce694ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce2c86d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce2c86d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.911886 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce2c86d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce2c86d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.968648 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce3be780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:45.996516 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.063302 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22f6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22f6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.095165 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22f6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce22f6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.159869 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47ae908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47ae908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.191894 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47ae908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d47ae908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.251125 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce1d8780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce1d8780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.278471 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce1d8780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce1d8780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.346060 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce002e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce002e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.375433 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce002e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce002e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.439735 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47aeda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce020f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce020f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.469704 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce020f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce020f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce1d8080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce1d8080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.546312 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce1d8080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9ce1d8080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce04b860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce04b860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.590598 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce04b860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9ce04b860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd3898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.667753 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd3898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.714329 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdf84a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdf84a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.793006 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdf84a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdf84a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cded6128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cded6128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.828921 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cded6128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cded6128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd36a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd36a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.887715 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd36a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdfd36a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:46.914566 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdf03dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:47.588827 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:47.661124 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:47.728466 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:47.733046 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:47.810551 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:47.882338 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:47.885684 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:47.953009 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.022101 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:48.025772 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.086728 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.164101 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:48.167725 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.702393 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc4db860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc4db860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.772309 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc4db860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc4db860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:33:48.775568 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.835275 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5a0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4727208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4727208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:33:48.902415 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4727208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4727208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0202 14:33:51.217470 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0202 14:33:51.217802 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0202 14:33:51.218112 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0202 14:33:51.218323 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0202 14:33:51.218605 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0202 14:33:51.218798 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0202 14:33:51.219081 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0202 14:33:51.219274 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0202 14:33:51.219558 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0202 14:33:51.219752 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0202 14:33:51.220017 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0202 14:33:51.220202 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0202 14:33:51.220476 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0202 14:33:51.220659 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0202 14:33:51.220927 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0202 14:33:51.221176 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0202 14:33:51.221709 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0202 14:33:51.222079 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0202 14:33:51.222511 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0202 14:33:51.222740 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0202 14:33:51.223051 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0202 14:33:51.223268 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0202 14:33:51.223564 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0202 14:33:51.223783 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0202 14:33:51.224098 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0202 14:33:51.224340 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0202 14:33:51.224627 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0202 14:33:51.224829 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0202 14:33:51.225126 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0202 14:33:51.225321 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0202 14:33:51.225620 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0202 14:33:51.225810 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0202 14:33:51.226090 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0202 14:33:51.226278 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0202 14:33:51.226565 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0202 14:33:51.226756 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0202 14:33:51.227006 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0202 14:33:51.227214 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0202 14:33:51.227438 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0202 14:33:51.227652 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0202 14:33:51.227895 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0202 14:33:51.228099 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0202 14:33:51.228294 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0202 14:33:51.255796 140715376195456 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0202 14:33:51.484336 140715376195456 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0202 14:33:52.292488 140715376195456 estimator.py:1147] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-02-02T14:33:52Z\n","I0202 14:33:52.310651 140715376195456 evaluation.py:255] Starting evaluation at 2021-02-02T14:33:52Z\n","INFO:tensorflow:Graph was finalized.\n","I0202 14:33:53.170902 140715376195456 monitored_session.py:240] Graph was finalized.\n","2021-02-02 14:33:53.172028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:33:53.172471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 14:33:53.172621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 14:33:53.172661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 14:33:53.172685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 14:33:53.172713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 14:33:53.172737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 14:33:53.172759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 14:33:53.172782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 14:33:53.172868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:33:53.173293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:33:53.173662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 14:33:53.173752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 14:33:53.173769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 14:33:53.173778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 14:33:53.173887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:33:53.174296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:33:53.174683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0202 14:33:53.174832 140715376195456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-769\n","I0202 14:33:53.177090 140715376195456 saver.py:1280] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-769\n","INFO:tensorflow:Running local_init_op.\n","I0202 14:33:54.779465 140715376195456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0202 14:33:54.930112 140715376195456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 20 images.\n","I0202 14:33:59.744690 140712538011392 coco_evaluation.py:293] Performing evaluation on 20 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0202 14:33:59.745238 140712538011392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0202 14:33:59.746794 140712538011392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.29s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.936\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.875\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.734\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n","INFO:tensorflow:Finished evaluation at 2021-02-02-14:34:00\n","I0202 14:34:00.659536 140715376195456 evaluation.py:275] Finished evaluation at 2021-02-02-14:34:00\n","INFO:tensorflow:Saving dict for global step 769: DetectionBoxes_Precision/mAP = 0.6512818, DetectionBoxes_Precision/mAP (large) = 0.69074684, DetectionBoxes_Precision/mAP (medium) = 0.6195496, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.93614084, DetectionBoxes_Precision/mAP@.75IOU = 0.8754936, DetectionBoxes_Recall/AR@1 = 0.315, DetectionBoxes_Recall/AR@10 = 0.73305553, DetectionBoxes_Recall/AR@100 = 0.7352778, DetectionBoxes_Recall/AR@100 (large) = 0.73660713, DetectionBoxes_Recall/AR@100 (medium) = 0.73380435, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 2.5321524, Loss/localization_loss = 0.3417712, Loss/regularization_loss = 0.34628388, Loss/total_loss = 3.220208, global_step = 769, learning_rate = 0.004, loss = 3.220208\n","I0202 14:34:00.659838 140715376195456 estimator.py:2039] Saving dict for global step 769: DetectionBoxes_Precision/mAP = 0.6512818, DetectionBoxes_Precision/mAP (large) = 0.69074684, DetectionBoxes_Precision/mAP (medium) = 0.6195496, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.93614084, DetectionBoxes_Precision/mAP@.75IOU = 0.8754936, DetectionBoxes_Recall/AR@1 = 0.315, DetectionBoxes_Recall/AR@10 = 0.73305553, DetectionBoxes_Recall/AR@100 = 0.7352778, DetectionBoxes_Recall/AR@100 (large) = 0.73660713, DetectionBoxes_Recall/AR@100 (medium) = 0.73380435, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 2.5321524, Loss/localization_loss = 0.3417712, Loss/regularization_loss = 0.34628388, Loss/total_loss = 3.220208, global_step = 769, learning_rate = 0.004, loss = 3.220208\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 769: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-769\n","I0202 14:34:01.802082 140715376195456 estimator.py:2099] Saving 'checkpoint_path' summary for global step 769: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-769\n","INFO:tensorflow:global_step/sec: 0.0422862\n","I0202 14:34:01.804451 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 0.0422862\n","INFO:tensorflow:loss = 2.884288, step = 768 (23.648 sec)\n","I0202 14:34:01.804745 140715376195456 basic_session_run_hooks.py:260] loss = 2.884288, step = 768 (23.648 sec)\n","INFO:tensorflow:global_step/sec: 1.35362\n","I0202 14:34:02.543249 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35362\n","INFO:tensorflow:loss = 2.7846742, step = 769 (0.739 sec)\n","I0202 14:34:02.543671 140715376195456 basic_session_run_hooks.py:260] loss = 2.7846742, step = 769 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.32915\n","I0202 14:34:03.295613 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32915\n","INFO:tensorflow:loss = 2.4323316, step = 770 (0.752 sec)\n","I0202 14:34:03.296028 140715376195456 basic_session_run_hooks.py:260] loss = 2.4323316, step = 770 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 1.35624\n","I0202 14:34:04.032925 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35624\n","INFO:tensorflow:loss = 2.5287752, step = 771 (0.737 sec)\n","I0202 14:34:04.033320 140715376195456 basic_session_run_hooks.py:260] loss = 2.5287752, step = 771 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.34095\n","I0202 14:34:04.778737 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34095\n","INFO:tensorflow:loss = 2.3654776, step = 772 (0.746 sec)\n","I0202 14:34:04.779069 140715376195456 basic_session_run_hooks.py:260] loss = 2.3654776, step = 772 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.34004\n","I0202 14:34:05.524907 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34004\n","INFO:tensorflow:loss = 3.2181876, step = 773 (0.746 sec)\n","I0202 14:34:05.525229 140715376195456 basic_session_run_hooks.py:260] loss = 3.2181876, step = 773 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.36822\n","I0202 14:34:06.255785 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36822\n","INFO:tensorflow:loss = 2.3007824, step = 774 (0.731 sec)\n","I0202 14:34:06.256096 140715376195456 basic_session_run_hooks.py:260] loss = 2.3007824, step = 774 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.33922\n","I0202 14:34:07.002518 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33922\n","INFO:tensorflow:loss = 2.8940954, step = 775 (0.747 sec)\n","I0202 14:34:07.002818 140715376195456 basic_session_run_hooks.py:260] loss = 2.8940954, step = 775 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.31895\n","I0202 14:34:07.760682 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31895\n","INFO:tensorflow:loss = 2.6544373, step = 776 (0.758 sec)\n","I0202 14:34:07.760992 140715376195456 basic_session_run_hooks.py:260] loss = 2.6544373, step = 776 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 1.32615\n","I0202 14:34:08.514743 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32615\n","INFO:tensorflow:loss = 2.5377948, step = 777 (0.754 sec)\n","I0202 14:34:08.515051 140715376195456 basic_session_run_hooks.py:260] loss = 2.5377948, step = 777 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.34921\n","I0202 14:34:09.255911 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34921\n","INFO:tensorflow:loss = 2.3351343, step = 778 (0.741 sec)\n","I0202 14:34:09.256230 140715376195456 basic_session_run_hooks.py:260] loss = 2.3351343, step = 778 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.36875\n","I0202 14:34:09.986527 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36875\n","INFO:tensorflow:loss = 2.2791388, step = 779 (0.731 sec)\n","I0202 14:34:09.986828 140715376195456 basic_session_run_hooks.py:260] loss = 2.2791388, step = 779 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.32775\n","I0202 14:34:10.739669 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32775\n","INFO:tensorflow:loss = 2.3903916, step = 780 (0.753 sec)\n","I0202 14:34:10.739993 140715376195456 basic_session_run_hooks.py:260] loss = 2.3903916, step = 780 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.29499\n","I0202 14:34:11.511868 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29499\n","INFO:tensorflow:loss = 2.9059334, step = 781 (0.772 sec)\n","I0202 14:34:11.512197 140715376195456 basic_session_run_hooks.py:260] loss = 2.9059334, step = 781 (0.772 sec)\n","INFO:tensorflow:global_step/sec: 1.34847\n","I0202 14:34:12.253463 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34847\n","INFO:tensorflow:loss = 2.765483, step = 782 (0.742 sec)\n","I0202 14:34:12.253778 140715376195456 basic_session_run_hooks.py:260] loss = 2.765483, step = 782 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.37554\n","I0202 14:34:12.980445 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37554\n","INFO:tensorflow:loss = 2.2910457, step = 783 (0.727 sec)\n","I0202 14:34:12.980872 140715376195456 basic_session_run_hooks.py:260] loss = 2.2910457, step = 783 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.32443\n","I0202 14:34:13.735496 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32443\n","INFO:tensorflow:loss = 2.7037766, step = 784 (0.755 sec)\n","I0202 14:34:13.735798 140715376195456 basic_session_run_hooks.py:260] loss = 2.7037766, step = 784 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.3151\n","I0202 14:34:14.495865 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3151\n","INFO:tensorflow:loss = 2.6410546, step = 785 (0.760 sec)\n","I0202 14:34:14.496157 140715376195456 basic_session_run_hooks.py:260] loss = 2.6410546, step = 785 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 1.36344\n","I0202 14:34:15.229368 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36344\n","INFO:tensorflow:loss = 2.5481749, step = 786 (0.734 sec)\n","I0202 14:34:15.229710 140715376195456 basic_session_run_hooks.py:260] loss = 2.5481749, step = 786 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.34806\n","I0202 14:34:15.971127 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34806\n","INFO:tensorflow:loss = 2.9630694, step = 787 (0.742 sec)\n","I0202 14:34:15.971598 140715376195456 basic_session_run_hooks.py:260] loss = 2.9630694, step = 787 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.33966\n","I0202 14:34:16.717600 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33966\n","INFO:tensorflow:loss = 2.391404, step = 788 (0.746 sec)\n","I0202 14:34:16.717909 140715376195456 basic_session_run_hooks.py:260] loss = 2.391404, step = 788 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 1.26651\n","I0202 14:34:17.507150 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.26651\n","INFO:tensorflow:loss = 2.6177897, step = 789 (0.790 sec)\n","I0202 14:34:17.507488 140715376195456 basic_session_run_hooks.py:260] loss = 2.6177897, step = 789 (0.790 sec)\n","INFO:tensorflow:global_step/sec: 1.36209\n","I0202 14:34:18.241322 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36209\n","INFO:tensorflow:loss = 2.5794592, step = 790 (0.734 sec)\n","I0202 14:34:18.241808 140715376195456 basic_session_run_hooks.py:260] loss = 2.5794592, step = 790 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.34158\n","I0202 14:34:18.986726 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34158\n","INFO:tensorflow:loss = 2.7893827, step = 791 (0.745 sec)\n","I0202 14:34:18.987030 140715376195456 basic_session_run_hooks.py:260] loss = 2.7893827, step = 791 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.30095\n","I0202 14:34:19.755394 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30095\n","INFO:tensorflow:loss = 3.0393696, step = 792 (0.769 sec)\n","I0202 14:34:19.755723 140715376195456 basic_session_run_hooks.py:260] loss = 3.0393696, step = 792 (0.769 sec)\n","INFO:tensorflow:global_step/sec: 1.30678\n","I0202 14:34:20.520624 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30678\n","INFO:tensorflow:loss = 2.97296, step = 793 (0.765 sec)\n","I0202 14:34:20.520959 140715376195456 basic_session_run_hooks.py:260] loss = 2.97296, step = 793 (0.765 sec)\n","INFO:tensorflow:global_step/sec: 1.36856\n","I0202 14:34:21.251307 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36856\n","INFO:tensorflow:loss = 2.5662112, step = 794 (0.731 sec)\n","I0202 14:34:21.251636 140715376195456 basic_session_run_hooks.py:260] loss = 2.5662112, step = 794 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37226\n","I0202 14:34:21.980045 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37226\n","INFO:tensorflow:loss = 2.237627, step = 795 (0.729 sec)\n","I0202 14:34:21.980389 140715376195456 basic_session_run_hooks.py:260] loss = 2.237627, step = 795 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.36931\n","I0202 14:34:22.710335 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36931\n","INFO:tensorflow:loss = 2.7263432, step = 796 (0.730 sec)\n","I0202 14:34:22.710674 140715376195456 basic_session_run_hooks.py:260] loss = 2.7263432, step = 796 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.36123\n","I0202 14:34:23.444955 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36123\n","INFO:tensorflow:loss = 2.3690054, step = 797 (0.735 sec)\n","I0202 14:34:23.445245 140715376195456 basic_session_run_hooks.py:260] loss = 2.3690054, step = 797 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.3877\n","I0202 14:34:24.165599 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3877\n","INFO:tensorflow:loss = 2.897737, step = 798 (0.721 sec)\n","I0202 14:34:24.165916 140715376195456 basic_session_run_hooks.py:260] loss = 2.897737, step = 798 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.30557\n","I0202 14:34:24.931560 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30557\n","INFO:tensorflow:loss = 2.2294812, step = 799 (0.766 sec)\n","I0202 14:34:24.932147 140715376195456 basic_session_run_hooks.py:260] loss = 2.2294812, step = 799 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 1.36479\n","I0202 14:34:25.664243 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36479\n","INFO:tensorflow:loss = 2.516428, step = 800 (0.733 sec)\n","I0202 14:34:25.665332 140715376195456 basic_session_run_hooks.py:260] loss = 2.516428, step = 800 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.37899\n","I0202 14:34:26.389408 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37899\n","INFO:tensorflow:loss = 2.4906747, step = 801 (0.724 sec)\n","I0202 14:34:26.389746 140715376195456 basic_session_run_hooks.py:260] loss = 2.4906747, step = 801 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.38101\n","I0202 14:34:27.113541 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38101\n","INFO:tensorflow:loss = 3.1657941, step = 802 (0.724 sec)\n","I0202 14:34:27.113863 140715376195456 basic_session_run_hooks.py:260] loss = 3.1657941, step = 802 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.35147\n","I0202 14:34:27.853468 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35147\n","INFO:tensorflow:loss = 2.7295127, step = 803 (0.740 sec)\n","I0202 14:34:27.853754 140715376195456 basic_session_run_hooks.py:260] loss = 2.7295127, step = 803 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.36017\n","I0202 14:34:28.588664 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36017\n","INFO:tensorflow:loss = 2.5404892, step = 804 (0.735 sec)\n","I0202 14:34:28.589017 140715376195456 basic_session_run_hooks.py:260] loss = 2.5404892, step = 804 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.37078\n","I0202 14:34:29.318159 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37078\n","INFO:tensorflow:loss = 2.2358649, step = 805 (0.729 sec)\n","I0202 14:34:29.318472 140715376195456 basic_session_run_hooks.py:260] loss = 2.2358649, step = 805 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.41444\n","I0202 14:34:30.025159 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41444\n","INFO:tensorflow:loss = 2.5332873, step = 806 (0.707 sec)\n","I0202 14:34:30.025474 140715376195456 basic_session_run_hooks.py:260] loss = 2.5332873, step = 806 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 1.41437\n","I0202 14:34:30.732205 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41437\n","INFO:tensorflow:loss = 2.6804693, step = 807 (0.707 sec)\n","I0202 14:34:30.732529 140715376195456 basic_session_run_hooks.py:260] loss = 2.6804693, step = 807 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 1.39951\n","I0202 14:34:31.446724 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39951\n","INFO:tensorflow:loss = 3.4668894, step = 808 (0.714 sec)\n","I0202 14:34:31.447012 140715376195456 basic_session_run_hooks.py:260] loss = 3.4668894, step = 808 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.42378\n","I0202 14:34:32.149080 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42378\n","INFO:tensorflow:loss = 2.9396071, step = 809 (0.702 sec)\n","I0202 14:34:32.149394 140715376195456 basic_session_run_hooks.py:260] loss = 2.9396071, step = 809 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.35302\n","I0202 14:34:32.888146 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35302\n","INFO:tensorflow:loss = 2.6991432, step = 810 (0.739 sec)\n","I0202 14:34:32.888485 140715376195456 basic_session_run_hooks.py:260] loss = 2.6991432, step = 810 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.40375\n","I0202 14:34:33.600543 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40375\n","INFO:tensorflow:loss = 2.8065693, step = 811 (0.712 sec)\n","I0202 14:34:33.600847 140715376195456 basic_session_run_hooks.py:260] loss = 2.8065693, step = 811 (0.712 sec)\n","INFO:tensorflow:global_step/sec: 1.38766\n","I0202 14:34:34.321183 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38766\n","INFO:tensorflow:loss = 2.3875923, step = 812 (0.721 sec)\n","I0202 14:34:34.321560 140715376195456 basic_session_run_hooks.py:260] loss = 2.3875923, step = 812 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.38547\n","I0202 14:34:35.042934 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38547\n","INFO:tensorflow:loss = 2.598966, step = 813 (0.722 sec)\n","I0202 14:34:35.043237 140715376195456 basic_session_run_hooks.py:260] loss = 2.598966, step = 813 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.32501\n","I0202 14:34:35.797657 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32501\n","INFO:tensorflow:loss = 2.5124602, step = 814 (0.755 sec)\n","I0202 14:34:35.797956 140715376195456 basic_session_run_hooks.py:260] loss = 2.5124602, step = 814 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.40166\n","I0202 14:34:36.511106 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40166\n","INFO:tensorflow:loss = 3.0298848, step = 815 (0.714 sec)\n","I0202 14:34:36.511585 140715376195456 basic_session_run_hooks.py:260] loss = 3.0298848, step = 815 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.36072\n","I0202 14:34:37.246005 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36072\n","INFO:tensorflow:loss = 2.5861056, step = 816 (0.735 sec)\n","I0202 14:34:37.246301 140715376195456 basic_session_run_hooks.py:260] loss = 2.5861056, step = 816 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35496\n","I0202 14:34:37.984032 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35496\n","INFO:tensorflow:loss = 2.8371613, step = 817 (0.738 sec)\n","I0202 14:34:37.984325 140715376195456 basic_session_run_hooks.py:260] loss = 2.8371613, step = 817 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.34314\n","I0202 14:34:38.728613 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34314\n","INFO:tensorflow:loss = 2.7764816, step = 818 (0.745 sec)\n","I0202 14:34:38.728911 140715376195456 basic_session_run_hooks.py:260] loss = 2.7764816, step = 818 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.4088\n","I0202 14:34:39.438372 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4088\n","INFO:tensorflow:loss = 2.6020389, step = 819 (0.710 sec)\n","I0202 14:34:39.438857 140715376195456 basic_session_run_hooks.py:260] loss = 2.6020389, step = 819 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.34453\n","I0202 14:34:40.182132 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34453\n","INFO:tensorflow:loss = 2.8680015, step = 820 (0.744 sec)\n","I0202 14:34:40.182677 140715376195456 basic_session_run_hooks.py:260] loss = 2.8680015, step = 820 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.35993\n","I0202 14:34:40.917499 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35993\n","INFO:tensorflow:loss = 2.491379, step = 821 (0.735 sec)\n","I0202 14:34:40.917956 140715376195456 basic_session_run_hooks.py:260] loss = 2.491379, step = 821 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.38849\n","I0202 14:34:41.637662 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38849\n","INFO:tensorflow:loss = 2.8226442, step = 822 (0.720 sec)\n","I0202 14:34:41.638133 140715376195456 basic_session_run_hooks.py:260] loss = 2.8226442, step = 822 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.37232\n","I0202 14:34:42.366374 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37232\n","INFO:tensorflow:loss = 2.1564527, step = 823 (0.729 sec)\n","I0202 14:34:42.366857 140715376195456 basic_session_run_hooks.py:260] loss = 2.1564527, step = 823 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.37544\n","I0202 14:34:43.093409 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37544\n","INFO:tensorflow:loss = 2.68366, step = 824 (0.727 sec)\n","I0202 14:34:43.093802 140715376195456 basic_session_run_hooks.py:260] loss = 2.68366, step = 824 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.34177\n","I0202 14:34:43.838684 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34177\n","INFO:tensorflow:loss = 2.4107533, step = 825 (0.745 sec)\n","I0202 14:34:43.838983 140715376195456 basic_session_run_hooks.py:260] loss = 2.4107533, step = 825 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.39018\n","I0202 14:34:44.558008 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39018\n","INFO:tensorflow:loss = 2.4080849, step = 826 (0.720 sec)\n","I0202 14:34:44.558487 140715376195456 basic_session_run_hooks.py:260] loss = 2.4080849, step = 826 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.36882\n","I0202 14:34:45.288580 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36882\n","INFO:tensorflow:loss = 2.724071, step = 827 (0.731 sec)\n","I0202 14:34:45.289044 140715376195456 basic_session_run_hooks.py:260] loss = 2.724071, step = 827 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.35559\n","I0202 14:34:46.026252 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35559\n","INFO:tensorflow:loss = 2.6851408, step = 828 (0.738 sec)\n","I0202 14:34:46.026575 140715376195456 basic_session_run_hooks.py:260] loss = 2.6851408, step = 828 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.41134\n","I0202 14:34:46.734833 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41134\n","INFO:tensorflow:loss = 2.5508146, step = 829 (0.709 sec)\n","I0202 14:34:46.735212 140715376195456 basic_session_run_hooks.py:260] loss = 2.5508146, step = 829 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.37927\n","I0202 14:34:47.459829 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37927\n","INFO:tensorflow:loss = 2.3798513, step = 830 (0.725 sec)\n","I0202 14:34:47.460132 140715376195456 basic_session_run_hooks.py:260] loss = 2.3798513, step = 830 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.37526\n","I0202 14:34:48.186974 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37526\n","INFO:tensorflow:loss = 2.5769536, step = 831 (0.727 sec)\n","I0202 14:34:48.187477 140715376195456 basic_session_run_hooks.py:260] loss = 2.5769536, step = 831 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.34384\n","I0202 14:34:48.931087 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34384\n","INFO:tensorflow:loss = 2.3481605, step = 832 (0.744 sec)\n","I0202 14:34:48.931392 140715376195456 basic_session_run_hooks.py:260] loss = 2.3481605, step = 832 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.35309\n","I0202 14:34:49.670177 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35309\n","INFO:tensorflow:loss = 2.559465, step = 833 (0.739 sec)\n","I0202 14:34:49.670661 140715376195456 basic_session_run_hooks.py:260] loss = 2.559465, step = 833 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.36455\n","I0202 14:34:50.403001 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36455\n","INFO:tensorflow:loss = 2.8657737, step = 834 (0.733 sec)\n","I0202 14:34:50.403608 140715376195456 basic_session_run_hooks.py:260] loss = 2.8657737, step = 834 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.42392\n","I0202 14:34:51.105279 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42392\n","INFO:tensorflow:loss = 2.4070787, step = 835 (0.702 sec)\n","I0202 14:34:51.105779 140715376195456 basic_session_run_hooks.py:260] loss = 2.4070787, step = 835 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.32396\n","I0202 14:34:51.860588 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32396\n","INFO:tensorflow:loss = 2.31045, step = 836 (0.755 sec)\n","I0202 14:34:51.861050 140715376195456 basic_session_run_hooks.py:260] loss = 2.31045, step = 836 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 1.36788\n","I0202 14:34:52.591640 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36788\n","INFO:tensorflow:loss = 2.612066, step = 837 (0.731 sec)\n","I0202 14:34:52.591947 140715376195456 basic_session_run_hooks.py:260] loss = 2.612066, step = 837 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.29155\n","I0202 14:34:53.365939 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29155\n","INFO:tensorflow:loss = 2.1422102, step = 838 (0.774 sec)\n","I0202 14:34:53.366253 140715376195456 basic_session_run_hooks.py:260] loss = 2.1422102, step = 838 (0.774 sec)\n","INFO:tensorflow:global_step/sec: 1.35684\n","I0202 14:34:54.102966 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35684\n","INFO:tensorflow:loss = 2.786364, step = 839 (0.737 sec)\n","I0202 14:34:54.103297 140715376195456 basic_session_run_hooks.py:260] loss = 2.786364, step = 839 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37757\n","I0202 14:34:54.828845 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37757\n","INFO:tensorflow:loss = 2.7426422, step = 840 (0.726 sec)\n","I0202 14:34:54.829364 140715376195456 basic_session_run_hooks.py:260] loss = 2.7426422, step = 840 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38312\n","I0202 14:34:55.551827 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38312\n","INFO:tensorflow:loss = 2.8119426, step = 841 (0.723 sec)\n","I0202 14:34:55.552115 140715376195456 basic_session_run_hooks.py:260] loss = 2.8119426, step = 841 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.34156\n","I0202 14:34:56.297245 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34156\n","INFO:tensorflow:loss = 3.0228157, step = 842 (0.745 sec)\n","I0202 14:34:56.297578 140715376195456 basic_session_run_hooks.py:260] loss = 3.0228157, step = 842 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.38527\n","I0202 14:34:57.019167 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38527\n","INFO:tensorflow:loss = 2.6339977, step = 843 (0.722 sec)\n","I0202 14:34:57.019651 140715376195456 basic_session_run_hooks.py:260] loss = 2.6339977, step = 843 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.34302\n","I0202 14:34:57.763718 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34302\n","INFO:tensorflow:loss = 2.349995, step = 844 (0.744 sec)\n","I0202 14:34:57.764067 140715376195456 basic_session_run_hooks.py:260] loss = 2.349995, step = 844 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.39029\n","I0202 14:34:58.482979 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39029\n","INFO:tensorflow:loss = 2.7416394, step = 845 (0.719 sec)\n","I0202 14:34:58.483273 140715376195456 basic_session_run_hooks.py:260] loss = 2.7416394, step = 845 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.34794\n","I0202 14:34:59.224878 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34794\n","INFO:tensorflow:loss = 2.6245878, step = 846 (0.742 sec)\n","I0202 14:34:59.225245 140715376195456 basic_session_run_hooks.py:260] loss = 2.6245878, step = 846 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.40109\n","I0202 14:34:59.938616 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40109\n","INFO:tensorflow:loss = 2.4016733, step = 847 (0.714 sec)\n","I0202 14:34:59.938939 140715376195456 basic_session_run_hooks.py:260] loss = 2.4016733, step = 847 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.3773\n","I0202 14:35:00.664672 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3773\n","INFO:tensorflow:loss = 2.623151, step = 848 (0.726 sec)\n","I0202 14:35:00.665146 140715376195456 basic_session_run_hooks.py:260] loss = 2.623151, step = 848 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.29698\n","I0202 14:35:01.435654 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29698\n","INFO:tensorflow:loss = 2.3456337, step = 849 (0.771 sec)\n","I0202 14:35:01.436110 140715376195456 basic_session_run_hooks.py:260] loss = 2.3456337, step = 849 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 1.34979\n","I0202 14:35:02.176533 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34979\n","INFO:tensorflow:loss = 2.9555995, step = 850 (0.741 sec)\n","I0202 14:35:02.176998 140715376195456 basic_session_run_hooks.py:260] loss = 2.9555995, step = 850 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.42855\n","I0202 14:35:02.876542 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42855\n","INFO:tensorflow:loss = 2.5535405, step = 851 (0.700 sec)\n","I0202 14:35:02.877090 140715376195456 basic_session_run_hooks.py:260] loss = 2.5535405, step = 851 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.39256\n","I0202 14:35:03.594622 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39256\n","INFO:tensorflow:loss = 2.5318801, step = 852 (0.718 sec)\n","I0202 14:35:03.595114 140715376195456 basic_session_run_hooks.py:260] loss = 2.5318801, step = 852 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.38662\n","I0202 14:35:04.315801 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38662\n","INFO:tensorflow:loss = 2.9096987, step = 853 (0.721 sec)\n","I0202 14:35:04.316094 140715376195456 basic_session_run_hooks.py:260] loss = 2.9096987, step = 853 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.38956\n","I0202 14:35:05.035477 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38956\n","INFO:tensorflow:loss = 2.6795514, step = 854 (0.720 sec)\n","I0202 14:35:05.035784 140715376195456 basic_session_run_hooks.py:260] loss = 2.6795514, step = 854 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.35237\n","I0202 14:35:05.774882 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35237\n","INFO:tensorflow:loss = 2.3135698, step = 855 (0.739 sec)\n","I0202 14:35:05.775181 140715376195456 basic_session_run_hooks.py:260] loss = 2.3135698, step = 855 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.32654\n","I0202 14:35:06.528748 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32654\n","INFO:tensorflow:loss = 2.8038123, step = 856 (0.754 sec)\n","I0202 14:35:06.529243 140715376195456 basic_session_run_hooks.py:260] loss = 2.8038123, step = 856 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.33853\n","I0202 14:35:07.275833 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33853\n","INFO:tensorflow:loss = 3.1461253, step = 857 (0.748 sec)\n","I0202 14:35:07.277146 140715376195456 basic_session_run_hooks.py:260] loss = 3.1461253, step = 857 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.33693\n","I0202 14:35:08.023832 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33693\n","INFO:tensorflow:loss = 2.3527813, step = 858 (0.747 sec)\n","I0202 14:35:08.024370 140715376195456 basic_session_run_hooks.py:260] loss = 2.3527813, step = 858 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.29783\n","I0202 14:35:08.794349 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.29783\n","INFO:tensorflow:loss = 2.5880964, step = 859 (0.771 sec)\n","I0202 14:35:08.794909 140715376195456 basic_session_run_hooks.py:260] loss = 2.5880964, step = 859 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 1.37424\n","I0202 14:35:09.522003 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37424\n","INFO:tensorflow:loss = 2.5922036, step = 860 (0.727 sec)\n","I0202 14:35:09.522328 140715376195456 basic_session_run_hooks.py:260] loss = 2.5922036, step = 860 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.34281\n","I0202 14:35:10.266717 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34281\n","INFO:tensorflow:loss = 2.8759348, step = 861 (0.745 sec)\n","I0202 14:35:10.267029 140715376195456 basic_session_run_hooks.py:260] loss = 2.8759348, step = 861 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.35432\n","I0202 14:35:11.005069 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35432\n","INFO:tensorflow:loss = 2.147432, step = 862 (0.738 sec)\n","I0202 14:35:11.005366 140715376195456 basic_session_run_hooks.py:260] loss = 2.147432, step = 862 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.32688\n","I0202 14:35:11.758710 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32688\n","INFO:tensorflow:loss = 2.6246133, step = 863 (0.754 sec)\n","I0202 14:35:11.759166 140715376195456 basic_session_run_hooks.py:260] loss = 2.6246133, step = 863 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.41782\n","I0202 14:35:12.464034 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41782\n","INFO:tensorflow:loss = 3.2673593, step = 864 (0.705 sec)\n","I0202 14:35:12.464541 140715376195456 basic_session_run_hooks.py:260] loss = 3.2673593, step = 864 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 1.37225\n","I0202 14:35:13.192758 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37225\n","INFO:tensorflow:loss = 2.4878323, step = 865 (0.729 sec)\n","I0202 14:35:13.193219 140715376195456 basic_session_run_hooks.py:260] loss = 2.4878323, step = 865 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.39933\n","I0202 14:35:13.907385 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39933\n","INFO:tensorflow:loss = 2.4842067, step = 866 (0.715 sec)\n","I0202 14:35:13.907762 140715376195456 basic_session_run_hooks.py:260] loss = 2.4842067, step = 866 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.34668\n","I0202 14:35:14.649961 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34668\n","INFO:tensorflow:loss = 2.68794, step = 867 (0.743 sec)\n","I0202 14:35:14.650495 140715376195456 basic_session_run_hooks.py:260] loss = 2.68794, step = 867 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.28159\n","I0202 14:35:15.430285 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.28159\n","INFO:tensorflow:loss = 2.510668, step = 868 (0.780 sec)\n","I0202 14:35:15.430874 140715376195456 basic_session_run_hooks.py:260] loss = 2.510668, step = 868 (0.780 sec)\n","INFO:tensorflow:global_step/sec: 1.34757\n","I0202 14:35:16.172311 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34757\n","INFO:tensorflow:loss = 2.4875364, step = 869 (0.742 sec)\n","I0202 14:35:16.172803 140715376195456 basic_session_run_hooks.py:260] loss = 2.4875364, step = 869 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.2677\n","I0202 14:35:16.961139 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.2677\n","INFO:tensorflow:loss = 2.7477741, step = 870 (0.789 sec)\n","I0202 14:35:16.961644 140715376195456 basic_session_run_hooks.py:260] loss = 2.7477741, step = 870 (0.789 sec)\n","INFO:tensorflow:global_step/sec: 1.33153\n","I0202 14:35:17.712158 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33153\n","INFO:tensorflow:loss = 2.515838, step = 871 (0.751 sec)\n","I0202 14:35:17.712630 140715376195456 basic_session_run_hooks.py:260] loss = 2.515838, step = 871 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.32872\n","I0202 14:35:18.464767 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32872\n","INFO:tensorflow:loss = 2.4382672, step = 872 (0.753 sec)\n","I0202 14:35:18.465284 140715376195456 basic_session_run_hooks.py:260] loss = 2.4382672, step = 872 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 1.33646\n","I0202 14:35:19.213003 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33646\n","INFO:tensorflow:loss = 2.714738, step = 873 (0.748 sec)\n","I0202 14:35:19.213509 140715376195456 basic_session_run_hooks.py:260] loss = 2.714738, step = 873 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.37227\n","I0202 14:35:19.941728 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37227\n","INFO:tensorflow:loss = 2.7326794, step = 874 (0.729 sec)\n","I0202 14:35:19.942044 140715376195456 basic_session_run_hooks.py:260] loss = 2.7326794, step = 874 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.34598\n","I0202 14:35:20.684673 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34598\n","INFO:tensorflow:loss = 3.048468, step = 875 (0.743 sec)\n","I0202 14:35:20.684991 140715376195456 basic_session_run_hooks.py:260] loss = 3.048468, step = 875 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.36199\n","I0202 14:35:21.418889 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36199\n","INFO:tensorflow:loss = 2.3091931, step = 876 (0.734 sec)\n","I0202 14:35:21.419358 140715376195456 basic_session_run_hooks.py:260] loss = 2.3091931, step = 876 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.33863\n","I0202 14:35:22.165944 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33863\n","INFO:tensorflow:loss = 2.4046829, step = 877 (0.747 sec)\n","I0202 14:35:22.166287 140715376195456 basic_session_run_hooks.py:260] loss = 2.4046829, step = 877 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.38498\n","I0202 14:35:22.887965 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38498\n","INFO:tensorflow:loss = 2.777244, step = 878 (0.722 sec)\n","I0202 14:35:22.888544 140715376195456 basic_session_run_hooks.py:260] loss = 2.777244, step = 878 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.38638\n","I0202 14:35:23.609253 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38638\n","INFO:tensorflow:loss = 2.2155395, step = 879 (0.721 sec)\n","I0202 14:35:23.609565 140715376195456 basic_session_run_hooks.py:260] loss = 2.2155395, step = 879 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 1.35565\n","I0202 14:35:24.346923 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35565\n","INFO:tensorflow:loss = 2.3666978, step = 880 (0.738 sec)\n","I0202 14:35:24.347213 140715376195456 basic_session_run_hooks.py:260] loss = 2.3666978, step = 880 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.42137\n","I0202 14:35:25.050490 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42137\n","INFO:tensorflow:loss = 2.6496115, step = 881 (0.704 sec)\n","I0202 14:35:25.051006 140715376195456 basic_session_run_hooks.py:260] loss = 2.6496115, step = 881 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 1.38921\n","I0202 14:35:25.770311 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38921\n","INFO:tensorflow:loss = 2.3296516, step = 882 (0.720 sec)\n","I0202 14:35:25.770621 140715376195456 basic_session_run_hooks.py:260] loss = 2.3296516, step = 882 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.36352\n","I0202 14:35:26.503691 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36352\n","INFO:tensorflow:loss = 3.1106489, step = 883 (0.733 sec)\n","I0202 14:35:26.504046 140715376195456 basic_session_run_hooks.py:260] loss = 3.1106489, step = 883 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.32048\n","I0202 14:35:27.260989 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.32048\n","INFO:tensorflow:loss = 2.495726, step = 884 (0.757 sec)\n","I0202 14:35:27.261283 140715376195456 basic_session_run_hooks.py:260] loss = 2.495726, step = 884 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 1.37479\n","I0202 14:35:27.988391 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37479\n","INFO:tensorflow:loss = 2.3275065, step = 885 (0.727 sec)\n","I0202 14:35:27.988730 140715376195456 basic_session_run_hooks.py:260] loss = 2.3275065, step = 885 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.34752\n","I0202 14:35:28.730519 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34752\n","INFO:tensorflow:loss = 2.9536138, step = 886 (0.742 sec)\n","I0202 14:35:28.730852 140715376195456 basic_session_run_hooks.py:260] loss = 2.9536138, step = 886 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.3577\n","I0202 14:35:29.467037 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3577\n","INFO:tensorflow:loss = 2.6557877, step = 887 (0.736 sec)\n","I0202 14:35:29.467330 140715376195456 basic_session_run_hooks.py:260] loss = 2.6557877, step = 887 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 1.3636\n","I0202 14:35:30.200391 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3636\n","INFO:tensorflow:loss = 2.2715993, step = 888 (0.733 sec)\n","I0202 14:35:30.200717 140715376195456 basic_session_run_hooks.py:260] loss = 2.2715993, step = 888 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.36778\n","I0202 14:35:30.931497 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36778\n","INFO:tensorflow:loss = 2.7167556, step = 889 (0.731 sec)\n","I0202 14:35:30.931791 140715376195456 basic_session_run_hooks.py:260] loss = 2.7167556, step = 889 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.33578\n","I0202 14:35:31.680114 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33578\n","INFO:tensorflow:loss = 2.6907113, step = 890 (0.749 sec)\n","I0202 14:35:31.680429 140715376195456 basic_session_run_hooks.py:260] loss = 2.6907113, step = 890 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.36038\n","I0202 14:35:32.415195 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36038\n","INFO:tensorflow:loss = 2.6138506, step = 891 (0.735 sec)\n","I0202 14:35:32.415514 140715376195456 basic_session_run_hooks.py:260] loss = 2.6138506, step = 891 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.35207\n","I0202 14:35:33.154805 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35207\n","INFO:tensorflow:loss = 2.9888835, step = 892 (0.740 sec)\n","I0202 14:35:33.155099 140715376195456 basic_session_run_hooks.py:260] loss = 2.9888835, step = 892 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 1.3636\n","I0202 14:35:33.888160 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3636\n","INFO:tensorflow:loss = 2.9358287, step = 893 (0.733 sec)\n","I0202 14:35:33.888544 140715376195456 basic_session_run_hooks.py:260] loss = 2.9358287, step = 893 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.3576\n","I0202 14:35:34.624751 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3576\n","INFO:tensorflow:loss = 2.343805, step = 894 (0.737 sec)\n","I0202 14:35:34.625072 140715376195456 basic_session_run_hooks.py:260] loss = 2.343805, step = 894 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 1.37605\n","I0202 14:35:35.351505 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37605\n","INFO:tensorflow:loss = 2.4169536, step = 895 (0.727 sec)\n","I0202 14:35:35.351832 140715376195456 basic_session_run_hooks.py:260] loss = 2.4169536, step = 895 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.3998\n","I0202 14:35:36.065863 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3998\n","INFO:tensorflow:loss = 2.7217393, step = 896 (0.715 sec)\n","I0202 14:35:36.066354 140715376195456 basic_session_run_hooks.py:260] loss = 2.7217393, step = 896 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.37472\n","I0202 14:35:36.793271 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37472\n","INFO:tensorflow:loss = 2.7069604, step = 897 (0.727 sec)\n","I0202 14:35:36.793592 140715376195456 basic_session_run_hooks.py:260] loss = 2.7069604, step = 897 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.37023\n","I0202 14:35:37.523103 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37023\n","INFO:tensorflow:loss = 2.6256354, step = 898 (0.730 sec)\n","I0202 14:35:37.523656 140715376195456 basic_session_run_hooks.py:260] loss = 2.6256354, step = 898 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.38979\n","I0202 14:35:38.242621 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38979\n","INFO:tensorflow:loss = 2.3780985, step = 899 (0.719 sec)\n","I0202 14:35:38.242936 140715376195456 basic_session_run_hooks.py:260] loss = 2.3780985, step = 899 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.36963\n","I0202 14:35:38.972753 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36963\n","INFO:tensorflow:loss = 2.8496287, step = 900 (0.731 sec)\n","I0202 14:35:38.973969 140715376195456 basic_session_run_hooks.py:260] loss = 2.8496287, step = 900 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.37299\n","I0202 14:35:39.701084 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37299\n","INFO:tensorflow:loss = 2.4940324, step = 901 (0.727 sec)\n","I0202 14:35:39.701402 140715376195456 basic_session_run_hooks.py:260] loss = 2.4940324, step = 901 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.36376\n","I0202 14:35:40.434354 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36376\n","INFO:tensorflow:loss = 2.656375, step = 902 (0.733 sec)\n","I0202 14:35:40.434832 140715376195456 basic_session_run_hooks.py:260] loss = 2.656375, step = 902 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.3895\n","I0202 14:35:41.154053 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3895\n","INFO:tensorflow:loss = 2.563498, step = 903 (0.720 sec)\n","I0202 14:35:41.154350 140715376195456 basic_session_run_hooks.py:260] loss = 2.563498, step = 903 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.35569\n","I0202 14:35:41.891661 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35569\n","INFO:tensorflow:loss = 3.2568758, step = 904 (0.738 sec)\n","I0202 14:35:41.891977 140715376195456 basic_session_run_hooks.py:260] loss = 3.2568758, step = 904 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.35375\n","I0202 14:35:42.630354 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35375\n","INFO:tensorflow:loss = 3.0719326, step = 905 (0.739 sec)\n","I0202 14:35:42.630705 140715376195456 basic_session_run_hooks.py:260] loss = 3.0719326, step = 905 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.40153\n","I0202 14:35:43.343854 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40153\n","INFO:tensorflow:loss = 3.0625358, step = 906 (0.714 sec)\n","I0202 14:35:43.344240 140715376195456 basic_session_run_hooks.py:260] loss = 3.0625358, step = 906 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.40414\n","I0202 14:35:44.056029 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40414\n","INFO:tensorflow:loss = 2.4875937, step = 907 (0.712 sec)\n","I0202 14:35:44.056368 140715376195456 basic_session_run_hooks.py:260] loss = 2.4875937, step = 907 (0.712 sec)\n","INFO:tensorflow:global_step/sec: 1.36242\n","I0202 14:35:44.790004 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36242\n","INFO:tensorflow:loss = 2.505009, step = 908 (0.734 sec)\n","I0202 14:35:44.790452 140715376195456 basic_session_run_hooks.py:260] loss = 2.505009, step = 908 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.37187\n","I0202 14:35:45.518950 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37187\n","INFO:tensorflow:loss = 2.3709211, step = 909 (0.729 sec)\n","I0202 14:35:45.519255 140715376195456 basic_session_run_hooks.py:260] loss = 2.3709211, step = 909 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.37821\n","I0202 14:35:46.244537 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37821\n","INFO:tensorflow:loss = 2.4289923, step = 910 (0.726 sec)\n","I0202 14:35:46.244863 140715376195456 basic_session_run_hooks.py:260] loss = 2.4289923, step = 910 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.3606\n","I0202 14:35:46.979521 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3606\n","INFO:tensorflow:loss = 3.2855353, step = 911 (0.735 sec)\n","I0202 14:35:46.979826 140715376195456 basic_session_run_hooks.py:260] loss = 3.2855353, step = 911 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.36161\n","I0202 14:35:47.713921 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36161\n","INFO:tensorflow:loss = 2.5186234, step = 912 (0.735 sec)\n","I0202 14:35:47.714335 140715376195456 basic_session_run_hooks.py:260] loss = 2.5186234, step = 912 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.37728\n","I0202 14:35:48.440000 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37728\n","INFO:tensorflow:loss = 2.1473863, step = 913 (0.726 sec)\n","I0202 14:35:48.440444 140715376195456 basic_session_run_hooks.py:260] loss = 2.1473863, step = 913 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.37204\n","I0202 14:35:49.168841 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37204\n","INFO:tensorflow:loss = 2.7358015, step = 914 (0.729 sec)\n","I0202 14:35:49.169163 140715376195456 basic_session_run_hooks.py:260] loss = 2.7358015, step = 914 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.3527\n","I0202 14:35:49.908105 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3527\n","INFO:tensorflow:loss = 3.067338, step = 915 (0.739 sec)\n","I0202 14:35:49.908575 140715376195456 basic_session_run_hooks.py:260] loss = 3.067338, step = 915 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.4007\n","I0202 14:35:50.622032 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4007\n","INFO:tensorflow:loss = 2.6295555, step = 916 (0.714 sec)\n","I0202 14:35:50.622508 140715376195456 basic_session_run_hooks.py:260] loss = 2.6295555, step = 916 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.34932\n","I0202 14:35:51.363123 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34932\n","INFO:tensorflow:loss = 2.8472066, step = 917 (0.741 sec)\n","I0202 14:35:51.363453 140715376195456 basic_session_run_hooks.py:260] loss = 2.8472066, step = 917 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.33234\n","I0202 14:35:52.113744 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33234\n","INFO:tensorflow:loss = 2.734824, step = 918 (0.751 sec)\n","I0202 14:35:52.114240 140715376195456 basic_session_run_hooks.py:260] loss = 2.734824, step = 918 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.34259\n","I0202 14:35:52.858531 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34259\n","INFO:tensorflow:loss = 2.7496998, step = 919 (0.745 sec)\n","I0202 14:35:52.858942 140715376195456 basic_session_run_hooks.py:260] loss = 2.7496998, step = 919 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.30888\n","I0202 14:35:53.622548 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30888\n","INFO:tensorflow:loss = 2.6484911, step = 920 (0.764 sec)\n","I0202 14:35:53.622962 140715376195456 basic_session_run_hooks.py:260] loss = 2.6484911, step = 920 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 1.34571\n","I0202 14:35:54.365646 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34571\n","INFO:tensorflow:loss = 2.664603, step = 921 (0.743 sec)\n","I0202 14:35:54.366096 140715376195456 basic_session_run_hooks.py:260] loss = 2.664603, step = 921 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.3624\n","I0202 14:35:55.099664 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3624\n","INFO:tensorflow:loss = 2.7208471, step = 922 (0.734 sec)\n","I0202 14:35:55.100141 140715376195456 basic_session_run_hooks.py:260] loss = 2.7208471, step = 922 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.34625\n","I0202 14:35:55.842449 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34625\n","INFO:tensorflow:loss = 2.2789044, step = 923 (0.743 sec)\n","I0202 14:35:55.842736 140715376195456 basic_session_run_hooks.py:260] loss = 2.2789044, step = 923 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 1.38895\n","I0202 14:35:56.562405 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38895\n","INFO:tensorflow:loss = 2.804229, step = 924 (0.720 sec)\n","I0202 14:35:56.562855 140715376195456 basic_session_run_hooks.py:260] loss = 2.804229, step = 924 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.33481\n","I0202 14:35:57.311595 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33481\n","INFO:tensorflow:loss = 2.4738421, step = 925 (0.749 sec)\n","I0202 14:35:57.312015 140715376195456 basic_session_run_hooks.py:260] loss = 2.4738421, step = 925 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 1.34337\n","I0202 14:35:58.055978 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34337\n","INFO:tensorflow:loss = 2.087138, step = 926 (0.744 sec)\n","I0202 14:35:58.056274 140715376195456 basic_session_run_hooks.py:260] loss = 2.087138, step = 926 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.36095\n","I0202 14:35:58.790772 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36095\n","INFO:tensorflow:loss = 2.2027767, step = 927 (0.735 sec)\n","I0202 14:35:58.791238 140715376195456 basic_session_run_hooks.py:260] loss = 2.2027767, step = 927 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 1.36664\n","I0202 14:35:59.522502 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36664\n","INFO:tensorflow:loss = 2.4152174, step = 928 (0.732 sec)\n","I0202 14:35:59.522802 140715376195456 basic_session_run_hooks.py:260] loss = 2.4152174, step = 928 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.37796\n","I0202 14:36:00.248181 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37796\n","INFO:tensorflow:loss = 2.519942, step = 929 (0.726 sec)\n","I0202 14:36:00.248609 140715376195456 basic_session_run_hooks.py:260] loss = 2.519942, step = 929 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.39395\n","I0202 14:36:00.965601 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39395\n","INFO:tensorflow:loss = 2.2950253, step = 930 (0.717 sec)\n","I0202 14:36:00.966021 140715376195456 basic_session_run_hooks.py:260] loss = 2.2950253, step = 930 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 1.40021\n","I0202 14:36:01.679750 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40021\n","INFO:tensorflow:loss = 2.3778172, step = 931 (0.714 sec)\n","I0202 14:36:01.680059 140715376195456 basic_session_run_hooks.py:260] loss = 2.3778172, step = 931 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 1.35428\n","I0202 14:36:02.418154 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35428\n","INFO:tensorflow:loss = 2.7377584, step = 932 (0.738 sec)\n","I0202 14:36:02.418490 140715376195456 basic_session_run_hooks.py:260] loss = 2.7377584, step = 932 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.37078\n","I0202 14:36:03.147696 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37078\n","INFO:tensorflow:loss = 3.1073132, step = 933 (0.730 sec)\n","I0202 14:36:03.148138 140715376195456 basic_session_run_hooks.py:260] loss = 3.1073132, step = 933 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 1.36526\n","I0202 14:36:03.880140 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36526\n","INFO:tensorflow:loss = 3.1727757, step = 934 (0.732 sec)\n","I0202 14:36:03.880589 140715376195456 basic_session_run_hooks.py:260] loss = 3.1727757, step = 934 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.39045\n","I0202 14:36:04.599339 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39045\n","INFO:tensorflow:loss = 2.2165344, step = 935 (0.719 sec)\n","I0202 14:36:04.599813 140715376195456 basic_session_run_hooks.py:260] loss = 2.2165344, step = 935 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 1.35568\n","I0202 14:36:05.336955 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35568\n","INFO:tensorflow:loss = 2.6476612, step = 936 (0.738 sec)\n","I0202 14:36:05.337446 140715376195456 basic_session_run_hooks.py:260] loss = 2.6476612, step = 936 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 1.38536\n","I0202 14:36:06.058793 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38536\n","INFO:tensorflow:loss = 2.5155644, step = 937 (0.722 sec)\n","I0202 14:36:06.059275 140715376195456 basic_session_run_hooks.py:260] loss = 2.5155644, step = 937 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.4099\n","I0202 14:36:06.768054 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4099\n","INFO:tensorflow:loss = 2.547714, step = 938 (0.709 sec)\n","I0202 14:36:06.768338 140715376195456 basic_session_run_hooks.py:260] loss = 2.547714, step = 938 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 1.37983\n","I0202 14:36:07.492783 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37983\n","INFO:tensorflow:loss = 2.4653418, step = 939 (0.725 sec)\n","I0202 14:36:07.493196 140715376195456 basic_session_run_hooks.py:260] loss = 2.4653418, step = 939 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.3272\n","I0202 14:36:08.246284 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3272\n","INFO:tensorflow:loss = 2.4190218, step = 940 (0.754 sec)\n","I0202 14:36:08.246713 140715376195456 basic_session_run_hooks.py:260] loss = 2.4190218, step = 940 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 1.36585\n","I0202 14:36:08.978409 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36585\n","INFO:tensorflow:loss = 2.5193794, step = 941 (0.732 sec)\n","I0202 14:36:08.978907 140715376195456 basic_session_run_hooks.py:260] loss = 2.5193794, step = 941 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.38921\n","I0202 14:36:09.698231 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38921\n","INFO:tensorflow:loss = 2.3048308, step = 942 (0.720 sec)\n","I0202 14:36:09.698539 140715376195456 basic_session_run_hooks.py:260] loss = 2.3048308, step = 942 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.34498\n","I0202 14:36:10.441745 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34498\n","INFO:tensorflow:loss = 2.3783548, step = 943 (0.744 sec)\n","I0202 14:36:10.442162 140715376195456 basic_session_run_hooks.py:260] loss = 2.3783548, step = 943 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 1.37636\n","I0202 14:36:11.168326 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37636\n","INFO:tensorflow:loss = 3.2943132, step = 944 (0.727 sec)\n","I0202 14:36:11.168852 140715376195456 basic_session_run_hooks.py:260] loss = 3.2943132, step = 944 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.36871\n","I0202 14:36:11.898929 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36871\n","INFO:tensorflow:loss = 2.6999378, step = 945 (0.731 sec)\n","I0202 14:36:11.899362 140715376195456 basic_session_run_hooks.py:260] loss = 2.6999378, step = 945 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.38597\n","I0202 14:36:12.620447 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38597\n","INFO:tensorflow:loss = 2.8295083, step = 946 (0.722 sec)\n","I0202 14:36:12.620900 140715376195456 basic_session_run_hooks.py:260] loss = 2.8295083, step = 946 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 1.36374\n","I0202 14:36:13.353699 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36374\n","INFO:tensorflow:loss = 2.2082782, step = 947 (0.733 sec)\n","I0202 14:36:13.354000 140715376195456 basic_session_run_hooks.py:260] loss = 2.2082782, step = 947 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 1.37796\n","I0202 14:36:14.079437 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37796\n","INFO:tensorflow:loss = 2.3115852, step = 948 (0.726 sec)\n","I0202 14:36:14.079864 140715376195456 basic_session_run_hooks.py:260] loss = 2.3115852, step = 948 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.38959\n","I0202 14:36:14.799065 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38959\n","INFO:tensorflow:loss = 2.9186535, step = 949 (0.720 sec)\n","I0202 14:36:14.799492 140715376195456 basic_session_run_hooks.py:260] loss = 2.9186535, step = 949 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 1.33905\n","I0202 14:36:15.545876 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33905\n","INFO:tensorflow:loss = 2.5828092, step = 950 (0.747 sec)\n","I0202 14:36:15.546310 140715376195456 basic_session_run_hooks.py:260] loss = 2.5828092, step = 950 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 1.36836\n","I0202 14:36:16.276662 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36836\n","INFO:tensorflow:loss = 2.5672445, step = 951 (0.731 sec)\n","I0202 14:36:16.277101 140715376195456 basic_session_run_hooks.py:260] loss = 2.5672445, step = 951 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.40451\n","I0202 14:36:16.988659 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40451\n","INFO:tensorflow:loss = 2.252573, step = 952 (0.712 sec)\n","I0202 14:36:16.988974 140715376195456 basic_session_run_hooks.py:260] loss = 2.252573, step = 952 (0.712 sec)\n","INFO:tensorflow:global_step/sec: 1.36579\n","I0202 14:36:17.720853 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36579\n","INFO:tensorflow:loss = 2.41366, step = 953 (0.732 sec)\n","I0202 14:36:17.721284 140715376195456 basic_session_run_hooks.py:260] loss = 2.41366, step = 953 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.3969\n","I0202 14:36:18.436711 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3969\n","INFO:tensorflow:loss = 2.3408809, step = 954 (0.716 sec)\n","I0202 14:36:18.437009 140715376195456 basic_session_run_hooks.py:260] loss = 2.3408809, step = 954 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.36866\n","I0202 14:36:19.167330 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36866\n","INFO:tensorflow:loss = 2.3294315, step = 955 (0.731 sec)\n","I0202 14:36:19.167755 140715376195456 basic_session_run_hooks.py:260] loss = 2.3294315, step = 955 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 1.40153\n","I0202 14:36:19.880868 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40153\n","INFO:tensorflow:loss = 2.7712796, step = 956 (0.713 sec)\n","I0202 14:36:19.881167 140715376195456 basic_session_run_hooks.py:260] loss = 2.7712796, step = 956 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.37542\n","I0202 14:36:20.607901 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37542\n","INFO:tensorflow:loss = 2.3578777, step = 957 (0.727 sec)\n","I0202 14:36:20.608198 140715376195456 basic_session_run_hooks.py:260] loss = 2.3578777, step = 957 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.37784\n","I0202 14:36:21.333655 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37784\n","INFO:tensorflow:loss = 2.5247574, step = 958 (0.726 sec)\n","I0202 14:36:21.334073 140715376195456 basic_session_run_hooks.py:260] loss = 2.5247574, step = 958 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 1.37629\n","I0202 14:36:22.060255 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37629\n","INFO:tensorflow:loss = 2.912911, step = 959 (0.727 sec)\n","I0202 14:36:22.060581 140715376195456 basic_session_run_hooks.py:260] loss = 2.912911, step = 959 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.43299\n","I0202 14:36:22.758099 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.43299\n","INFO:tensorflow:loss = 2.9260068, step = 960 (0.698 sec)\n","I0202 14:36:22.758524 140715376195456 basic_session_run_hooks.py:260] loss = 2.9260068, step = 960 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 1.41606\n","I0202 14:36:23.464277 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41606\n","INFO:tensorflow:loss = 2.8793237, step = 961 (0.706 sec)\n","I0202 14:36:23.464704 140715376195456 basic_session_run_hooks.py:260] loss = 2.8793237, step = 961 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.40731\n","I0202 14:36:24.174865 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40731\n","INFO:tensorflow:loss = 2.4588523, step = 962 (0.710 sec)\n","I0202 14:36:24.175167 140715376195456 basic_session_run_hooks.py:260] loss = 2.4588523, step = 962 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.40913\n","I0202 14:36:24.884547 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40913\n","INFO:tensorflow:loss = 2.3581538, step = 963 (0.710 sec)\n","I0202 14:36:24.884969 140715376195456 basic_session_run_hooks.py:260] loss = 2.3581538, step = 963 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 1.39912\n","I0202 14:36:25.599248 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39912\n","INFO:tensorflow:loss = 2.7413304, step = 964 (0.715 sec)\n","I0202 14:36:25.599674 140715376195456 basic_session_run_hooks.py:260] loss = 2.7413304, step = 964 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.39809\n","I0202 14:36:26.314532 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39809\n","INFO:tensorflow:loss = 2.25334, step = 965 (0.715 sec)\n","I0202 14:36:26.314940 140715376195456 basic_session_run_hooks.py:260] loss = 2.25334, step = 965 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.36698\n","I0202 14:36:27.046069 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36698\n","INFO:tensorflow:loss = 2.5989676, step = 966 (0.732 sec)\n","I0202 14:36:27.046591 140715376195456 basic_session_run_hooks.py:260] loss = 2.5989676, step = 966 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.34277\n","I0202 14:36:27.790796 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34277\n","INFO:tensorflow:loss = 2.6709085, step = 967 (0.745 sec)\n","I0202 14:36:27.791273 140715376195456 basic_session_run_hooks.py:260] loss = 2.6709085, step = 967 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 1.36276\n","I0202 14:36:28.524615 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36276\n","INFO:tensorflow:loss = 2.2698736, step = 968 (0.734 sec)\n","I0202 14:36:28.525028 140715376195456 basic_session_run_hooks.py:260] loss = 2.2698736, step = 968 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 1.30364\n","I0202 14:36:29.291701 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.30364\n","INFO:tensorflow:loss = 3.5510757, step = 969 (0.767 sec)\n","I0202 14:36:29.292146 140715376195456 basic_session_run_hooks.py:260] loss = 3.5510757, step = 969 (0.767 sec)\n","INFO:tensorflow:global_step/sec: 1.38248\n","I0202 14:36:30.015008 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38248\n","INFO:tensorflow:loss = 2.5775976, step = 970 (0.723 sec)\n","I0202 14:36:30.015488 140715376195456 basic_session_run_hooks.py:260] loss = 2.5775976, step = 970 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 1.33339\n","I0202 14:36:30.765012 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33339\n","INFO:tensorflow:loss = 2.6775188, step = 971 (0.750 sec)\n","I0202 14:36:30.765474 140715376195456 basic_session_run_hooks.py:260] loss = 2.6775188, step = 971 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 1.37645\n","I0202 14:36:31.491540 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37645\n","INFO:tensorflow:loss = 2.5034337, step = 972 (0.727 sec)\n","I0202 14:36:31.491980 140715376195456 basic_session_run_hooks.py:260] loss = 2.5034337, step = 972 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 1.36527\n","I0202 14:36:32.223961 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.36527\n","INFO:tensorflow:loss = 2.8224037, step = 973 (0.732 sec)\n","I0202 14:36:32.224291 140715376195456 basic_session_run_hooks.py:260] loss = 2.8224037, step = 973 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 1.41625\n","I0202 14:36:32.930046 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.41625\n","INFO:tensorflow:loss = 2.567087, step = 974 (0.706 sec)\n","I0202 14:36:32.930472 140715376195456 basic_session_run_hooks.py:260] loss = 2.567087, step = 974 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 1.33764\n","I0202 14:36:33.677620 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33764\n","INFO:tensorflow:loss = 2.7043505, step = 975 (0.748 sec)\n","I0202 14:36:33.678044 140715376195456 basic_session_run_hooks.py:260] loss = 2.7043505, step = 975 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 1.42802\n","I0202 14:36:34.377894 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42802\n","INFO:tensorflow:loss = 2.5747495, step = 976 (0.700 sec)\n","I0202 14:36:34.378299 140715376195456 basic_session_run_hooks.py:260] loss = 2.5747495, step = 976 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 1.4401\n","I0202 14:36:35.072315 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.4401\n","INFO:tensorflow:loss = 2.3380287, step = 977 (0.694 sec)\n","I0202 14:36:35.072813 140715376195456 basic_session_run_hooks.py:260] loss = 2.3380287, step = 977 (0.694 sec)\n","INFO:tensorflow:global_step/sec: 1.34692\n","I0202 14:36:35.814721 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34692\n","INFO:tensorflow:loss = 2.6579309, step = 978 (0.742 sec)\n","I0202 14:36:35.815016 140715376195456 basic_session_run_hooks.py:260] loss = 2.6579309, step = 978 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 1.34925\n","I0202 14:36:36.555874 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34925\n","INFO:tensorflow:loss = 2.5253553, step = 979 (0.741 sec)\n","I0202 14:36:36.556296 140715376195456 basic_session_run_hooks.py:260] loss = 2.5253553, step = 979 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.38139\n","I0202 14:36:37.279778 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38139\n","INFO:tensorflow:loss = 2.3381407, step = 980 (0.724 sec)\n","I0202 14:36:37.280183 140715376195456 basic_session_run_hooks.py:260] loss = 2.3381407, step = 980 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.40189\n","I0202 14:36:37.993113 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.40189\n","INFO:tensorflow:loss = 2.7216272, step = 981 (0.713 sec)\n","I0202 14:36:37.993484 140715376195456 basic_session_run_hooks.py:260] loss = 2.7216272, step = 981 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 1.39603\n","I0202 14:36:38.709444 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39603\n","INFO:tensorflow:loss = 3.134758, step = 982 (0.716 sec)\n","I0202 14:36:38.709893 140715376195456 basic_session_run_hooks.py:260] loss = 3.134758, step = 982 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 1.31826\n","I0202 14:36:39.467982 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31826\n","INFO:tensorflow:loss = 2.4238367, step = 983 (0.758 sec)\n","I0202 14:36:39.468377 140715376195456 basic_session_run_hooks.py:260] loss = 2.4238367, step = 983 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 1.37925\n","I0202 14:36:40.193026 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37925\n","INFO:tensorflow:loss = 3.066158, step = 984 (0.725 sec)\n","I0202 14:36:40.193333 140715376195456 basic_session_run_hooks.py:260] loss = 3.066158, step = 984 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 1.37176\n","I0202 14:36:40.922017 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37176\n","INFO:tensorflow:loss = 2.4299483, step = 985 (0.729 sec)\n","I0202 14:36:40.922528 140715376195456 basic_session_run_hooks.py:260] loss = 2.4299483, step = 985 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.293\n","I0202 14:36:41.695413 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.293\n","INFO:tensorflow:loss = 2.2491105, step = 986 (0.773 sec)\n","I0202 14:36:41.695879 140715376195456 basic_session_run_hooks.py:260] loss = 2.2491105, step = 986 (0.773 sec)\n","INFO:tensorflow:global_step/sec: 1.31409\n","I0202 14:36:42.456388 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.31409\n","INFO:tensorflow:loss = 3.0444942, step = 987 (0.761 sec)\n","I0202 14:36:42.456828 140715376195456 basic_session_run_hooks.py:260] loss = 3.0444942, step = 987 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 1.33036\n","I0202 14:36:43.208084 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33036\n","INFO:tensorflow:loss = 2.3482442, step = 988 (0.752 sec)\n","I0202 14:36:43.208531 140715376195456 basic_session_run_hooks.py:260] loss = 2.3482442, step = 988 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 1.38169\n","I0202 14:36:43.931840 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.38169\n","INFO:tensorflow:loss = 2.4478273, step = 989 (0.724 sec)\n","I0202 14:36:43.932272 140715376195456 basic_session_run_hooks.py:260] loss = 2.4478273, step = 989 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 1.39196\n","I0202 14:36:44.650238 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39196\n","INFO:tensorflow:loss = 2.907279, step = 990 (0.718 sec)\n","I0202 14:36:44.650673 140715376195456 basic_session_run_hooks.py:260] loss = 2.907279, step = 990 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 1.42398\n","I0202 14:36:45.352500 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.42398\n","INFO:tensorflow:loss = 2.51821, step = 991 (0.702 sec)\n","I0202 14:36:45.353003 140715376195456 basic_session_run_hooks.py:260] loss = 2.51821, step = 991 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 1.3502\n","I0202 14:36:46.093112 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.3502\n","INFO:tensorflow:loss = 2.599848, step = 992 (0.741 sec)\n","I0202 14:36:46.093599 140715376195456 basic_session_run_hooks.py:260] loss = 2.599848, step = 992 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 1.39758\n","I0202 14:36:46.808640 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.39758\n","INFO:tensorflow:loss = 2.3559082, step = 993 (0.715 sec)\n","I0202 14:36:46.808937 140715376195456 basic_session_run_hooks.py:260] loss = 2.3559082, step = 993 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 1.35319\n","I0202 14:36:47.547658 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35319\n","INFO:tensorflow:loss = 2.7122557, step = 994 (0.739 sec)\n","I0202 14:36:47.548040 140715376195456 basic_session_run_hooks.py:260] loss = 2.7122557, step = 994 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.37271\n","I0202 14:36:48.276131 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.37271\n","INFO:tensorflow:loss = 2.5399075, step = 995 (0.729 sec)\n","I0202 14:36:48.276590 140715376195456 basic_session_run_hooks.py:260] loss = 2.5399075, step = 995 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 1.33133\n","I0202 14:36:49.027256 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.33133\n","INFO:tensorflow:loss = 2.6950836, step = 996 (0.751 sec)\n","I0202 14:36:49.027646 140715376195456 basic_session_run_hooks.py:260] loss = 2.6950836, step = 996 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 1.35301\n","I0202 14:36:49.766339 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35301\n","INFO:tensorflow:loss = 2.539649, step = 997 (0.739 sec)\n","I0202 14:36:49.766794 140715376195456 basic_session_run_hooks.py:260] loss = 2.539649, step = 997 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.35355\n","I0202 14:36:50.505164 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.35355\n","INFO:tensorflow:loss = 2.528456, step = 998 (0.739 sec)\n","I0202 14:36:50.505506 140715376195456 basic_session_run_hooks.py:260] loss = 2.528456, step = 998 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 1.34434\n","I0202 14:36:51.249017 140715376195456 basic_session_run_hooks.py:692] global_step/sec: 1.34434\n","INFO:tensorflow:loss = 2.6161106, step = 999 (0.745 sec)\n","I0202 14:36:51.250163 140715376195456 basic_session_run_hooks.py:260] loss = 2.6161106, step = 999 (0.745 sec)\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt.\n","I0202 14:36:51.250986 140715376195456 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0202 14:36:53.998475 140715376195456 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:Reading unweighted datasets: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","I0202 14:36:54.027475 140715376195456 dataset_builder.py:163] Reading unweighted datasets: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","I0202 14:36:54.028453 140715376195456 dataset_builder.py:80] Reading record datasets for input file: ['/content/myprojet/models/object_detection/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0202 14:36:54.028612 140715376195456 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0202 14:36:54.836999 140715376195456 estimator.py:1145] Calling model_fn.\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:54.922643 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:54.951524 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ef95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ef95630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:54.990305 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ef95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ef95630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ef3b588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ef3b588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.050811 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ef3b588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ef3b588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.078635 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc42c7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a282b320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a282b320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.148851 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a282b320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a282b320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3d9d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3d9d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.178389 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3d9d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3d9d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ee04e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ee04e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.218032 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ee04e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ee04e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79efaecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79efaecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.281477 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79efaecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79efaecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.310154 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d4775b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ee04be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ee04be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.370394 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ee04be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ee04be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed809e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed809e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.397312 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed809e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed809e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed80f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed80f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.446570 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed80f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed80f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eef2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eef2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.513205 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eef2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eef2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d803a470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d803a470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.544595 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d803a470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d803a470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ed809e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ed809e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.615778 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ed809e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ed809e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ece4b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ece4b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.651358 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ece4b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ece4b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec3f2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec3f2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.693051 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec3f2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec3f2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ebe46a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ebe46a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.752470 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ebe46a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ebe46a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca47f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca47f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.779724 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca47f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca47f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.840773 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79efaed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79efaed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.868444 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79efaed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79efaed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb2ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb2ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.908843 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb2ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb2ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:55.977967 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79eb43048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.011230 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea59be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea59be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.080890 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea59be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea59be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed4ee48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed4ee48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.109836 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed4ee48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ed4ee48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.155050 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea59be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea39ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea39ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.224883 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea39ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ea39ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca4828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca4828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.257766 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca4828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eca4828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8f0780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8f0780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.324576 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8f0780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8f0780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec0fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec0fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.352157 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec0fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ec0fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e7cfe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e7cfe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.389226 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e7cfe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e7cfe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8ac208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8ac208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.461624 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8ac208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79e8ac208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb9d320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb9d320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.490190 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb9d320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79eb9d320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df84b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df84b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.551940 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df84b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df84b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e840588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e840588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.580734 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e840588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e840588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79def4ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79def4ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.616533 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79def4ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79def4ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df70dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df70dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.683015 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df70dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df70dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea05278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea05278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.710845 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea05278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ea05278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df41a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df41a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.795508 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df41a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79df41a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.833381 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddfb2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddfb2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.880608 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddfb2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddfb2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ddd3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ddd3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.950250 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ddd3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79ddd3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:56.984679 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.060856 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e8408d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e8408d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.094944 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e8408d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79e8408d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce9160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce9160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.139373 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce9160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce9160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5c828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5c828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.218378 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5c828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dd5c828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.251982 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.332903 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.367409 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79df04c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79db24a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79db24a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.411657 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79db24a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79db24a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.478362 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dbf4278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.515102 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79de60828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.600926 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddd33c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddd33c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.632573 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddd33c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ddd33c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9f8c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9f8c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.681511 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9f8c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9f8c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacd080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacd080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.763381 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacd080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79dacd080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5ceb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5ceb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.798096 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5ceb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dd5ceb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d9a7160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d9a7160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.871683 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d9a7160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d9a7160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce91d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce91d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.899502 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce91d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79dce91d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d8aab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d8aab70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.937199 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d8aab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d8aab70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8e0be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8e0be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:57.995479 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8e0be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8e0be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d864128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d864128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.022787 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d864128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d864128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8646a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8646a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.086220 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8646a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d8646a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79cb0f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79cb0f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.114823 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79cb0f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79cb0f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.164480 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d864b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d864b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.223833 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d864b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d864b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca99da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca99da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.254089 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca99da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca99da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d7c1d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d7c1d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.312639 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d7c1d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d7c1d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.339170 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca29b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca29b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.375731 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca29b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca29b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c98c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c98c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.435917 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c98c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c98c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9a7978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9a7978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.472882 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9a7978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d9a7978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.541399 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d931978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d931978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.571439 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d931978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d931978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c8ec550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c8ec550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.611804 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c8ec550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c8ec550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.676526 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c935278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d81ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d81ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.705009 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d81ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d81ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c7ef630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c7ef630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.775035 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c7ef630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c7ef630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.802235 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79d7f4da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.838745 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.899199 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca420b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca420b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:58.927740 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca420b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca420b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.000592 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a281f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.038259 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c773fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280eb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280eb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.146078 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280eb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280eb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca42208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca42208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.182671 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca42208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79ca42208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ed68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ed68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.241061 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ed68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ed68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c5eccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c5eccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.277323 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c5eccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c5eccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.335177 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c53afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c53afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.362942 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c53afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c53afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c518cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c518cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.419723 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c518cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c518cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c787c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c787c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.445637 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c787c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c787c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c53afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c53afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.512645 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c53afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c53afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c671d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c671d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.542945 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c671d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c671d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c570f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c570f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.612319 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c570f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c570f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.641870 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.707187 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c8ec400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c34f278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c34f278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.741577 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c34f278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c34f278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.809287 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a280ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:36:59.835977 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff79c407e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.104279 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11497b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11497b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.166965 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11497b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11497b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.230956 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.234004 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11499b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11499b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.293515 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11499b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a11499b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.353566 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.356663 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.424146 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1149780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c41e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c41e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.486554 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c41e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79c41e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.489626 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1190160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1190160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.555289 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1190160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1190160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d3b64a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d3b64a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.622375 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d3b64a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d3b64a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.625527 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d466a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d466a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.688504 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d466a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d466a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4784080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4784080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.754215 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4784080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4784080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:01.757546 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.825532 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1191f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1191f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:01.886821 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1191f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1191f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0202 14:37:04.225043 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0202 14:37:04.225451 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0202 14:37:04.225765 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0202 14:37:04.225947 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0202 14:37:04.226202 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0202 14:37:04.226398 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0202 14:37:04.226670 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0202 14:37:04.226851 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0202 14:37:04.227090 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0202 14:37:04.227269 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0202 14:37:04.227520 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0202 14:37:04.227699 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0202 14:37:04.227941 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0202 14:37:04.228117 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0202 14:37:04.228360 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0202 14:37:04.228540 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0202 14:37:04.228803 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0202 14:37:04.228983 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0202 14:37:04.229247 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0202 14:37:04.229429 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0202 14:37:04.229674 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0202 14:37:04.229843 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0202 14:37:04.230084 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0202 14:37:04.230262 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0202 14:37:04.230512 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0202 14:37:04.230695 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0202 14:37:04.230935 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0202 14:37:04.231110 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0202 14:37:04.231355 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0202 14:37:04.231536 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0202 14:37:04.231782 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0202 14:37:04.231951 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0202 14:37:04.232196 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0202 14:37:04.232366 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0202 14:37:04.232629 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0202 14:37:04.232794 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0202 14:37:04.232954 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0202 14:37:04.233125 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0202 14:37:04.233293 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0202 14:37:04.233474 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0202 14:37:04.233644 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0202 14:37:04.233813 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0202 14:37:04.233979 140715376195456 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0202 14:37:05.263733 140715376195456 estimator.py:1147] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-02-02T14:37:05Z\n","I0202 14:37:05.283181 140715376195456 evaluation.py:255] Starting evaluation at 2021-02-02T14:37:05Z\n","INFO:tensorflow:Graph was finalized.\n","I0202 14:37:06.114215 140715376195456 monitored_session.py:240] Graph was finalized.\n","2021-02-02 14:37:06.114965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:06.115482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 14:37:06.115619: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 14:37:06.115649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 14:37:06.115692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 14:37:06.115723: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 14:37:06.115753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 14:37:06.115775: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 14:37:06.115800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 14:37:06.115892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:06.116335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:06.116686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 14:37:06.116732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 14:37:06.116746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 14:37:06.116755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 14:37:06.116856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:06.117256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:06.117621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","I0202 14:37:06.119626 140715376195456 saver.py:1280] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","INFO:tensorflow:Running local_init_op.\n","I0202 14:37:07.690863 140715376195456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0202 14:37:07.833920 140715376195456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 20 images.\n","I0202 14:37:12.361541 140712546404096 coco_evaluation.py:293] Performing evaluation on 20 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0202 14:37:12.362649 140712546404096 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0202 14:37:12.363757 140712546404096 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.26s).\n","Accumulating evaluation results...\n","DONE (t=0.06s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.956\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.872\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.752\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.753\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n","INFO:tensorflow:Finished evaluation at 2021-02-02-14:37:13\n","I0202 14:37:13.248453 140715376195456 evaluation.py:275] Finished evaluation at 2021-02-02-14:37:13\n","INFO:tensorflow:Saving dict for global step 1000: DetectionBoxes_Precision/mAP = 0.6768957, DetectionBoxes_Precision/mAP (large) = 0.70469785, DetectionBoxes_Precision/mAP (medium) = 0.6633385, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9558296, DetectionBoxes_Precision/mAP@.75IOU = 0.8717863, DetectionBoxes_Recall/AR@1 = 0.32583332, DetectionBoxes_Recall/AR@10 = 0.75222224, DetectionBoxes_Recall/AR@100 = 0.75333333, DetectionBoxes_Recall/AR@100 (large) = 0.74214286, DetectionBoxes_Recall/AR@100 (medium) = 0.7496739, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 2.676736, Loss/localization_loss = 0.26771683, Loss/regularization_loss = 0.34621912, Loss/total_loss = 3.2906718, global_step = 1000, learning_rate = 0.004, loss = 3.2906718\n","I0202 14:37:13.248749 140715376195456 estimator.py:2039] Saving dict for global step 1000: DetectionBoxes_Precision/mAP = 0.6768957, DetectionBoxes_Precision/mAP (large) = 0.70469785, DetectionBoxes_Precision/mAP (medium) = 0.6633385, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9558296, DetectionBoxes_Precision/mAP@.75IOU = 0.8717863, DetectionBoxes_Recall/AR@1 = 0.32583332, DetectionBoxes_Recall/AR@10 = 0.75222224, DetectionBoxes_Recall/AR@100 = 0.75333333, DetectionBoxes_Recall/AR@100 (large) = 0.74214286, DetectionBoxes_Recall/AR@100 (medium) = 0.7496739, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 2.676736, Loss/localization_loss = 0.26771683, Loss/regularization_loss = 0.34621912, Loss/total_loss = 3.2906718, global_step = 1000, learning_rate = 0.004, loss = 3.2906718\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","I0202 14:37:13.253090 140715376195456 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0202 14:37:13.254194 140715376195456 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I0202 14:37:13.564632 140715376195456 estimator.py:1145] Calling model_fn.\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe00f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe00f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.636616 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe00f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe00f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe05c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe05c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.673603 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe05c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe05c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb94048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb94048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.718276 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb94048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb94048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe0da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe0da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.783914 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe0da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe0da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d479fb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d479fb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.810783 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d479fb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9d479fb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb01320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb01320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.877928 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb01320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb01320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.904890 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabe0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabe0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:13.946045 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabe0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabe0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb20518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb20518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.004631 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb20518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdb20518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabef28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabef28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.032009 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabef28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdabef28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.100260 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9fc5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9fc5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.129850 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9fc5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9fc5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9ab1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9ab1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.172935 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9ab1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9ab1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.241559 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd9c3390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.272886 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd8d8748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd8d8748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.335763 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd8d8748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd8d8748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe0d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe0d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.367531 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe0d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbe0d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.411488 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd8d8a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd869c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd869c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.477103 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd869c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd869c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.507663 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdb44eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe09b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe09b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.573170 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe09b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbe09b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc7005f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc7005f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.604516 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc7005f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc7005f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc6aec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc6aec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.645250 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc6aec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc6aec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd827e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd827e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.720649 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd827e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd827e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cda1b278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cda1b278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.750779 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cda1b278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cda1b278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e7940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e7940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.817196 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e7940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e7940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9abcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9abcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.843245 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9abcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cd9abcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2a2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2a2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.878748 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2a2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2a2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e79b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e79b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.937503 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e79b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc5e79b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc745b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc745b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:14.972841 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc745b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc745b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd884780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd884780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.044227 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd884780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cd884780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.075919 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc25e940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc25e940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.119496 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc25e940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc25e940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.184169 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.211914 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0c45c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0c45c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.279522 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0c45c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0c45c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc07e5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc07e5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.309505 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc07e5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc07e5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc11e5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc11e5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.346493 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc11e5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc11e5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0ac278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0ac278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.406080 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0ac278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc0ac278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.432782 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f9d860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f9d860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.491849 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f9d860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f9d860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3008d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3008d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.524553 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3008d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc3008d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9df60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9df60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.568557 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9df60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f9df60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f30438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f30438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.631041 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f30438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2f30438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.658240 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bdc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d96b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d96b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.727189 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d96b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d96b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bddd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bddd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.753710 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bddd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc1bddd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2daac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2daac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.790678 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2daac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2daac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d78b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d78b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.847649 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d78b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2d78b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2225c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2225c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.880578 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2225c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc2225c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2acbef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2acbef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.947818 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2acbef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2acbef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc0ac860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc0ac860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:15.978239 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc0ac860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cc0ac860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.016084 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2a9eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2a9eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.082032 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2a9eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2a9eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f47198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f47198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.117746 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f47198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2f47198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.188249 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.222655 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.264441 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a278da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.329390 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a27d1da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.358662 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2667668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2667668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.427950 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2667668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2667668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2c449b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2c449b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.454987 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2c449b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2c449b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.493092 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2667dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2621be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2621be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.551266 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2621be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2621be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.577854 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2bee710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2c44400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2c44400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.637138 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2c44400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2c44400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2a9e860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2a9e860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.663661 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2a9e860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2a9e860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23ed8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23ed8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.712339 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23ed8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23ed8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a25b4c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a25b4c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.773760 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a25b4c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a25b4c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27e8ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27e8ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.802801 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27e8ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27e8ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a239aba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a239aba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.860582 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a239aba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a239aba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.886774 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a224a898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a224a898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.923395 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a224a898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a224a898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a22bde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a22bde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:16.990959 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a22bde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a22bde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27ba048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27ba048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.021186 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27ba048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a27ba048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.088022 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25925f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25925f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.119712 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25925f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25925f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2274358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2274358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.158512 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2274358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2274358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a21f9860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a21f9860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.217664 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a21f9860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a21f9860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25379e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25379e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.245458 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25379e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a25379e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20d80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20d80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.316624 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20d80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20d80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23fd208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23fd208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.346924 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23fd208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23fd208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2092a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2092a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.388269 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2092a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2092a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20eff98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20eff98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.454787 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20eff98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20eff98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1fefd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1fefd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.484844 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1fefd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1fefd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.547389 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f02f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f02f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.583831 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f02f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f02f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcd5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcd5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.652817 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcd5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcd5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbcd6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbcd6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.679984 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbcd6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff9cdbcd6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcdc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcdc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.746429 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcdc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cdbcdc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.772749 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9afd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f42e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f42e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.830094 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f42e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9cc1f42e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9a240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9a240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.856698 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9a240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1f9a240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.923825 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a23b5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1dd19e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1dd19e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:17.953721 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1dd19e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1dd19e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20333c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20333c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.013798 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20333c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a20333c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.044216 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a23b5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1f02fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1f02fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.103457 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1f02fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1f02fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c9b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c9b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.131442 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c9b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c9b748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2274da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2274da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.204728 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2274da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a2274da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2316898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2316898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.236053 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2316898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a2316898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1e4d9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1e4d9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.294312 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1e4d9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1e4d9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c7abe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c7abe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:18.321368 140715376195456 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c7abe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7ff7a1c7abe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:19.558275 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.619781 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d4641d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.682354 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:19.685455 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6501d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6501d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.750220 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6501d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6501d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.820175 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d650240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:19.823231 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6500f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6500f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.882545 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6500f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6500f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffa54095f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffa54095f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:19.943538 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffa54095f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ffa54095f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:19.946994 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6502e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6502e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.006370 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6502e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6502e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.068975 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:20.072065 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d801c320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d801c320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.146565 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d801c320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d801c320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.218587 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff9d47ae9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 14:37:20.222136 140715376195456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6506a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6506a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.289592 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6506a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff79d6506a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1da9f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1da9f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 14:37:20.370041 140715376195456 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1da9f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff7a1da9f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Done calling model_fn.\n","I0202 14:37:21.154263 140715376195456 estimator.py:1147] Done calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0202 14:37:21.154570 140715376195456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0202 14:37:21.155265 140715376195456 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0202 14:37:21.155390 140715376195456 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0202 14:37:21.155513 140715376195456 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0202 14:37:21.155591 140715376195456 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0202 14:37:21.155663 140715376195456 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2021-02-02 14:37:21.156273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:21.156778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 14:37:21.156900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 14:37:21.156930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 14:37:21.156969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 14:37:21.156994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 14:37:21.157016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 14:37:21.157042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 14:37:21.157069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 14:37:21.157163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:21.157584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:21.157922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 14:37:21.157971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 14:37:21.157985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 14:37:21.157994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 14:37:21.158089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:21.158497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 14:37:21.158850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","I0202 14:37:21.162686 140715376195456 saver.py:1280] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","INFO:tensorflow:Assets added to graph.\n","I0202 14:37:21.674313 140715376195456 builder_impl.py:661] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0202 14:37:21.674550 140715376195456 builder_impl.py:456] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/export/Servo/temp-b'1612276633'/saved_model.pb\n","I0202 14:37:22.508306 140715376195456 builder_impl.py:421] SavedModel written to: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/export/Servo/temp-b'1612276633'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 2.6161106.\n","I0202 14:37:23.177145 140715376195456 estimator.py:368] Loss for final step: 2.6161106.\n","Colab train finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTr9cBlu7U3B","executionInfo":{"status":"ok","timestamp":1612278665525,"user_tz":-480,"elapsed":1360,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"16f590ea-c0ef-4c96-92d5-e0ba2ffe47da"},"source":["print(model_dir)\r\n","!ls -ltra '{model_dir}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203\n","total 358198\n","-rw------- 1 root root 31674715 Feb  2 14:23 graph.pbtxt\n","-rw------- 1 root root    68664 Feb  2 14:23 model.ckpt-0.index\n","-rw------- 1 root root 74452352 Feb  2 14:23 model.ckpt-0.data-00000-of-00001\n","-rw------- 1 root root 16851333 Feb  2 14:23 model.ckpt-0.meta\n","-rw------- 1 root root    68664 Feb  2 14:33 model.ckpt-769.index\n","-rw------- 1 root root 74452352 Feb  2 14:33 model.ckpt-769.data-00000-of-00001\n","-rw------- 1 root root 16851333 Feb  2 14:33 model.ckpt-769.meta\n","-rw------- 1 root root    68664 Feb  2 14:36 model.ckpt-1000.index\n","-rw------- 1 root root 74452352 Feb  2 14:36 model.ckpt-1000.data-00000-of-00001\n","-rw------- 1 root root      175 Feb  2 14:36 checkpoint\n","-rw------- 1 root root 16851333 Feb  2 14:36 model.ckpt-1000.meta\n","drwx------ 3 root root     4096 Feb  2 14:37 export\n","-rw------- 1 root root 60991258 Feb  2 14:37 events.out.tfevents.1612275785.fb90fa442b25\n","drwx------ 2 root root     4096 Feb  2 14:37 eval_0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KuA0BtS0-cuF"},"source":["5保存並轉換模型輸出\r\n","\r\n","5.1導出訓練的模型"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"iBxGLBGD-aIh","executionInfo":{"status":"error","timestamp":1612319009495,"user_tz":-480,"elapsed":1494,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"ebcdac5e-a9cf-4cad-90bb-5880e2fb6a57"},"source":["import os\r\n","import re\r\n","import numpy as np\r\n","\r\n","output_directory = '%s/fine_tuned_model' % model_dir\r\n","os.makedirs(output_directory, exist_ok=True)\r\n","print(\"output_directory:\")\r\n","print(output_directory)\r\n","!cp {label_map_pbtxt_fname} '{output_directory}'\r\n","!ls -ltra '{output_directory}'\r\n","lst = os.listdir(model_dir)\r\n","# find the last model checkpoint file, i.e. model.ckpt-1000.meta\r\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\r\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\r\n","last_model = lst[steps.argmax()].replace('.meta', '')\r\n","\r\n","last_model_path = os.path.join(model_dir, last_model)\r\n","print(last_model_path)\r\n","print(pipeline_fname)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["output_directory:\n","/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model\n","total 39537\n","-rw------- 1 root root    23537 Feb  2 15:11 model.ckpt.index\n","-rw------- 1 root root 18726392 Feb  2 15:11 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root       77 Feb  2 15:11 checkpoint\n","-rw------- 1 root root  2155983 Feb  2 15:11 model.ckpt.meta\n","drwx------ 2 root root     4096 Feb  2 15:11 saved_model\n","-rw------- 1 root root 19569838 Feb  2 15:11 frozen_inference_graph.pb\n","-rw------- 1 root root     4188 Feb  2 15:11 pipeline.config\n","-rw------- 1 root root      122 Feb  3 02:23 label_map.pbtxt\n","/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-dbde6a73ace9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlast_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pipeline_fname' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"5zwY2Hmw_Xu_"},"source":["保存訓練結果"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TWBalkO-6fJ","executionInfo":{"status":"ok","timestamp":1612278713638,"user_tz":-480,"elapsed":22934,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"b55dd4ff-2a94-4f92-eee0-d456b81fa7d3"},"source":["!echo creates the frozen inference graph in fine_tune_model\r\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \r\n","!python /content/models/research/object_detection/export_inference_graph.py \\\r\n","    --input_type=image_tensor \\\r\n","    --pipeline_config_path={pipeline_fname} \\\r\n","    --output_directory='{output_directory}' \\\r\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["creates the frozen inference graph in fine_tune_model\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80750b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80750b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.025781 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80750b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80750b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.052365 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.087055 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fe9c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.146932 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f6eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f6eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.186146 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f6eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f6eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.247004 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8075898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.271794 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8015518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8015518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.308518 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8015518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8015518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ed3dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ed3dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.366090 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ed3dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ed3dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.392313 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7eb6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7eb6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.447874 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7eb6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7eb6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e66898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e66898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.472231 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e66898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e66898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.505656 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d8beb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d8beb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.560795 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d8beb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d8beb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.585625 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe8004588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d52f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d52f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.644764 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d52f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d52f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe80045c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe80045c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.669876 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe80045c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe80045c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.703650 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d2dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d2dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.760524 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d2dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d2dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fef898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fef898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.785063 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fef898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fef898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7db5908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7db5908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.840512 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7db5908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7db5908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7ec2cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7ec2cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.865529 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7ec2cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7ec2cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7c38c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7c38c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.903143 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7c38c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7c38c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7c77748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7c77748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.957667 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7c77748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7c77748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:38.983017 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7eb6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.040179 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e2f588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e2f588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.066294 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e2f588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7e2f588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0c780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0c780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.100824 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0c780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0c780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.160572 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7b73940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d62668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d62668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.186235 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d62668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d62668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ab8208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ab8208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.246321 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ab8208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7ab8208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.271265 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7d24470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79954e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79954e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.305277 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79954e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79954e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d24278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d24278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.363670 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d24278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7d24278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.389249 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe79b5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe79b5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.445890 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe79b5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe79b5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7965ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7965ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.470913 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7965ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7965ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.507872 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe78a2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe78a2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.562454 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe78a2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe78a2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7bb7be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7bb7be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.586591 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7bb7be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7bb7be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe784b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe784b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.643511 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe784b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe784b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0cba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0cba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.770653 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0cba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7b0cba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe78b0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe78b0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.805560 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe78b0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe78b0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.860613 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f89da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f89da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.884968 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f89da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7f89da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe774d940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe774d940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.947451 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe774d940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe774d940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7a1ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7a1ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:39.973464 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7a1ccc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7a1ccc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fa0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fa0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.010000 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fa0b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7fa0b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.066369 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.091757 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe79b5dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe766dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe766dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.154297 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe766dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe766dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.181300 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76000b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76000b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.220185 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76000b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76000b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe762e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe762e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.275946 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe762e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe762e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe785e668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe785e668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.302010 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe785e668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe785e668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe754df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe754df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.358697 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe754df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe754df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe751a860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe751a860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.384342 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe751a860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe751a860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe757ada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe757ada0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.419646 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe757ada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe757ada0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe751aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe751aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.478577 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe751aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe751aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7766ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7766ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.505723 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7766ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7766ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe745d9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe745d9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.571507 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe745d9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe745d9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77172b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77172b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.596187 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77172b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77172b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7422320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7422320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.630806 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7422320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7422320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe747bb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe747bb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.686026 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe747bb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe747bb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7345748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7345748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.711110 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7345748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7345748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.769799 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe767fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe767fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.794863 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe767fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe767fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7313470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7313470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.832268 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7313470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7313470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe73d7588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe73d7588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.888068 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe73d7588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe73d7588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.913199 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe729d438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe729d438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.969259 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe729d438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe729d438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:40.994117 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe75b3780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe729ddd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe729ddd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.029346 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe729ddd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe729ddd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe72b7908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe72b7908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.084517 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe72b7908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe72b7908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe74af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe74af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.113327 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe74af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe74af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7168828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7168828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.176306 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7168828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7168828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7134898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7134898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.202668 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7134898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe7134898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe70d8eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe70d8eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.238049 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe70d8eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe70d8eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe71c2780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe71c2780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.293930 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe71c2780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe71c2780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73457f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73457f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.328892 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73457f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73457f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.394308 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7345470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73136d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73136d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.421595 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73136d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe73136d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe707bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe707bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.456743 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe707bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe707bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7027828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7027828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.514309 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7027828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7027828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe72b7ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe72b7ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.540998 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe72b7ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe72b7ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.597836 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe8062f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f4b978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f4b978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.627485 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f4b978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f4b978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.689081 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f5bdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f5bdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.714159 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f5bdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f5bdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f8f828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f8f828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.770877 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f8f828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f8f828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f9eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f9eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.795709 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f9eda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f9eda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7cbd7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7cbd7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.860149 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7cbd7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7cbd7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e6aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e6aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.886274 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e6aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e6aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:41.942210 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe80f3518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e1eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e1eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.077736 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e1eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6e1eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6e36f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6e36f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.138029 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6e36f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6e36f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77775c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77775c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.169793 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77775c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe77775c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.226746 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe7777978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.253718 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe76c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe707bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe707bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.310364 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe707bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe707bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f25cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f25cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.335782 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f25cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe6f25cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f9ecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f9ecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.393322 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f9ecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6f9ecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe771c828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe771c828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:42.420506 140051867096960 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe771c828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f5fe771c828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:42.994593 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.055593 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.121109 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe670ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:43.127687 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.191707 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.261455 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6717128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:43.268335 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6687710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6687710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.326043 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6687710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6687710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe66872b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe66872b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.390570 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe66872b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe66872b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:43.396931 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6cb2940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6cb2940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.454171 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6cb2940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6cb2940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe667cc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe667cc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.521880 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe667cc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe667cc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:43.531040 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.588361 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.651919 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe65e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0202 15:11:43.658355 140051867096960 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.715335 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0202 15:11:43.786129 140051867096960 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f5fe6556ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:601: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0202 15:11:44.010025 140051867096960 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:601: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0202 15:11:44.539181 140051867096960 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0202 15:11:45.983534 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0202 15:11:45.983848 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0202 15:11:45.984121 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0202 15:11:45.984308 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0202 15:11:45.984563 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0202 15:11:45.984745 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0202 15:11:45.984993 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0202 15:11:45.985163 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0202 15:11:45.985404 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0202 15:11:45.985599 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0202 15:11:45.985846 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0202 15:11:45.986020 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0202 15:11:45.986258 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0202 15:11:45.986441 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0202 15:11:45.986689 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0202 15:11:45.986863 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0202 15:11:45.987105 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0202 15:11:45.987272 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0202 15:11:45.987524 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0202 15:11:45.987700 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0202 15:11:45.987946 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0202 15:11:45.988154 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0202 15:11:45.988444 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0202 15:11:45.988642 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0202 15:11:45.988922 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0202 15:11:45.989119 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0202 15:11:45.989384 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0202 15:11:45.989588 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0202 15:11:45.989846 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0202 15:11:45.990021 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0202 15:11:45.990298 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0202 15:11:45.990499 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0202 15:11:45.990782 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0202 15:11:45.990958 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0202 15:11:45.991223 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0202 15:11:45.991383 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0202 15:11:45.991567 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0202 15:11:45.991736 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0202 15:11:45.991910 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0202 15:11:45.992074 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0202 15:11:45.992240 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0202 15:11:45.992404 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0202 15:11:45.992582 140051867096960 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0202 15:11:45.994686 140051867096960 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0202 15:11:45.995119 140051867096960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","277 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.61m params)\n","  BoxPredictor_0 (--/13.85k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/6.92k params)\n","      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","  BoxPredictor_1 (--/61.49k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/30.74k params)\n","      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","  BoxPredictor_2 (--/24.62k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/12.31k params)\n","      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  BoxPredictor_3 (--/12.34k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/6.17k params)\n","      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_4 (--/12.34k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/6.17k params)\n","      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_5 (--/6.19k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/3.10k params)\n","      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","277 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/4.49m flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV2/Conv_1/mul_fold (409.60k/409.60k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/mul_fold (327.68k/327.68k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/project/mul_fold (307.20k/307.20k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/project/mul_fold (92.16k/92.16k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/project/mul_fold (36.86k/36.86k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/project/mul_fold (12.29k/12.29k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/project/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/project/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/project/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/expand/mul_fold (1.54k/1.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/mul_fold (1.30k/1.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/mul_fold (1.30k/1.30k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV2/Conv/mul_fold (864/864 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/project/mul_fold (512/512 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/add (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Preprocessor/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n","  Preprocessor/map/while/add (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","\n","======================End of Report==========================\n","2021-02-02 15:11:48.940819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2021-02-02 15:11:48.958608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:48.959153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 15:11:48.959480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 15:11:48.961560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 15:11:48.963046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 15:11:48.963637: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 15:11:48.965540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 15:11:48.966715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 15:11:48.970754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 15:11:48.970919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:48.971489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:48.972003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 15:11:48.972461: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2021-02-02 15:11:49.066856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.067543: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e3cf40 executing computations on platform CUDA. Devices:\n","2021-02-02 15:11:49.067575: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-02-02 15:11:49.069940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2021-02-02 15:11:49.070494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e3d480 executing computations on platform Host. Devices:\n","2021-02-02 15:11:49.070538: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2021-02-02 15:11:49.070753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.071286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 15:11:49.071368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 15:11:49.071400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 15:11:49.071444: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 15:11:49.071473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 15:11:49.071501: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 15:11:49.071527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 15:11:49.071553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 15:11:49.071641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.072198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.072726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 15:11:49.072836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 15:11:49.074027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 15:11:49.074061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 15:11:49.074075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 15:11:49.074260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.074898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:49.075405: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-02-02 15:11:49.075520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0202 15:11:49.076460 140051867096960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","I0202 15:11:49.079156 140051867096960 saver.py:1280] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","2021-02-02 15:11:52.332290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:52.332878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 15:11:52.332968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 15:11:52.332997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 15:11:52.333019: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 15:11:52.333042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 15:11:52.333064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 15:11:52.333085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 15:11:52.333105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 15:11:52.333195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:52.333761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:52.334263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 15:11:52.334304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 15:11:52.334320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 15:11:52.334330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 15:11:52.334437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:52.334979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:52.335507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","I0202 15:11:52.337409 140051867096960 saver.py:1280] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/model.ckpt-1000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0202 15:11:53.365953 140051867096960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0202 15:11:53.366233 140051867096960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I0202 15:11:53.861526 140051867096960 graph_util_impl.py:311] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I0202 15:11:53.962970 140051867096960 graph_util_impl.py:364] Converted 632 variables to const ops.\n","2021-02-02 15:11:54.161305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:54.161906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-02-02 15:11:54.161995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2021-02-02 15:11:54.162020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2021-02-02 15:11:54.162042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2021-02-02 15:11:54.162062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2021-02-02 15:11:54.162082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2021-02-02 15:11:54.162101: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2021-02-02 15:11:54.162127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2021-02-02 15:11:54.162217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:54.162776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:54.163262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2021-02-02 15:11:54.163303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-02-02 15:11:54.163317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2021-02-02 15:11:54.163329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2021-02-02 15:11:54.163443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:54.163981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-02-02 15:11:54.164489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0202 15:11:54.684746 140051867096960 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0202 15:11:54.685372 140051867096960 builder_impl.py:636] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0202 15:11:54.685567 140051867096960 builder_impl.py:456] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model/saved_model/saved_model.pb\n","I0202 15:11:55.205999 140051867096960 builder_impl.py:421] SavedModel written to: /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model/pipeline.config\n","I0202 15:11:55.237150 140051867096960 config_util.py:254] Writing pipeline config file to /content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ShUB4NJ_hzJ","executionInfo":{"status":"ok","timestamp":1612278713639,"user_tz":-480,"elapsed":16242,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"4cb14f36-33bd-4667-b8a9-3f358d8141c2"},"source":["print(output_directory)\r\n","!ls -ltra '{output_directory}'\r\n","#pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\") # this is main one\r\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\r\n","!cp '{label_map_pbtxt_fname}' '{output_directory}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model\n","total 39537\n","-rw------- 1 root root      122 Feb  2 15:11 label_map.pbtxt\n","-rw------- 1 root root    23537 Feb  2 15:11 model.ckpt.index\n","-rw------- 1 root root 18726392 Feb  2 15:11 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root       77 Feb  2 15:11 checkpoint\n","-rw------- 1 root root  2155983 Feb  2 15:11 model.ckpt.meta\n","-rw------- 1 root root 19569838 Feb  2 15:11 frozen_inference_graph.pb\n","drwx------ 3 root root     4096 Feb  2 15:11 saved_model\n","-rw------- 1 root root     4188 Feb  2 15:11 pipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o3Xm2ffF_1Uz"},"source":["5.2推論測試(設定凍結模型與參數、測試影像資料等位置)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-5KNj4K_vC2","executionInfo":{"status":"ok","timestamp":1612278713929,"user_tz":-480,"elapsed":757,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"c6f3b563-07f3-4de9-cac0-5e5fe2543504"},"source":["import os\r\n","import glob\r\n","\r\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\r\n","PATH_TO_CKPT = pb_fname\r\n","print(PATH_TO_CKPT)\r\n","\r\n","# List of the strings that is used to add correct label for each box.\r\n","PATH_TO_LABELS = label_map_pbtxt_fname\r\n","\r\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\r\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"models/object_detection/data/images/test\")\r\n","\r\n","assert os.path.isfile(pb_fname)\r\n","assert os.path.isfile(PATH_TO_LABELS)\r\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\r\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\r\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning0203/Training0203/fine_tuned_model/frozen_inference_graph.pb\n","['/content/myprojet/models/object_detection/data/images/test/013.jpg', '/content/myprojet/models/object_detection/data/images/test/044.jpg', '/content/myprojet/models/object_detection/data/images/test/082.jpg', '/content/myprojet/models/object_detection/data/images/test/014.jpg', '/content/myprojet/models/object_detection/data/images/test/084.jpg', '/content/myprojet/models/object_detection/data/images/test/061.jpg', '/content/myprojet/models/object_detection/data/images/test/064.jpg', '/content/myprojet/models/object_detection/data/images/test/012.jpg', '/content/myprojet/models/object_detection/data/images/test/083.jpg', '/content/myprojet/models/object_detection/data/images/test/065.jpg', '/content/myprojet/models/object_detection/data/images/test/045.jpg', '/content/myprojet/models/object_detection/data/images/test/043.jpg', '/content/myprojet/models/object_detection/data/images/test/042.jpg', '/content/myprojet/models/object_detection/data/images/test/063.jpg', '/content/myprojet/models/object_detection/data/images/test/011.jpg', '/content/myprojet/models/object_detection/data/images/test/085.jpg', '/content/myprojet/models/object_detection/data/images/test/041.jpg', '/content/myprojet/models/object_detection/data/images/test/062.jpg', '/content/myprojet/models/object_detection/data/images/test/081.jpg', '/content/myprojet/models/object_detection/data/images/test/015.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gA5w6DSY_4gn","executionInfo":{"status":"ok","timestamp":1612278923570,"user_tz":-480,"elapsed":1705,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"8002dad3-d65e-45df-a5e4-a05e90bcc2eb"},"source":["%cd /content/models/research/object_detection\r\n","\r\n","import numpy as np\r\n","import os\r\n","import six.moves.urllib as urllib\r\n","import sys\r\n","import tarfile\r\n","import tensorflow as tf\r\n","import zipfile\r\n","\r\n","from collections import defaultdict\r\n","from io import StringIO\r\n","from matplotlib import pyplot as plt\r\n","from PIL import Image\r\n","\r\n","# This is needed since the notebook is stored in the object_detection folder.\r\n","sys.path.append(\"..\")\r\n","from object_detection.utils import ops as utils_ops\r\n","\r\n","# This is needed to display the images.\r\n","%matplotlib inline\r\n","\r\n","from object_detection.utils import label_map_util\r\n","\r\n","from object_detection.utils import visualization_utils as vis_util\r\n","\r\n","detection_graph = tf.Graph()\r\n","with detection_graph.as_default():\r\n","    od_graph_def = tf.GraphDef()\r\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n","        serialized_graph = fid.read()\r\n","        od_graph_def.ParseFromString(serialized_graph)\r\n","        tf.import_graph_def(od_graph_def, name='')\r\n","\r\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\n","categories = label_map_util.convert_label_map_to_categories(\r\n","    label_map, max_num_classes=num_classes, use_display_name=True)\r\n","category_index = label_map_util.create_category_index(categories)\r\n","\r\n","def load_image_into_numpy_array(image):\r\n","    (im_width, im_height) = image.size\r\n","    return np.array(image.getdata()).reshape(\r\n","        (im_height, im_width, 3)).astype(np.uint8)\r\n","\r\n","# Size, in inches, of the output images.\r\n","IMAGE_SIZE = (24, 16)\r\n","\r\n","def run_inference_for_single_image(image, graph):\r\n","    with graph.as_default():\r\n","        with tf.Session() as sess:\r\n","            # Get handles to input and output tensors\r\n","            ops = tf.get_default_graph().get_operations()\r\n","            all_tensor_names = {\r\n","                output.name for op in ops for output in op.outputs}\r\n","            tensor_dict = {}\r\n","            for key in [\r\n","                'num_detections', 'detection_boxes', 'detection_scores',\r\n","                'detection_classes', 'detection_masks'\r\n","            ]:\r\n","                tensor_name = key + ':0'\r\n","                if tensor_name in all_tensor_names:\r\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n","                        tensor_name)\r\n","            if 'detection_masks' in tensor_dict:\r\n","                # The following processing is only for single image\r\n","                detection_boxes = tf.squeeze(\r\n","                    tensor_dict['detection_boxes'], [0])\r\n","                detection_masks = tf.squeeze(\r\n","                    tensor_dict['detection_masks'], [0])\r\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\r\n","                real_num_detection = tf.cast(\r\n","                    tensor_dict['num_detections'][0], tf.int32)\r\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\r\n","                                           real_num_detection, -1])\r\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\r\n","                                           real_num_detection, -1, -1])\r\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\r\n","                detection_masks_reframed = tf.cast(\r\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\r\n","                # Follow the convention by adding back the batch dimension\r\n","                tensor_dict['detection_masks'] = tf.expand_dims(\r\n","                    detection_masks_reframed, 0)\r\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\r\n","\r\n","            # Run inference\r\n","            output_dict = sess.run(tensor_dict,\r\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\r\n","\r\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\r\n","            output_dict['num_detections'] = int(\r\n","                output_dict['num_detections'][0])\r\n","            output_dict['detection_classes'] = output_dict[\r\n","                'detection_classes'][0].astype(np.uint8)\r\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\r\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\r\n","            if 'detection_masks' in output_dict:\r\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\r\n","    return output_dict"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ndlssYpNAPvp"},"source":["推論測試(顯示辨識結果)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-z75zfvsk0C2PReBJHnI2FjpOwKrA9Up"},"id":"nLjaxIroAKZT","executionInfo":{"status":"ok","timestamp":1612278980526,"user_tz":-480,"elapsed":52450,"user":{"displayName":"宜芳蔡","photoUrl":"","userId":"06957795387783369418"}},"outputId":"8f7b6d85-ba80-4aa5-966c-83a2ed65b113"},"source":["# running inferences.  This should show images with bounding boxes\r\n","%matplotlib inline\r\n","\r\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\r\n","for image_path in TEST_IMAGE_PATHS:\r\n","    image = Image.open(image_path)\r\n","    # the array based representation of the image will be used later in order to prepare the\r\n","    # result image with boxes and labels on it.\r\n","    image_np = load_image_into_numpy_array(image)\r\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\r\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\r\n","    # Actual detection.\r\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\r\n","    # Visualization of the results of a detection.\r\n","    vis_util.visualize_boxes_and_labels_on_image_array(\r\n","        image_np,\r\n","        output_dict['detection_boxes'],\r\n","        output_dict['detection_classes'],\r\n","        output_dict['detection_scores'],\r\n","        category_index,\r\n","        instance_masks=output_dict.get('detection_masks'),\r\n","        use_normalized_coordinates=True,\r\n","        line_thickness=2)\r\n","    plt.figure(figsize=IMAGE_SIZE)\r\n","    plt.imshow(image_np)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}